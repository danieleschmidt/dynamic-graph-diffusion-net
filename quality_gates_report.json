{
  "overall_success": false,
  "total_duration": 12.26460075378418,
  "results": {
    "import_tests": {
      "name": "Import Tests",
      "passed": false,
      "duration": 0.4693150520324707,
      "output": "",
      "error": "ImportError while loading conftest '/root/repo/tests/conftest.py'.\ntests/conftest.py:4: in <module>\n    import torch\nE   ModuleNotFoundError: No module named 'torch'\n"
    },
    "unit_tests": {
      "name": "Unit Tests",
      "passed": false,
      "duration": 0.4835984706878662,
      "coverage": 0,
      "output": "",
      "error": "ImportError while loading conftest '/root/repo/tests/conftest.py'.\ntests/conftest.py:4: in <module>\n    import torch\nE   ModuleNotFoundError: No module named 'torch'\n"
    },
    "integration_tests": {
      "name": "Integration Tests",
      "passed": false,
      "duration": 0.41460156440734863,
      "output": "",
      "error": "ImportError while loading conftest '/root/repo/tests/conftest.py'.\ntests/conftest.py:4: in <module>\n    import torch\nE   ModuleNotFoundError: No module named 'torch'\n"
    },
    "code_coverage": {
      "name": "code_coverage",
      "passed": false,
      "duration": 0,
      "error": "'code_coverage'"
    },
    "type_checking": {
      "name": "Type Checking",
      "passed": false,
      "duration": 9.086289405822754,
      "error_count": 331,
      "output": "src/dgdn/i18n/messages.py: note: In member \"get\" of class \"Messages\":\nsrc/dgdn/i18n/messages.py:298:5: error: Function is missing a type annotation\nfor one or more arguments  [no-untyped-def]\n        def get(self, key: str, **kwargs) -> str:\n        ^\nsrc/dgdn/i18n/messages.py: note: In member \"set_locale\" of class \"Messages\":\nsrc/dgdn/i18n/messages.py:311:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def set_locale(self, locale: str):\n        ^\nsrc/dgdn/training/losses.py: note: In class \"DGDNLoss\":\nsrc/dgdn/training/losses.py:10:16: error: Class cannot subclass \"Module\" (has\ntype \"Any\")  [misc]\n    class DGDNLoss(nn.Module):\n                   ^~~~~~~~~\nsrc/dgdn/training/losses.py: note: In member \"forward\" of class \"DGDNLoss\":\nsrc/dgdn/training/losses.py:41:5: error: Function is missing a type annotation\nfor one or more arguments  [no-untyped-def]\n        def forward(\n        ^\nsrc/dgdn/training/losses.py: note: In class \"VariationalLoss\":\nsrc/dgdn/training/losses.py:188:23: error: Class cannot subclass \"Module\" (has\ntype \"Any\")  [misc]\n    class VariationalLoss(nn.Module):\n                          ^~~~~~~~~\nsrc/dgdn/training/losses.py: note: In class \"TemporalRegularizationLoss\":\nsrc/dgdn/training/losses.py:230:34: error: Class cannot subclass \"Module\" (has\ntype \"Any\")  [misc]\n    class TemporalRegularizationLoss(nn.Module):\n                                     ^~~~~~~~~\nsrc/dgdn/training/losses.py: note: In class \"DiffusionLoss\":\nsrc/dgdn/training/losses.py:258:21: error: Class cannot subclass \"Module\" (has\ntype \"Any\")  [misc]\n    class DiffusionLoss(nn.Module):\n                        ^~~~~~~~~\nsrc/dgdn/training/losses.py: note: In member \"forward\" of class \"DiffusionLoss\":\nsrc/dgdn/training/losses.py:265:40: error: Missing type parameters for generic\ntype \"list\"  [type-arg]\n        def forward(self, diffusion_steps: list) -> torch.Tensor:\n                                           ^\nsrc/dgdn/training/losses.py: note: In class \"ContrastiveLoss\":\nsrc/dgdn/training/losses.py:296:23: error: Class cannot subclass \"Module\" (has\ntype \"Any\")  [misc]\n    class ContrastiveLoss(nn.Module):\n                          ^~~~~~~~~\nsrc/dgdn/training/losses.py: note: In class \"AdversarialLoss\":\nsrc/dgdn/training/losses.py:335:23: error: Class cannot subclass \"Module\" (has\ntype \"Any\")  [misc]\n    class AdversarialLoss(nn.Module):\n                          ^~~~~~~~~\nsrc/dgdn/training/losses.py: note: In member \"forward\" of class \"AdversarialLoss\":\nsrc/dgdn/training/losses.py:342:5: error: Function is missing a type annotation\nfor one or more arguments  [no-untyped-def]\n        def forward(\n        ^\nsrc/dgdn/temporal/encoding.py: note: In class \"EdgeTimeEncoder\":\nsrc/dgdn/temporal/encoding.py:14:23: error: Class cannot subclass \"Module\" (has\ntype \"Any\")  [misc]\n    class EdgeTimeEncoder(nn.Module):\n                          ^~~~~~~~~\nsrc/dgdn/temporal/encoding.py: note: In member \"reset_parameters\" of class \"EdgeTimeEncoder\":\nsrc/dgdn/temporal/encoding.py:58:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def reset_parameters(self):\n        ^\nsrc/dgdn/temporal/encoding.py:58:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/temporal/encoding.py: note: In class \"PositionalTimeEncoder\":\nsrc/dgdn/temporal/encoding.py:156:29: error: Class cannot subclass \"Module\"\n(has type \"Any\")  [misc]\n    class PositionalTimeEncoder(nn.Module):\n                                ^~~~~~~~~\nsrc/dgdn/temporal/encoding.py: note: In class \"MultiScaleTimeEncoder\":\nsrc/dgdn/temporal/encoding.py:195:29: error: Class cannot subclass \"Module\"\n(has type \"Any\")  [misc]\n    class MultiScaleTimeEncoder(nn.Module):\n                                ^~~~~~~~~\nsrc/dgdn/temporal/encoding.py: note: In member \"__init__\" of class \"MultiScaleTimeEncoder\":\nsrc/dgdn/temporal/encoding.py:204:26: error: Missing type parameters for\ngeneric type \"list\"  [type-arg]\n            scales: Optional[list] = None,\n                             ^\nsrc/dgdn/temporal/diffusion.py: note: In class \"VariationalDiffusion\":\nsrc/dgdn/temporal/diffusion.py:16:28: error: Class cannot subclass \"Module\"\n(has type \"Any\")  [misc]\n    class VariationalDiffusion(nn.Module):\n                               ^~~~~~~~~\nsrc/dgdn/temporal/diffusion.py: note: In member \"forward\" of class \"VariationalDiffusion\":\nsrc/dgdn/temporal/diffusion.py:106:21: error: Need type annotation for\n\"all_steps\"  [var-annotated]\n            all_steps = [] if return_all_steps else None\n                        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/temporal/diffusion.py:128:17: error: Item \"None\" of\n\"Optional[list[Any]]\" has no attribute \"append\"  [union-attr]\n                    all_steps.append({\n                    ^~~~~~~~~~~~~~~~\nsrc/dgdn/temporal/diffusion.py: note: In class \"DiffusionLayer\":\nsrc/dgdn/temporal/diffusion.py:215:22: error: Class cannot subclass\n\"MessagePassing\" (has type \"Any\")  [misc]\n    class DiffusionLayer(MessagePassing):\n                         ^~~~~~~~~~~~~~\nsrc/dgdn/temporal/diffusion.py: note: In member \"reset_parameters\" of class \"DiffusionLayer\":\nsrc/dgdn/temporal/diffusion.py:266:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def reset_parameters(self):\n        ^\nsrc/dgdn/temporal/diffusion.py:266:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/models/layers.py: note: In class \"MultiHeadTemporalAttention\":\nsrc/dgdn/models/layers.py:12:34: error: Class cannot subclass \"Module\" (has\ntype \"Any\")  [misc]\n    class MultiHeadTemporalAttention(nn.Module):\n                                     ^~~~~~~~~\nsrc/dgdn/models/layers.py: note: In member \"reset_parameters\" of class \"MultiHeadTemporalAttention\":\nsrc/dgdn/models/layers.py:54:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def reset_parameters(self):\n        ^\nsrc/dgdn/models/layers.py:54:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/models/layers.py: note: In class \"DGDNLayer\":\nsrc/dgdn/models/layers.py:136:17: error: Class cannot subclass \"MessagePassing\"\n(has type \"Any\")  [misc]\n    class DGDNLayer(MessagePassing):\n                    ^~~~~~~~~~~~~~\nsrc/dgdn/models/layers.py: note: In class \"GraphNorm\":\nsrc/dgdn/models/layers.py:266:17: error: Class cannot subclass \"Module\" (has\ntype \"Any\")  [misc]\n    class GraphNorm(nn.Module):\n                    ^~~~~~~~~\nsrc/dgdn/models/layers.py: note: In class \"PositionalEncoding\":\nsrc/dgdn/models/layers.py:314:26: error: Class cannot subclass \"Module\" (has\ntype \"Any\")  [misc]\n    class PositionalEncoding(nn.Module):\n                             ^~~~~~~~~\nsrc/dgdn/utils/config.py: note: In class \"SecurityConfig\":\nsrc/dgdn/utils/config.py:57:25: error: Missing type parameters for generic type\n\"list\"  [type-arg]\n        allowed_file_types: list = None\n                            ^\nsrc/dgdn/utils/config.py:57:32: error: Incompatible types in assignment\n(expression has type \"None\", variable has type \"list[Any]\")  [assignment]\n        allowed_file_types: list = None\n                                   ^~~~\nsrc/dgdn/utils/config.py: note: In member \"__post_init__\" of class \"SecurityConfig\":\nsrc/dgdn/utils/config.py:59:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def __post_init__(self):\n        ^\nsrc/dgdn/utils/config.py:59:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/utils/config.py:61:13: error: Statement is unreachable  [unreachable]\n                self.allowed_file_types = ['.pt', '.pth', '.json', '.yaml'...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...\nsrc/dgdn/utils/config.py: note: In member \"from_file\" of class \"DGDNConfig\":\nsrc/dgdn/utils/config.py:111:35: error: Name \"yaml\" is not defined \n[name-defined]\n                        config_dict = yaml.safe_load(f)\n                                      ^~~~\nsrc/dgdn/utils/config.py: note: In member \"save\" of class \"DGDNConfig\":\nsrc/dgdn/utils/config.py:156:21: error: Name \"yaml\" is not defined \n[name-defined]\n                        yaml.dump(config_dict, f, default_flow_style=False...\n                        ^~~~\nsrc/dgdn/utils/config.py: note: In function \"load_config_from_env\":\nsrc/dgdn/utils/config.py:198:19: error: Need type annotation for \"config_dict\" \n[var-annotated]\n        config_dict = {\n                      ^\nsrc/dgdn/utils/config.py:207:48: error: Argument 1 to \"int\" has incompatible\ntype \"Optional[str]\"; expected\n\"Union[str, Buffer, SupportsInt, SupportsIndex, SupportsTrunc]\"  [arg-type]\n            config_dict['model']['node_dim'] = int(os.getenv('DGDN_NODE_DI...\n                                                   ^~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/utils/config.py:209:50: error: Argument 1 to \"int\" has incompatible\ntype \"Optional[str]\"; expected\n\"Union[str, Buffer, SupportsInt, SupportsIndex, SupportsTrunc]\"  [arg-type]\n            config_dict['model']['hidden_dim'] = int(os.getenv('DGDN_HIDDE...\n                                                     ^~~~~~~~~~~~~~~~~~~~~...\nsrc/dgdn/utils/config.py:211:50: error: Argument 1 to \"int\" has incompatible\ntype \"Optional[str]\"; expected\n\"Union[str, Buffer, SupportsInt, SupportsIndex, SupportsTrunc]\"  [arg-type]\n            config_dict['model']['num_layers'] = int(os.getenv('DGDN_NUM_L...\n                                                     ^~~~~~~~~~~~~~~~~~~~~...\nsrc/dgdn/utils/config.py:215:58: error: Argument 1 to \"float\" has incompatible\ntype \"Optional[str]\"; expected\n\"Union[str, Buffer, SupportsFloat, SupportsIndex]\"  [arg-type]\n    ...config_dict['training']['learning_rate'] = float(os.getenv('DGDN_LEARN...\n                                                        ^~~~~~~~~~~~~~~~~~~~~...\nsrc/dgdn/utils/config.py:217:53: error: Argument 1 to \"int\" has incompatible\ntype \"Optional[str]\"; expected\n\"Union[str, Buffer, SupportsInt, SupportsIndex, SupportsTrunc]\"  [arg-type]\n    ...     config_dict['training']['batch_size'] = int(os.getenv('DGDN_BATCH...\n                                                        ^~~~~~~~~~~~~~~~~~~~~...\nsrc/dgdn/utils/config.py:219:49: error: Argument 1 to \"int\" has incompatible\ntype \"Optional[str]\"; expected\n\"Union[str, Buffer, SupportsInt, SupportsIndex, SupportsTrunc]\"  [arg-type]\n            config_dict['training']['epochs'] = int(os.getenv('DGDN_EPOCHS...\n                                                    ^~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/utils/config.py:223:62: error: Item \"None\" of \"Optional[str]\" has no\nattribute \"lower\"  [union-attr]\n    ...ig_dict['security']['enable_input_validation'] = os.getenv('DGDN_ENABL...\n                                                        ^~~~~~~~~~~~~~~~~~~~~...\nsrc/dgdn/utils/config.py: note: In function \"merge_configs\":\nsrc/dgdn/utils/config.py:242:26: error: Missing type parameters for generic\ntype \"dict\"  [type-arg]\n        def deep_merge(base: dict, override: dict) -> dict:\n                             ^\nsrc/dgdn/models/dgdn.py: note: In class \"DynamicGraphDiffusionNet\":\nsrc/dgdn/models/dgdn.py:13:32: error: Class cannot subclass \"Module\" (has type\n\"Any\")  [misc]\n    class DynamicGraphDiffusionNet(nn.Module):\n                                   ^~~~~~~~~\nsrc/dgdn/models/dgdn.py: note: In member \"__init__\" of class \"DynamicGraphDiffusionNet\":\nsrc/dgdn/models/dgdn.py:35:5: error: Function is missing a type annotation for\none or more arguments  [no-untyped-def]\n        def __init__(\n        ^\nsrc/dgdn/models/dgdn.py: note: In member \"reset_parameters\" of class \"DynamicGraphDiffusionNet\":\nsrc/dgdn/models/dgdn.py:132:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def reset_parameters(self):\n        ^\nsrc/dgdn/models/dgdn.py:132:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/models/dgdn.py: note: In member \"forward\" of class \"DynamicGraphDiffusionNet\":\nsrc/dgdn/models/dgdn.py:141:5: error: Function is missing a type annotation for\none or more arguments  [no-untyped-def]\n        def forward(\n        ^\nsrc/dgdn/models/dgdn.py:187:29: error: Need type annotation for\n\"attention_weights\"  [var-annotated]\n            attention_weights = [] if return_attention else None\n                                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/models/dgdn.py:201:17: error: Item \"None\" of \"Optional[list[Any]]\" has\nno attribute \"append\"  [union-attr]\n                    attention_weights.append(layer_output[\"attention_weigh...\n                    ^~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/models/dgdn.py: note: In member \"get_node_embeddings\" of class \"DynamicGraphDiffusionNet\":\nsrc/dgdn/models/dgdn.py:239:5: error: Function is missing a type annotation for\none or more arguments  [no-untyped-def]\n        def get_node_embeddings(\n        ^\nsrc/dgdn/models/dgdn.py: note: In member \"predict_edges\" of class \"DynamicGraphDiffusionNet\":\nsrc/dgdn/models/dgdn.py:265:5: error: Function is missing a type annotation for\none or more arguments  [no-untyped-def]\n        def predict_edges(\n        ^\nsrc/dgdn/models/dgdn.py: note: In member \"predict_nodes\" of class \"DynamicGraphDiffusionNet\":\nsrc/dgdn/models/dgdn.py:301:5: error: Function is missing a type annotation for\none or more arguments  [no-untyped-def]\n        def predict_nodes(\n        ^\nsrc/dgdn/models/dgdn.py: note: In member \"_validate_init_parameters\" of class \"DynamicGraphDiffusionNet\":\nsrc/dgdn/models/dgdn.py:396:5: error: Function is missing a type annotation \n[no-untyped-def]\n        def _validate_init_parameters(self, node_dim, edge_dim, time_dim, ...\n        ^\nsrc/dgdn/models/dgdn.py: note: In member \"_validate_forward_input\" of class \"DynamicGraphDiffusionNet\":\nsrc/dgdn/models/dgdn.py:441:5: error: Function is missing a type annotation \n[no-untyped-def]\n        def _validate_forward_input(self, data):\n        ^\nsrc/dgdn/models/dgdn.py: note: In class \"EdgePredictor\":\nsrc/dgdn/models/dgdn.py:493:21: error: Class cannot subclass \"Module\" (has type\n\"Any\")  [misc]\n    class EdgePredictor(nn.Module):\n                        ^~~~~~~~~\nsrc/dgdn/models/dgdn.py: note: In class \"NodeClassifier\":\nsrc/dgdn/models/dgdn.py:515:22: error: Class cannot subclass \"Module\" (has type\n\"Any\")  [misc]\n    class NodeClassifier(nn.Module):\n                         ^~~~~~~~~\nsrc/dgdn/i18n/translator.py: note: In function \"locale\":\nsrc/dgdn/i18n/translator.py:69:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def locale(self, value: str):\n        ^\nsrc/dgdn/i18n/translator.py: note: In member \"translate\" of class \"DGDNTranslator\":\nsrc/dgdn/i18n/translator.py:77:5: error: Function is missing a type annotation\nfor one or more arguments  [no-untyped-def]\n        def translate(self, key: str, **kwargs) -> str:\n        ^\nsrc/dgdn/i18n/translator.py: note: In member \"t\" of class \"DGDNTranslator\":\nsrc/dgdn/i18n/translator.py:91:5: error: Function is missing a type annotation\nfor one or more arguments  [no-untyped-def]\n        def t(self, key: str, **kwargs) -> str:\n        ^\nsrc/dgdn/i18n/translator.py: note: In member \"get_supported_locales\" of class \"DGDNTranslator\":\nsrc/dgdn/i18n/translator.py:99:40: error: Missing type parameters for generic\ntype \"set\"  [type-arg]\n        def get_supported_locales(self) -> set:\n                                           ^\nsrc/dgdn/i18n/translator.py: note: In member \"pluralize\" of class \"DGDNTranslator\":\nsrc/dgdn/i18n/translator.py:134:5: error: Function is missing a type annotation\nfor one or more arguments  [no-untyped-def]\n        def pluralize(self, key: str, count: int, **kwargs) -> str:\n        ^\nsrc/dgdn/i18n/translator.py: note: In function \"set_global_locale\":\nsrc/dgdn/i18n/translator.py:156:1: error: Function is missing a return type\nannotation  [no-untyped-def]\n    def set_global_locale(locale: str):\n    ^\nsrc/dgdn/i18n/translator.py: note: In function \"_\":\nsrc/dgdn/i18n/translator.py:168:1: error: Function is missing a type annotation\nfor one or more arguments  [no-untyped-def]\n    def _(key: str, **kwargs) -> str:\n    ^\nsrc/dgdn/i18n/translator.py: note: In function \"ngettext\":\nsrc/dgdn/i18n/translator.py:173:1: error: Function is missing a type annotation\nfor one or more arguments  [no-untyped-def]\n    def ngettext(singular_key: str, plural_key: str, n: int, **kwargs) -> ...\n    ^\nsrc/dgdn/i18n/translator.py: note: In function \"demonstrate_i18n\":\nsrc/dgdn/i18n/translator.py:204:1: error: Function is missing a return type\nannotation  [no-untyped-def]\n    def demonstrate_i18n():\n    ^\nsrc/dgdn/i18n/translator.py:204:1: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/utils/logging.py: note: In function \"log_model_info\":\nsrc/dgdn/utils/logging.py:117:1: error: Function is missing a type annotation\nfor one or more arguments  [no-untyped-def]\n    def log_model_info(model, logger: Optional[logging.Logger] = None) -> ...\n    ^\nsrc/dgdn/utils/logging.py: note: In member \"log_training_start\" of class \"TrainingLogger\":\nsrc/dgdn/utils/logging.py:155:27: error: Incompatible types in assignment\n(expression has type \"float\", variable has type \"None\")  [assignment]\n            self.start_time = time.time()\n                              ^~~~~~~~~~~\nsrc/dgdn/utils/logging.py: note: In member \"log_epoch_start\" of class \"TrainingLogger\":\nsrc/dgdn/utils/logging.py:165:33: error: Incompatible types in assignment\n(expression has type \"float\", variable has type \"None\")  [assignment]\n            self.epoch_start_time = time.time()\n                                    ^~~~~~~~~~~\nsrc/dgdn/utils/logging.py: note: In member \"__init__\" of class \"PerformanceLogger\":\nsrc/dgdn/utils/logging.py:211:9: error: Need type annotation for \"timers\"\n(hint: \"timers: dict[<type>, <type>] = ...\")  [var-annotated]\n            self.timers = {}\n            ^~~~~~~~~~~\nsrc/dgdn/utils/logging.py: note: In member \"end_timer\" of class \"PerformanceLogger\":\nsrc/dgdn/utils/logging.py:229:9: error: Returning Any from function declared to\nreturn \"float\"  [no-any-return]\n            return elapsed\n            ^~~~~~~~~~~~~~\nsrc/dgdn/optimization/memory.py: note: In member \"optimize_batch_size\" of class \"MemoryOptimizer\":\nsrc/dgdn/optimization/memory.py:24:5: error: Function is missing a type\nannotation for one or more arguments  [no-untyped-def]\n        def optimize_batch_size(self, initial_batch_size: int, model: nn.M...\n        ^\nsrc/dgdn/optimization/memory.py: note: In member \"_test_memory_usage\" of class \"MemoryOptimizer\":\nsrc/dgdn/optimization/memory.py:58:5: error: Function is missing a type\nannotation for one or more arguments  [no-untyped-def]\n        def _test_memory_usage(self, batch_size: int, model: nn.Module, \n        ^\nsrc/dgdn/optimization/memory.py:78:21: error: Returning Any from function\ndeclared to return \"bool\"  [no-any-return]\n                        return usage_fraction < self.threshold_gb\n                        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/optimization/memory.py: note: In member \"_expand_batch\" of class \"MemoryOptimizer\":\nsrc/dgdn/optimization/memory.py:91:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def _expand_batch(self, sample_data, target_batch_size: int):\n        ^\nsrc/dgdn/optimization/memory.py:91:5: error: Function is missing a type\nannotation for one or more arguments  [no-untyped-def]\n        def _expand_batch(self, sample_data, target_batch_size: int):\n        ^\nsrc/dgdn/optimization/memory.py: note: In member \"cleanup_memory\" of class \"MemoryOptimizer\":\nsrc/dgdn/optimization/memory.py:142:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def cleanup_memory(self):\n        ^\nsrc/dgdn/optimization/memory.py:142:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/optimization/memory.py: note: In member \"enable_checkpointing\" of class \"GradientCheckpointing\":\nsrc/dgdn/optimization/memory.py:164:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def enable_checkpointing(self):\n        ^\nsrc/dgdn/optimization/memory.py:164:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/optimization/memory.py: note: In member \"_checkpoint_wrapper\" of class \"GradientCheckpointing\":\nsrc/dgdn/optimization/memory.py:173:47: error: Missing type parameters for\ngeneric type \"Callable\"  [type-arg]\n        def _checkpoint_wrapper(self, forward_fn: Callable) -> Callable:\n                                                  ^\nsrc/dgdn/optimization/memory.py: note: In function \"_checkpoint_wrapper\":\nsrc/dgdn/optimization/memory.py:175:9: error: Function is missing a type\nannotation  [no-untyped-def]\n            def checkpointed_forward(*args, **kwargs):\n            ^\nsrc/dgdn/optimization/memory.py: note: In member \"setup_data_parallel\" of class \"DataParallelOptimizer\":\nsrc/dgdn/optimization/memory.py:208:56: error: Missing type parameters for\ngeneric type \"list\"  [type-arg]\n    ...f setup_data_parallel(self, device_ids: Optional[list] = None) -> nn.M...\n                                                        ^\nsrc/dgdn/optimization/memory.py: note: In member \"optimize_for_multi_gpu\" of class \"DataParallelOptimizer\":\nsrc/dgdn/optimization/memory.py:229:53: error: Incompatible types in assignment\n(expression has type \"int\", target has type \"bool\")  [assignment]\n    ...         recommendations['optimal_batch_size'] = self._calculate_optim...\n                                                        ^~~~~~~~~~~~~~~~~~~~~...\nsrc/dgdn/optimization/memory.py:230:62: error: Incompatible types in assignment\n(expression has type \"int\", target has type \"bool\")  [assignment]\n    ...recommendations['gradient_accumulation_steps'] = self._calculate_gradi...\n                                                        ^~~~~~~~~~~~~~~~~~~~~...\nsrc/dgdn/optimization/memory.py:233:59: error: Incompatible types in assignment\n(expression has type \"list[str]\", target has type \"bool\")  [assignment]\n                recommendations['single_gpu_optimizations'] = [\n                                                              ^\nsrc/dgdn/optimization/memory.py: note: In member \"_calculate_optimal_batch_size\" of class \"DataParallelOptimizer\":\nsrc/dgdn/optimization/memory.py:247:9: error: Returning Any from function\ndeclared to return \"int\"  [no-any-return]\n            return base_batch_size * num_gpus\n            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/optimization/caching.py: note: In member \"__init__\" of class \"EmbeddingCache\":\nsrc/dgdn/optimization/caching.py:25:9: error: Need type annotation for \"cache\" \n[var-annotated]\n            self.cache = OrderedDict()\n            ^~~~~~~~~~\nsrc/dgdn/optimization/caching.py:26:9: error: Need type annotation for\n\"access_times\" (hint: \"access_times: dict[<type>, <type>] = ...\") \n[var-annotated]\n            self.access_times = {}\n            ^~~~~~~~~~~~~~~~~\nsrc/dgdn/optimization/caching.py: note: In member \"get\" of class \"EmbeddingCache\":\nsrc/dgdn/optimization/caching.py:61:38: error: \"float\" has no attribute \"time\" \n[attr-defined]\n                self.access_times[key] = time.time()\n                                         ^~~~~~~~~\nsrc/dgdn/optimization/caching.py: note: In member \"put\" of class \"EmbeddingCache\":\nsrc/dgdn/optimization/caching.py:68:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def put(self, node_ids: torch.Tensor, time: float, embeddings: tor...\n        ^\nsrc/dgdn/optimization/caching.py:81:34: error: \"float\" has no attribute \"time\" \n[attr-defined]\n            self.access_times[key] = time.time()\n                                     ^~~~~~~~~\nsrc/dgdn/optimization/caching.py: note: In member \"_evict_key\" of class \"EmbeddingCache\":\nsrc/dgdn/optimization/caching.py:83:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def _evict_key(self, key: str):\n        ^\nsrc/dgdn/optimization/caching.py: note: In member \"clear\" of class \"EmbeddingCache\":\nsrc/dgdn/optimization/caching.py:90:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def clear(self):\n        ^\nsrc/dgdn/optimization/caching.py:90:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/optimization/caching.py: note: In member \"cleanup_expired\" of class \"EmbeddingCache\":\nsrc/dgdn/optimization/caching.py:118:5: error: Function is missing a return\ntype annotation  [no-untyped-def]\n        def cleanup_expired(self):\n        ^\nsrc/dgdn/optimization/caching.py:118:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/optimization/caching.py: note: In member \"__init__\" of class \"AttentionCache\":\nsrc/dgdn/optimization/caching.py:144:9: error: Need type annotation for \"cache\"\n [var-annotated]\n            self.cache = OrderedDict()\n            ^~~~~~~~~~\nsrc/dgdn/optimization/caching.py: note: In member \"store_attention\" of class \"AttentionCache\":\nsrc/dgdn/optimization/caching.py:168:5: error: Function is missing a return\ntype annotation  [no-untyped-def]\n        def store_attention(self, edge_index: torch.Tensor, \n        ^\nsrc/dgdn/optimization/caching.py: note: In member \"__init__\" of class \"ComputationCache\":\nsrc/dgdn/optimization/caching.py:191:9: error: Need type annotation for \"cache\"\n(hint: \"cache: dict[<type>, <type>] = ...\")  [var-annotated]\n            self.cache = {}\n            ^~~~~~~~~~\nsrc/dgdn/optimization/caching.py:193:9: error: Need type annotation for\n\"access_order\"  [var-annotated]\n            self.access_order = OrderedDict()\n            ^~~~~~~~~~~~~~~~~\nsrc/dgdn/optimization/caching.py: note: In member \"_estimate_size\" of class \"ComputationCache\":\nsrc/dgdn/optimization/caching.py:199:13: error: Returning Any from function\ndeclared to return \"int\"  [no-any-return]\n                return obj.numel() * obj.element_size()\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/optimization/caching.py: note: In member \"_make_key\" of class \"ComputationCache\":\nsrc/dgdn/optimization/caching.py:206:47: error: Missing type parameters for\ngeneric type \"Tuple\"  [type-arg]\n        def _make_key(self, func_name: str, args: Tuple, kwargs: Dict) -> ...\n                                                  ^\nsrc/dgdn/optimization/caching.py:206:62: error: Missing type parameters for\ngeneric type \"Dict\"  [type-arg]\n    ...def _make_key(self, func_name: str, args: Tuple, kwargs: Dict) -> str:\n                                                                ^\nsrc/dgdn/optimization/caching.py: note: In function \"_make_key\":\nsrc/dgdn/optimization/caching.py:209:9: error: Function is missing a type\nannotation  [no-untyped-def]\n            def tensorize_args(obj):\n            ^\nsrc/dgdn/optimization/caching.py: note: In member \"get\" of class \"ComputationCache\":\nsrc/dgdn/optimization/caching.py:225:41: error: Missing type parameters for\ngeneric type \"Tuple\"  [type-arg]\n        def get(self, func_name: str, args: Tuple, kwargs: Dict) -> Tuple[...\n                                            ^\nsrc/dgdn/optimization/caching.py:225:56: error: Missing type parameters for\ngeneric type \"Dict\"  [type-arg]\n    ...f get(self, func_name: str, args: Tuple, kwargs: Dict) -> Tuple[bool, ...\n                                                        ^\nsrc/dgdn/optimization/caching.py: note: In member \"put\" of class \"ComputationCache\":\nsrc/dgdn/optimization/caching.py:236:5: error: Function is missing a return\ntype annotation  [no-untyped-def]\n        def put(self, func_name: str, args: Tuple, kwargs: Dict, result: A...\n        ^\nsrc/dgdn/optimization/caching.py:236:41: error: Missing type parameters for\ngeneric type \"Tuple\"  [type-arg]\n        def put(self, func_name: str, args: Tuple, kwargs: Dict, result: A...\n                                            ^\nsrc/dgdn/optimization/caching.py:236:56: error: Missing type parameters for\ngeneric type \"Dict\"  [type-arg]\n    ...def put(self, func_name: str, args: Tuple, kwargs: Dict, result: Any):\n                                                          ^\nsrc/dgdn/optimization/caching.py: note: In member \"_evict_oldest\" of class \"ComputationCache\":\nsrc/dgdn/optimization/caching.py:251:5: error: Function is missing a return\ntype annotation  [no-untyped-def]\n        def _evict_oldest(self):\n        ^\nsrc/dgdn/optimization/caching.py:251:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/optimization/caching.py: note: In function \"cached_computation\":\nsrc/dgdn/optimization/caching.py:261:1: error: Function is missing a return\ntype annotation  [no-untyped-def]\n    def cached_computation(cache: ComputationCache, func_name: str):\n    ^\nsrc/dgdn/optimization/caching.py:263:5: error: Function is missing a type\nannotation  [no-untyped-def]\n        def decorator(func):\n        ^\nsrc/dgdn/optimization/caching.py:264:9: error: Function is missing a type\nannotation  [no-untyped-def]\n            def wrapper(*args, **kwargs):\n            ^\nsrc/dgdn/optimization/caching.py: note: In member \"clear_all\" of class \"CacheManager\":\nsrc/dgdn/optimization/caching.py:310:5: error: Function is missing a return\ntype annotation  [no-untyped-def]\n        def clear_all(self):\n        ^\nsrc/dgdn/optimization/caching.py:310:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/optimization/caching.py: note: In member \"optimize_cache_sizes\" of class \"CacheManager\":\nsrc/dgdn/optimization/caching.py:336:5: error: Function is missing a return\ntype annotation  [no-untyped-def]\n        def optimize_cache_sizes(self, memory_budget_mb: float):\n        ^\nsrc/dgdn/deployment/region_manager.py: note: In member \"__init__\" of class \"RegionManager\":\nsrc/dgdn/deployment/region_manager.py:32:5: error: Function is missing a return\ntype annotation  [no-untyped-def]\n        def __init__(self):\n        ^\nsrc/dgdn/deployment/region_manager.py:32:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/deployment/region_manager.py: note: In member \"_initialize_region_health\" of class \"RegionManager\":\nsrc/dgdn/deployment/region_manager.py:93:5: error: Function is missing a return\ntype annotation  [no-untyped-def]\n        def _initialize_region_health(self):\n        ^\nsrc/dgdn/deployment/region_manager.py:93:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/deployment/region_manager.py: note: In member \"get_optimal_region\" of class \"RegionManager\":\nsrc/dgdn/deployment/region_manager.py:138:20: error: Unsupported right operand\ntype for in (\"object\")  [operator]\n                    if language_preference in config[\"supported_languages\"...\n                       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py:154:29: error: Value of type \"object\" is\nnot indexable  [index]\n                cpu_available = capacity[\"cpu\"] * (1 - health.get(\"cpu_usa...\n                                ^~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py:155:32: error: Value of type \"object\" is\nnot indexable  [index]\n                memory_available = capacity[\"memory\"] * (1 - health.get(\"m...\n                                   ^~~~~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py:164:47: error: Argument \"key\" to \"max\"\nhas incompatible type overloaded function; expected\n\"Callable[[DeploymentRegion], Union[SupportsDunderLT[Any], SupportsDunderGT[Any]]]\"\n [arg-type]\n                optimal_region = max(scoring, key=scoring.get)\n                                                  ^~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py: note: In member \"deploy_to_region\" of class \"RegionManager\":\nsrc/dgdn/deployment/region_manager.py:186:26: error: \"object\" has no attribute\n\"copy\"  [attr-defined]\n                \"endpoints\": region_config[\"endpoints\"].copy(),\n                             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py:199:39: error: Value of type \"object\" is\nnot indexable  [index]\n                    \"health_check_url\": f\"{region_config['endpoints']['api...\n                                          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py: note: In member \"update_region_health\" of class \"RegionManager\":\nsrc/dgdn/deployment/region_manager.py:310:5: error: Function is missing a\nreturn type annotation  [no-untyped-def]\n        def update_region_health(self, region: DeploymentRegion, health_me...\n        ^\nsrc/dgdn/deployment/region_manager.py: note: In member \"scale_region\" of class \"RegionManager\":\nsrc/dgdn/deployment/region_manager.py:341:24: error: Value of type \"object\" is\nnot indexable  [index]\n                \"cpu\": int(current_capacity[\"cpu\"] * scale_factor),\n                           ^~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py:342:27: error: Value of type \"object\" is\nnot indexable  [index]\n                \"memory\": int(current_capacity[\"memory\"] * scale_factor),\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py:343:28: error: Value of type \"object\" is\nnot indexable  [index]\n                \"storage\": int(current_capacity[\"storage\"] * scale_factor)\n                               ^~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py: note: In member \"get_deployment_status\" of class \"RegionManager\":\nsrc/dgdn/deployment/region_manager.py:369:24: error: Value of type \"object\" is\nnot indexable  [index]\n                \"cpu\": sum(config[\"capacity\"][\"cpu\"] for config in self.re...\n                           ^~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py:370:27: error: Value of type \"object\" is\nnot indexable  [index]\n                \"memory\": sum(config[\"capacity\"][\"memory\"] for config in s...\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py:371:28: error: Value of type \"object\" is\nnot indexable  [index]\n                \"storage\": sum(config[\"capacity\"][\"storage\"] for config in...\n                               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py:386:29: error: \"object\" has no attribute\n\"__iter__\"; maybe \"__dir__\" or \"__str__\"? (not iterable)  [attr-defined]\n                    for lang in config[\"supported_languages\"]\n                                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py: note: In member \"get_region_recommendations\" of class \"RegionManager\":\nsrc/dgdn/deployment/region_manager.py:415:21: error: Unsupported operand types\nfor + (\"object\" and \"int\")  [operator]\n                        recommendation[\"score\"] += 50\n                        ^\nsrc/dgdn/deployment/region_manager.py:416:21: error: \"object\" has no attribute\n\"append\"  [attr-defined]\n                        recommendation[\"reasons\"].append(\"Geographic proxi...\n                        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py:418:21: error: Unsupported operand types\nfor + (\"object\" and \"int\")  [operator]\n                        recommendation[\"score\"] += 50\n                        ^\nsrc/dgdn/deployment/region_manager.py:419:21: error: \"object\" has no attribute\n\"append\"  [attr-defined]\n                        recommendation[\"reasons\"].append(\"Geographic proxi...\n                        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py:421:21: error: Unsupported operand types\nfor + (\"object\" and \"int\")  [operator]\n                        recommendation[\"score\"] += 50\n                        ^\nsrc/dgdn/deployment/region_manager.py:422:21: error: \"object\" has no attribute\n\"append\"  [attr-defined]\n                        recommendation[\"reasons\"].append(\"Geographic proxi...\n                        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py:425:16: error: Unsupported right operand\ntype for in (\"object\")  [operator]\n                if user_language in config[\"supported_languages\"]:\n                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py:426:17: error: Unsupported operand types\nfor + (\"object\" and \"int\")  [operator]\n                    recommendation[\"score\"] += 20\n                    ^\nsrc/dgdn/deployment/region_manager.py:427:17: error: \"object\" has no attribute\n\"append\"  [attr-defined]\n                    recommendation[\"reasons\"].append(f\"Supports {user_lang...\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py:431:17: error: Unsupported operand types\nfor + (\"object\" and \"int\")  [operator]\n                    recommendation[\"score\"] += 30\n                    ^\nsrc/dgdn/deployment/region_manager.py:432:17: error: \"object\" has no attribute\n\"append\"  [attr-defined]\n                    recommendation[\"reasons\"].append(f\"{config['compliance...\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py:432:53: error: \"object\" has no attribute\n\"upper\"  [attr-defined]\n    ...             recommendation[\"reasons\"].append(f\"{config['compliance_re...\n                                                        ^~~~~~~~~~~~~~~~~~~~~...\nsrc/dgdn/deployment/region_manager.py:437:17: error: Unsupported operand types\nfor + (\"object\" and \"int\")  [operator]\n                    recommendation[\"score\"] += 10\n                    ^\nsrc/dgdn/deployment/region_manager.py:438:17: error: \"object\" has no attribute\n\"append\"  [attr-defined]\n                    recommendation[\"reasons\"].append(\"Healthy region statu...\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/deployment/region_manager.py:443:34: error: Argument \"key\" to \"sort\"\nof \"list\" has incompatible type \"Callable[[dict[str, object]], object]\";\nexpected\n\"Callable[[dict[str, object]], Union[SupportsDunderLT[Any], SupportsDunderGT[Any]]]\"\n [arg-type]\n            recommendations.sort(key=lambda x: x[\"score\"], reverse=True)\n                                     ^\nsrc/dgdn/deployment/region_manager.py: note: In function \"get_region_recommendations\":\nsrc/dgdn/deployment/region_manager.py:443:44: error: Incompatible return value\ntype (got \"object\", expected\n\"Union[SupportsDunderLT[Any], SupportsDunderGT[Any]]\")  [return-value]\n            recommendations.sort(key=lambda x: x[\"score\"], reverse=True)\n                                               ^~~~~~~~~~\nsrc/dgdn/compliance/pdpa.py: note: In member \"__init__\" of class \"PDPACompliance\":\nsrc/dgdn/compliance/pdpa.py:28:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def __init__(self):\n        ^\nsrc/dgdn/compliance/pdpa.py:28:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/compliance/pdpa.py: note: In member \"check_processing_lawfulness\" of class \"PDPACompliance\":\nsrc/dgdn/compliance/pdpa.py:65:17: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                    lawfulness_check['legal_basis'].append(PDPAConsentBasi...\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/pdpa.py:67:17: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                    lawfulness_check['required_actions'].append('obtain_ex...\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/pdpa.py:74:17: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                    lawfulness_check['legal_basis'].append('research_excep...\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/pdpa.py:75:17: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                    lawfulness_check['required_actions'].append('ensure_re...\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/pdpa.py:78:17: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                    lawfulness_check['legal_basis'].append(PDPAConsentBasi...\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/pdpa.py:80:17: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                    lawfulness_check['required_actions'].append('obtain_co...\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/pdpa.py:86:17: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                    lawfulness_check['legal_basis'].append(PDPAConsentBasi...\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/pdpa.py:89:17: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                    lawfulness_check['legal_basis'].append(PDPAConsentBasi...\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/pdpa.py:90:17: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                    lawfulness_check['required_actions'].append('conduct_l...\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/pdpa.py:92:17: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                    lawfulness_check['required_actions'].append('obtain_co...\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/pdpa.py:96:13: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                lawfulness_check['required_actions'].append('ensure_purpos...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/pdpa.py:100:13: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                lawfulness_check['required_actions'].append('apply_data_mi...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/pdpa.py: note: In member \"record_consent\" of class \"PDPACompliance\":\nsrc/dgdn/compliance/pdpa.py:105:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def record_consent(self, consent_record: Dict[str, Any]):\n        ^\nsrc/dgdn/compliance/gdpr.py: note: In member \"__init__\" of class \"GDPRCompliance\":\nsrc/dgdn/compliance/gdpr.py:29:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def __init__(self):\n        ^\nsrc/dgdn/compliance/gdpr.py:29:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/compliance/gdpr.py: note: In member \"check_processing_lawfulness\" of class \"GDPRCompliance\":\nsrc/dgdn/compliance/gdpr.py:60:17: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                    lawfulness_check['legal_basis'].append(GDPRLegalBasis....\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/gdpr.py:62:17: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                    lawfulness_check['required_actions'].append('obtain_ex...\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/gdpr.py:68:13: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                lawfulness_check['legal_basis'].append(GDPRLegalBasis.LEGI...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/gdpr.py:69:13: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                lawfulness_check['required_actions'].append('conduct_balan...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/gdpr.py:70:13: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                lawfulness_check['required_actions'].append('implement_saf...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/gdpr.py:75:13: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                lawfulness_check['legal_basis'].append(GDPRLegalBasis.LEGI...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/gdpr.py:76:13: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                lawfulness_check['required_actions'].append('provide_opt_o...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/gdpr.py:82:17: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                    lawfulness_check['legal_basis'].append(GDPRLegalBasis....\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/gdpr.py:84:17: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                    lawfulness_check['required_actions'].append('obtain_co...\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/gdpr.py:88:13: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                lawfulness_check['required_actions'].append('apply_data_mi...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/gdpr.py:92:13: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                lawfulness_check['required_actions'].append('review_retent...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/gdpr.py: note: In member \"record_consent\" of class \"GDPRCompliance\":\nsrc/dgdn/compliance/gdpr.py:97:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def record_consent(self, consent_record: Dict[str, Any]):\n        ^\nsrc/dgdn/compliance/data_protection.py: note: In member \"__init__\" of class \"DataProtectionManager\":\nsrc/dgdn/compliance/data_protection.py:30:80: error: Incompatible default for\nargument \"compliance_regimes\" (default has type \"None\", argument has type\n\"list[str]\")  [assignment]\n    ..._(self, region: str = \"global\", compliance_regimes: List[str] = None):\n                                                                       ^~~~\nsrc/dgdn/compliance/data_protection.py:30:80: note: PEP 484 prohibits implicit Optional. Accordingly, mypy has changed its default to no_implicit_optional=True\nsrc/dgdn/compliance/data_protection.py:30:80: note: Use https://github.com/hauntsaninja/no_implicit_optional to automatically upgrade your codebase\nsrc/dgdn/compliance/data_protection.py:43:9: error: Need type annotation for\n\"audit_log\" (hint: \"audit_log: list[<type>] = ...\")  [var-annotated]\n            self.audit_log = []\n            ^~~~~~~~~~~~~~\nsrc/dgdn/compliance/data_protection.py: note: In member \"classify_data_protection_level\" of class \"DataProtectionManager\":\nsrc/dgdn/compliance/data_protection.py:97:83: error: Incompatible default for\nargument \"context\" (default has type \"None\", argument has type \"dict[str, Any]\")\n [assignment]\n    ...level(self, data: Any, context: Dict[str, Any] = None) -> DataProtecti...\n                                                        ^~~~\nsrc/dgdn/compliance/data_protection.py:97:83: note: PEP 484 prohibits implicit Optional. Accordingly, mypy has changed its default to no_implicit_optional=True\nsrc/dgdn/compliance/data_protection.py:97:83: note: Use https://github.com/hauntsaninja/no_implicit_optional to automatically upgrade your codebase\nsrc/dgdn/compliance/data_protection.py: note: In member \"check_cross_border_transfer_compliance\" of class \"DataProtectionManager\":\nsrc/dgdn/compliance/data_protection.py:322:13: error: \"object\" has no attribute\n\"append\"  [attr-defined]\n                compliance_check[\"requirements\"].append(\"adequacy_decision...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/data_protection.py:333:17: error: \"object\" has no attribute\n\"extend\"  [attr-defined]\n                    compliance_check[\"safeguards_needed\"].extend([\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/data_protection.py:341:13: error: \"object\" has no attribute\n\"extend\"  [attr-defined]\n                compliance_check[\"safeguards_needed\"].extend([\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/data_protection.py: note: In member \"_log_audit_event\" of class \"DataProtectionManager\":\nsrc/dgdn/compliance/data_protection.py:413:5: error: Function is missing a\nreturn type annotation  [no-untyped-def]\n        def _log_audit_event(self, event_type: str, details: Dict[str, Any...\n        ^\nsrc/dgdn/compliance/data_protection.py: note: In member \"validate_compliance_configuration\" of class \"DataProtectionManager\":\nsrc/dgdn/compliance/data_protection.py:453:13: error: \"object\" has no attribute\n\"append\"  [attr-defined]\n                validation_results[\"warnings\"].append(f\"No specific policy...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/data_protection.py:457:13: error: \"object\" has no attribute\n\"append\"  [attr-defined]\n                validation_results[\"errors\"].append(\"Encryption system not...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/data_protection.py:464:17: error: \"object\" has no attribute\n\"append\"  [attr-defined]\n                    validation_results[\"warnings\"].append(f\"Compliance reg...\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/data_protection.py:467:9: error: \"object\" has no attribute\n\"extend\"  [attr-defined]\n            validation_results[\"recommendations\"].extend([\n            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/ccpa.py: note: In member \"__init__\" of class \"CCPACompliance\":\nsrc/dgdn/compliance/ccpa.py:38:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def __init__(self):\n        ^\nsrc/dgdn/compliance/ccpa.py:38:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/compliance/ccpa.py: note: In member \"check_processing_lawfulness\" of class \"CCPACompliance\":\nsrc/dgdn/compliance/ccpa.py:69:13: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                lawfulness_check['legal_basis'].append(ccpa_purpose.value)\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/ccpa.py:71:13: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                lawfulness_check['legal_basis'].append('business_purpose_o...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/ccpa.py:78:17: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                    lawfulness_check['required_actions'].append('honor_opt...\n                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/ccpa.py:82:13: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                lawfulness_check['required_actions'].append('update_privac...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/ccpa.py:86:13: error: \"object\" has no attribute \"append\" \n[attr-defined]\n                lawfulness_check['required_actions'].append('limit_sensiti...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/utils/monitoring.py: note: In member \"__init__\" of class \"PerformanceProfiler\":\nsrc/dgdn/utils/monitoring.py:40:9: error: Need type annotation for\n\"operation_stats\"  [var-annotated]\n            self.operation_stats = defaultdict(list)\n            ^~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/utils/monitoring.py: note: In member \"get_summary\" of class \"PerformanceProfiler\":\nsrc/dgdn/utils/monitoring.py:131:13: error: Unsupported target for indexed\nassignment (\"object\")  [index]\n                summary['operations'][op_name] = self.get_operation_stats(...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/utils/monitoring.py:136:13: error: Unsupported target for indexed\nassignment (\"object\")  [index]\n                summary['memory_stats']['cpu_memory_mb'] = {\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/utils/monitoring.py:145:21: error: Unsupported target for indexed\nassignment (\"object\")  [index]\n                        summary['memory_stats']['gpu_memory_mb'] = {\n                        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/utils/monitoring.py: note: In member \"__init__\" of class \"ModelMonitor\":\nsrc/dgdn/utils/monitoring.py:173:5: error: Function is missing a type\nannotation for one or more arguments  [no-untyped-def]\n        def __init__(self, model, monitor_gradients: bool = True):\n        ^\nsrc/dgdn/utils/monitoring.py:178:9: error: Need type annotation for\n\"parameter_stats\" (hint: \"parameter_stats: dict[<type>, <type>] = ...\") \n[var-annotated]\n            self.parameter_stats = {}\n            ^~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/utils/monitoring.py:179:9: error: Need type annotation for\n\"gradient_stats\" (hint: \"gradient_stats: dict[<type>, <type>] = ...\") \n[var-annotated]\n            self.gradient_stats = {}\n            ^~~~~~~~~~~~~~~~~~~\nsrc/dgdn/utils/monitoring.py:180:9: error: Need type annotation for\n\"activation_stats\" (hint: \"activation_stats: dict[<type>, <type>] = ...\") \n[var-annotated]\n            self.activation_stats = {}\n            ^~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/utils/monitoring.py:181:9: error: Need type annotation for \"hooks\"\n(hint: \"hooks: list[<type>] = ...\")  [var-annotated]\n            self.hooks = []\n            ^~~~~~~~~~\nsrc/dgdn/utils/monitoring.py: note: In function \"_register_gradient_hooks\":\nsrc/dgdn/utils/monitoring.py:188:9: error: Function is missing a type\nannotation  [no-untyped-def]\n            def gradient_hook(name):\n            ^\nsrc/dgdn/utils/monitoring.py:189:13: error: Function is missing a type\nannotation  [no-untyped-def]\n                def hook(grad):\n                ^\nsrc/dgdn/utils/monitoring.py: note: In member \"__init__\" of class \"TrainingMonitor\":\nsrc/dgdn/utils/monitoring.py:283:29: error: Need type annotation for\n\"train_losses\"  [var-annotated]\n            self.train_losses = deque(maxlen=1000)\n                                ^~~~~~~~~~~~~~~~~~\nsrc/dgdn/utils/monitoring.py:284:27: error: Need type annotation for\n\"val_losses\"  [var-annotated]\n            self.val_losses = deque(maxlen=1000)\n                              ^~~~~~~~~~~~~~~~~~\nsrc/dgdn/utils/monitoring.py:285:31: error: Need type annotation for\n\"learning_rates\"  [var-annotated]\n            self.learning_rates = deque(maxlen=1000)\n                                  ^~~~~~~~~~~~~~~~~~\nsrc/dgdn/utils/monitoring.py:291:9: error: Need type annotation for\n\"loss_history\" (hint: \"loss_history: list[<type>] = ...\")  [var-annotated]\n            self.loss_history = []\n            ^~~~~~~~~~~~~~~~~\nsrc/dgdn/utils/monitoring.py:292:9: error: Need type annotation for\n\"metrics_history\" (hint: \"metrics_history: list[<type>] = ...\")  [var-annotated]\n            self.metrics_history = []\n            ^~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/utils/monitoring.py: note: In member \"detect_training_issues\" of class \"TrainingMonitor\":\nsrc/dgdn/utils/monitoring.py:338:9: error: Need type annotation for \"issues\"\n(hint: \"issues: list[<type>] = ...\")  [var-annotated]\n            issues = []\n            ^~~~~~\nsrc/dgdn/utils/monitoring.py: note: In member \"__init__\" of class \"SystemMonitor\":\nsrc/dgdn/utils/monitoring.py:406:9: error: Need type annotation for \"metrics\"\n(hint: \"metrics: list[<type>] = ...\")  [var-annotated]\n            self.metrics = []\n            ^~~~~~~~~~~~\nsrc/dgdn/utils/monitoring.py: note: In member \"start_monitoring\" of class \"SystemMonitor\":\nsrc/dgdn/utils/monitoring.py:415:31: error: Incompatible types in assignment\n(expression has type \"Thread\", variable has type \"None\")  [assignment]\n            self.monitor_thread = threading.Thread(target=self._monitor_lo...\n                                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...\nsrc/dgdn/utils/monitoring.py:416:9: error: \"None\" has no attribute \"start\" \n[attr-defined]\n            self.monitor_thread.start()\n            ^~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/utils/monitoring.py: note: In member \"stop_monitoring\" of class \"SystemMonitor\":\nsrc/dgdn/utils/monitoring.py:423:13: error: Statement is unreachable \n[unreachable]\n                self.monitor_thread.join(timeout=2.0)\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/utils/monitoring.py: note: In member \"get_current_metrics\" of class \"SystemMonitor\":\nsrc/dgdn/utils/monitoring.py:465:9: error: Returning Any from function declared\nto return \"dict[str, Any]\"  [no-any-return]\n            return self.metrics[-1].copy()\n            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/privacy_manager.py: note: In member \"__init__\" of class \"PrivacyManager\":\nsrc/dgdn/compliance/privacy_manager.py:46:62: error: Incompatible default for\nargument \"active_regimes\" (default has type \"None\", argument has type\n\"list[PrivacyRegime]\")  [assignment]\n        def __init__(self, active_regimes: List[PrivacyRegime] = None):\n                                                                 ^~~~\nsrc/dgdn/compliance/privacy_manager.py:46:62: note: PEP 484 prohibits implicit Optional. Accordingly, mypy has changed its default to no_implicit_optional=True\nsrc/dgdn/compliance/privacy_manager.py:46:62: note: Use https://github.com/hauntsaninja/no_implicit_optional to automatically upgrade your codebase\nsrc/dgdn/compliance/privacy_manager.py:56:59: error: Incompatible types in\nassignment (expression has type \"CCPACompliance\", target has type\n\"GDPRCompliance\")  [assignment]\n    ...        self.compliance_systems[PrivacyRegime.CCPA] = CCPACompliance()\n                                                             ^~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/privacy_manager.py:58:59: error: Incompatible types in\nassignment (expression has type \"PDPACompliance\", target has type\n\"GDPRCompliance\")  [assignment]\n    ...        self.compliance_systems[PrivacyRegime.PDPA] = PDPACompliance()\n                                                             ^~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/privacy_manager.py:61:9: error: Need type annotation for\n\"processing_records\" (hint: \"processing_records: list[<type>] = ...\") \n[var-annotated]\n            self.processing_records = []\n            ^~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/privacy_manager.py:62:9: error: Need type annotation for\n\"consent_records\" (hint: \"consent_records: dict[<type>, <type>] = ...\") \n[var-annotated]\n            self.consent_records = {}\n            ^~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/privacy_manager.py:63:9: error: Need type annotation for\n\"data_minimization_policies\" (hint:\n\"data_minimization_policies: dict[<type>, <type>] = ...\")  [var-annotated]\n            self.data_minimization_policies = {}\n            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/privacy_manager.py: note: In member \"classify_data\" of class \"PrivacyManager\":\nsrc/dgdn/compliance/privacy_manager.py:67:66: error: Incompatible default for\nargument \"context\" (default has type \"None\", argument has type \"dict[str, Any]\")\n [assignment]\n    ..._data(self, data: Any, context: Dict[str, Any] = None) -> Dict[str, An...\n                                                        ^~~~\nsrc/dgdn/compliance/privacy_manager.py:67:66: note: PEP 484 prohibits implicit Optional. Accordingly, mypy has changed its default to no_implicit_optional=True\nsrc/dgdn/compliance/privacy_manager.py:67:66: note: Use https://github.com/hauntsaninja/no_implicit_optional to automatically upgrade your codebase\nsrc/dgdn/compliance/privacy_manager.py: note: In member \"check_processing_lawfulness\" of class \"PrivacyManager\":\nsrc/dgdn/compliance/privacy_manager.py:175:13: error: \"object\" has no attribute\n\"extend\"  [attr-defined]\n                lawfulness_check['legal_basis'].extend(regime_check.get('l...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/privacy_manager.py:176:13: error: \"object\" has no attribute\n\"extend\"  [attr-defined]\n                lawfulness_check['required_actions'].extend(regime_check.g...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/privacy_manager.py:177:13: error: \"object\" has no attribute\n\"append\"  [attr-defined]\n                lawfulness_check['compliance_notes'].append(f\"{regime.valu...\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/privacy_manager.py: note: In member \"_record_processing_activity\" of class \"PrivacyManager\":\nsrc/dgdn/compliance/privacy_manager.py:358:5: error: Function is missing a\nreturn type annotation  [no-untyped-def]\n        def _record_processing_activity(self, data: Any, purpose: Processi...\n        ^\nsrc/dgdn/compliance/privacy_manager.py: note: In member \"_estimate_data_size\" of class \"PrivacyManager\":\nsrc/dgdn/compliance/privacy_manager.py:381:13: error: Returning Any from\nfunction declared to return \"int\"  [no-any-return]\n                return data.numel() * data.element_size()\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/compliance/privacy_manager.py: note: In member \"set_data_minimization_policy\" of class \"PrivacyManager\":\nsrc/dgdn/compliance/privacy_manager.py:404:5: error: Function is missing a\nreturn type annotation  [no-untyped-def]\n        def set_data_minimization_policy(self, purpose: ProcessingPurpose,...\n        ^\nsrc/dgdn/optimization/computation.py: note: In member \"optimize_forward_pass\" of class \"ComputationOptimizer\":\nsrc/dgdn/optimization/computation.py:39:5: error: Function is missing a type\nannotation  [no-untyped-def]\n        def optimize_forward_pass(self, model, data):\n        ^\nsrc/dgdn/optimization/computation.py: note: In member \"optimize_backward_pass\" of class \"ComputationOptimizer\":\nsrc/dgdn/optimization/computation.py:47:5: error: Function is missing a type\nannotation  [no-untyped-def]\n        def optimize_backward_pass(self, loss, model):\n        ^\nsrc/dgdn/optimization/computation.py: note: In member \"__init__\" of class \"TensorOperationOptimizer\":\nsrc/dgdn/optimization/computation.py:69:5: error: Function is missing a return\ntype annotation  [no-untyped-def]\n        def __init__(self):\n        ^\nsrc/dgdn/optimization/computation.py:69:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/optimization/computation.py: note: In member \"optimized_attention\" of class \"TensorOperationOptimizer\":\nsrc/dgdn/optimization/computation.py:75:5: error: Function is missing a type\nannotation  [no-untyped-def]\n        def optimized_attention(query, key, value, mask=None, dropout_p=0....\n        ^\nsrc/dgdn/optimization/computation.py: note: In member \"optimized_edge_aggregation\" of class \"TensorOperationOptimizer\":\nsrc/dgdn/optimization/computation.py:102:5: error: Function is missing a type\nannotation  [no-untyped-def]\n        def optimized_edge_aggregation(edge_index, edge_attr, num_nodes, a...\n        ^\nsrc/dgdn/optimization/computation.py: note: In member \"cache_computation\" of class \"TensorOperationOptimizer\":\nsrc/dgdn/optimization/computation.py:137:5: error: Function is missing a return\ntype annotation  [no-untyped-def]\n        def cache_computation(self, key: str, computation_fn, *args, **kwa...\n        ^\nsrc/dgdn/optimization/computation.py:137:5: error: Function is missing a type\nannotation for one or more arguments  [no-untyped-def]\n        def cache_computation(self, key: str, computation_fn, *args, **kwa...\n        ^\nsrc/dgdn/optimization/computation.py: note: In member \"clear_cache\" of class \"TensorOperationOptimizer\":\nsrc/dgdn/optimization/computation.py:149:5: error: Function is missing a return\ntype annotation  [no-untyped-def]\n        def clear_cache(self):\n        ^\nsrc/dgdn/optimization/computation.py:149:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/optimization/computation.py: note: In member \"parallel_batch_processing\" of class \"ParallelProcessor\":\nsrc/dgdn/optimization/computation.py:171:5: error: Function is missing a type\nannotation  [no-untyped-def]\n        def parallel_batch_processing(self, data_list, process_fn, use_thr...\n        ^\nsrc/dgdn/optimization/computation.py: note: In member \"parallel_graph_processing\" of class \"ParallelProcessor\":\nsrc/dgdn/optimization/computation.py:183:5: error: Function is missing a type\nannotation  [no-untyped-def]\n        def parallel_graph_processing(self, graphs, model, batch_size=32):\n        ^\nsrc/dgdn/optimization/computation.py: note: In function \"parallel_graph_processing\":\nsrc/dgdn/optimization/computation.py:185:9: error: Function is missing a type\nannotation  [no-untyped-def]\n            def process_batch(graph_batch):\n            ^\nsrc/dgdn/optimization/computation.py: note: In member \"cleanup\" of class \"ParallelProcessor\":\nsrc/dgdn/optimization/computation.py:206:5: error: Function is missing a return\ntype annotation  [no-untyped-def]\n        def cleanup(self):\n        ^\nsrc/dgdn/optimization/computation.py:206:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/optimization/computation.py: note: In member \"__init__\" of class \"MemoryOptimizer\":\nsrc/dgdn/optimization/computation.py:216:5: error: Function is missing a return\ntype annotation  [no-untyped-def]\n        def __init__(self):\n        ^\nsrc/dgdn/optimization/computation.py:216:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/optimization/computation.py: note: In member \"enable_gradient_checkpointing\" of class \"MemoryOptimizer\":\nsrc/dgdn/optimization/computation.py:220:5: error: Function is missing a type\nannotation  [no-untyped-def]\n        def enable_gradient_checkpointing(self, model):\n        ^\nsrc/dgdn/optimization/computation.py: note: In function \"enable_gradient_checkpointing\":\nsrc/dgdn/optimization/computation.py:222:9: error: Function is missing a type\nannotation  [no-untyped-def]\n            def create_custom_forward(module):\n            ^\nsrc/dgdn/optimization/computation.py:223:13: error: Function is missing a type\nannotation  [no-untyped-def]\n                def custom_forward(*inputs):\n                ^\nsrc/dgdn/optimization/computation.py:233:17: error: Function is missing a type\nannotation  [no-untyped-def]\n                    def checkpointed_forward(self, *args, **kwargs):\n                    ^\nsrc/dgdn/optimization/computation.py: note: In member \"optimize_memory_usage\" of class \"MemoryOptimizer\":\nsrc/dgdn/optimization/computation.py:244:5: error: Function is missing a type\nannotation  [no-untyped-def]\n        def optimize_memory_usage(self, model, data):\n        ^\nsrc/dgdn/optimization/computation.py: note: In member \"memory_profiling_context\" of class \"MemoryOptimizer\":\nsrc/dgdn/optimization/computation.py:258:5: error: Function is missing a return\ntype annotation  [no-untyped-def]\n        def memory_profiling_context(self):\n        ^\nsrc/dgdn/optimization/computation.py: note: In function \"memory_profiling_context\":\nsrc/dgdn/optimization/computation.py:261:13: error: Function is missing a type\nannotation  [no-untyped-def]\n                def __init__(self, logger):\n                ^\nsrc/dgdn/optimization/computation.py:265:13: error: Function is missing a type\nannotation  [no-untyped-def]\n                def __enter__(self):\n                ^\nsrc/dgdn/optimization/computation.py:271:13: error: Function is missing a type\nannotation  [no-untyped-def]\n                def __exit__(self, exc_type, exc_val, exc_tb):\n                ^\nsrc/dgdn/optimization/computation.py: note: In member \"get_optimal_batch_size\" of class \"DynamicBatchSizer\":\nsrc/dgdn/optimization/computation.py:293:5: error: Function is missing a type\nannotation  [no-untyped-def]\n        def get_optimal_batch_size(self, model, sample_data):\n        ^\nsrc/dgdn/optimization/computation.py: note: In function \"get_optimal_batch_size\":\nsrc/dgdn/optimization/computation.py:295:9: error: Function is missing a type\nannotation  [no-untyped-def]\n            def test_batch_size(batch_size):\n            ^\nsrc/dgdn/optimization/computation.py: note: In member \"adapt_batch_size\" of class \"DynamicBatchSizer\":\nsrc/dgdn/optimization/computation.py:330:5: error: Function is missing a return\ntype annotation  [no-untyped-def]\n        def adapt_batch_size(self, oom_occurred: bool):\n        ^\nsrc/dgdn/optimization/computation.py: note: In member \"__init__\" of class \"GraphCompiler\":\nsrc/dgdn/optimization/computation.py:348:5: error: Function is missing a return\ntype annotation  [no-untyped-def]\n        def __init__(self):\n        ^\nsrc/dgdn/optimization/computation.py:348:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/optimization/computation.py: note: In member \"compile_model\" of class \"GraphCompiler\":\nsrc/dgdn/optimization/computation.py:352:5: error: Function is missing a type\nannotation  [no-untyped-def]\n        def compile_model(self, model, sample_input, optimization_level=\"d...\n        ^\nsrc/dgdn/optimization/computation.py: note: In member \"optimize_for_inference\" of class \"GraphCompiler\":\nsrc/dgdn/optimization/computation.py:382:5: error: Function is missing a type\nannotation  [no-untyped-def]\n        def optimize_for_inference(self, model):\n        ^\nsrc/dgdn/optimization/computation.py: note: In member \"__init__\" of class \"OptimizedOperations\":\nsrc/dgdn/optimization/computation.py:408:5: error: Function is missing a return\ntype annotation  [no-untyped-def]\n        def __init__(self):\n        ^\nsrc/dgdn/optimization/computation.py:408:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/optimization/computation.py: note: In member \"optimize_model\" of class \"OptimizedOperations\":\nsrc/dgdn/optimization/computation.py:416:5: error: Function is missing a type\nannotation  [no-untyped-def]\n        def optimize_model(self, model, sample_data):\n        ^\nsrc/dgdn/optimization/computation.py: note: In member \"cleanup\" of class \"OptimizedOperations\":\nsrc/dgdn/optimization/computation.py:429:5: error: Function is missing a return\ntype annotation  [no-untyped-def]\n        def cleanup(self):\n        ^\nsrc/dgdn/optimization/computation.py:429:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/utils/validation.py: note: In function \"validate_temporal_data\":\nsrc/dgdn/utils/validation.py:86:1: error: Function is missing a type annotation\nfor one or more arguments  [no-untyped-def]\n    def validate_temporal_data(data) -> bool:\n    ^\nsrc/dgdn/utils/validation.py: note: In function \"validate_data\":\nsrc/dgdn/utils/validation.py:227:1: error: Function is missing a type\nannotation for one or more arguments  [no-untyped-def]\n    def validate_data(data, strict: bool = True) -> bool:\n    ^\nsrc/dgdn/utils/validation.py: note: In member \"validate\" of class \"DataValidator\":\nsrc/dgdn/utils/validation.py:367:5: error: Function is missing a type\nannotation for one or more arguments  [no-untyped-def]\n        def validate(self, data, validation_name: str = \"data\") -> bool:\n        ^\nsrc/dgdn/training/metrics.py: note: In member \"reset\" of class \"DGDNMetrics\":\nsrc/dgdn/training/metrics.py:17:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def reset(self):\n        ^\nsrc/dgdn/training/metrics.py:17:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/training/metrics.py: note: In member \"update\" of class \"DGDNMetrics\":\nsrc/dgdn/training/metrics.py:24:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def update(\n        ^\nsrc/dgdn/training/metrics.py: note: In member \"compute\" of class \"DGDNMetrics\":\nsrc/dgdn/training/metrics.py:58:28: error: Argument 1 to \"update\" of\n\"MutableMapping\" has incompatible type \"dict[str, float]\"; expected\n\"SupportsKeysAndGetItem[str, floating[Any]]\"  [arg-type]\n                metrics.update(self._compute_edge_prediction_metrics(predi...\n                               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...\nsrc/dgdn/training/metrics.py:60:28: error: Argument 1 to \"update\" of\n\"MutableMapping\" has incompatible type \"dict[str, float]\"; expected\n\"SupportsKeysAndGetItem[str, floating[Any]]\"  [arg-type]\n                metrics.update(self._compute_node_classification_metrics(p...\n                               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...\nsrc/dgdn/training/metrics.py:65:28: error: Argument 1 to \"update\" of\n\"MutableMapping\" has incompatible type \"dict[str, float]\"; expected\n\"SupportsKeysAndGetItem[str, floating[Any]]\"  [arg-type]\n                metrics.update(self._compute_uncertainty_metrics(predictio...\n                               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...\nsrc/dgdn/training/metrics.py:67:16: error: Incompatible return value type (got\n\"dict[str, floating[Any]]\", expected \"dict[str, float]\")  [return-value]\n            return metrics\n                   ^~~~~~~\nsrc/dgdn/training/metrics.py: note: In member \"_compute_uncertainty_metrics\" of class \"DGDNMetrics\":\nsrc/dgdn/training/metrics.py:158:30: error: Incompatible types in assignment\n(expression has type \"float\", target has type \"floating[Any]\")  [assignment]\n                metrics[\"ece\"] = ece\n                                 ^~~\nsrc/dgdn/training/metrics.py:162:28: error: Argument 1 to \"update\" of\n\"MutableMapping\" has incompatible type \"dict[str, float]\"; expected\n\"SupportsKeysAndGetItem[str, floating[Any]]\"  [arg-type]\n                metrics.update(reliability)\n                               ^~~~~~~~~~~\nsrc/dgdn/training/metrics.py:164:16: error: Incompatible return value type (got\n\"dict[str, floating[Any]]\", expected \"dict[str, float]\")  [return-value]\n            return metrics\n                   ^~~~~~~\nsrc/dgdn/training/metrics.py: note: In member \"_compute_reliability\" of class \"DGDNMetrics\":\nsrc/dgdn/training/metrics.py:220:13: error: Dict entry 1 has incompatible type\n\"str\": \"floating[Any]\"; expected \"str\": \"float\"  [dict-item]\n                \"mean_error\": np.mean(errors),\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/training/metrics.py:221:13: error: Dict entry 2 has incompatible type\n\"str\": \"floating[Any]\"; expected \"str\": \"float\"  [dict-item]\n                \"error_std\": np.std(errors)\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/training/metrics.py: note: In member \"__init__\" of class \"EdgePredictionMetrics\":\nsrc/dgdn/training/metrics.py:228:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def __init__(self):\n        ^\nsrc/dgdn/training/metrics.py:228:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/training/metrics.py: note: In member \"__init__\" of class \"TemporalMetrics\":\nsrc/dgdn/training/metrics.py:318:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def __init__(self):\n        ^\nsrc/dgdn/training/metrics.py:318:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/training/metrics.py: note: In member \"update\" of class \"TemporalMetrics\":\nsrc/dgdn/training/metrics.py:323:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def update(\n        ^\nsrc/dgdn/training/metrics.py: note: In member \"__init__\" of class \"UncertaintyMetrics\":\nsrc/dgdn/training/metrics.py:391:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def __init__(self):\n        ^\nsrc/dgdn/training/metrics.py:391:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/training/metrics.py: note: In member \"update\" of class \"UncertaintyMetrics\":\nsrc/dgdn/training/metrics.py:396:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def update(\n        ^\nsrc/dgdn/training/metrics.py: note: In member \"compute_calibration_metrics\" of class \"UncertaintyMetrics\":\nsrc/dgdn/training/metrics.py:433:31: error: Value of type \"floating[Any]\" is\nnot indexable  [index]\n                mask = (unc_np >= bin_edges[i]) & (unc_np < bin_edges[i + ...\n                                  ^~~~~~~~~~~~\nsrc/dgdn/training/metrics.py:444:13: error: Dict entry 2 has incompatible type\n\"str\": \"floating[Any]\"; expected \"str\": \"float\"  [dict-item]\n                \"mean_uncertainty\": np.mean(unc_np),\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/training/metrics.py:445:13: error: Dict entry 3 has incompatible type\n\"str\": \"floating[Any]\"; expected \"str\": \"float\"  [dict-item]\n                \"mean_error\": np.mean(errors)\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/data/datasets.py: note: In member \"__post_init__\" of class \"TemporalData\":\nsrc/dgdn/data/datasets.py:34:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def __post_init__(self):\n        ^\nsrc/dgdn/data/datasets.py:34:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/data/datasets.py: note: In member \"get_temporal_statistics\" of class \"TemporalData\":\nsrc/dgdn/data/datasets.py:122:13: error: Dict entry 4 has incompatible type\n\"str\": \"Optional[int]\"; expected \"str\": \"float\"  [dict-item]\n                \"num_nodes\": self.num_nodes,\n                ^~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/data/datasets.py: note: In member \"split\" of class \"TemporalDataset\":\nsrc/dgdn/data/datasets.py:245:28: error: Incompatible types in assignment\n(expression has type \"TemporalDataset\", variable has type \"None\")  [assignment]\n            self._train_data = TemporalDataset(train_data, f\"{self.name}_t...\n                               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...\nsrc/dgdn/data/datasets.py:246:26: error: Incompatible types in assignment\n(expression has type \"TemporalDataset\", variable has type \"None\")  [assignment]\n            self._val_data = TemporalDataset(val_data, f\"{self.name}_val\")\n                             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/data/datasets.py:247:27: error: Incompatible types in assignment\n(expression has type \"TemporalDataset\", variable has type \"None\")  [assignment]\n            self._test_data = TemporalDataset(test_data, f\"{self.name}_tes...\n                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/data/datasets.py:249:16: error: Incompatible return value type (got\n\"tuple[None, None, None]\", expected\n\"tuple[TemporalDataset, TemporalDataset, TemporalDataset]\")  [return-value]\n            return self._train_data, self._val_data, self._test_data\n                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/data/datasets.py: note: In member \"get_statistics\" of class \"TemporalDataset\":\nsrc/dgdn/data/datasets.py:266:13: error: Dict entry 0 has incompatible type\n\"str\": \"str\"; expected \"str\": \"float\"  [dict-item]\n                \"dataset_name\": self.name,\n                ^~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/data/datasets.py: note: In member \"save\" of class \"TemporalDataset\":\nsrc/dgdn/data/datasets.py:276:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def save(self, path: str):\n        ^\nsrc/dgdn/data/datasets.py: note: In member \"load_from_file\" of class \"TemporalDataset\":\nsrc/dgdn/data/datasets.py:285:13: error: Returning Any from function declared\nto return \"TemporalDataset\"  [no-any-return]\n                return pickle.load(f)\n                ^~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/data/datasets.py: note: In class \"TemporalGraphDataset\":\nsrc/dgdn/data/datasets.py:288:28: error: Class cannot subclass \"Dataset\" (has\ntype \"Any\")  [misc]\n    class TemporalGraphDataset(Dataset):\n                               ^~~~~~~\nsrc/dgdn/data/datasets.py: note: In member \"_create_windows\" of class \"TemporalGraphDataset\":\nsrc/dgdn/data/datasets.py:305:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def _create_windows(self):\n        ^\nsrc/dgdn/data/datasets.py:305:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/data/datasets.py: note: In member \"process\" of class \"TemporalGraphDataset\":\nsrc/dgdn/data/datasets.py:350:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def process(self):\n        ^\nsrc/dgdn/data/datasets.py:350:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/data/datasets.py: note: In function \"create_temporal_batch\":\nsrc/dgdn/data/datasets.py:388:9: error: Unsupported operand types for + (\"int\"\nand \"None\")  [operator]\n            node_offset += data.num_nodes\n            ^\nsrc/dgdn/data/datasets.py:388:9: note: Right operand is of type \"Optional[int]\"\nsrc/dgdn/utils/security.py: note: In member \"__init__\" of class \"SecurityValidator\":\nsrc/dgdn/utils/security.py:31:9: error: Need type annotation for\n\"blocked_operations\" (hint: \"blocked_operations: set[<type>] = ...\") \n[var-annotated]\n            self.blocked_operations = set()\n            ^~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/utils/security.py: note: In function \"sanitize_input\":\nsrc/dgdn/utils/security.py:186:21: error: Incompatible types in assignment\n(expression has type \"dict[Never, Never]\", variable has type \"list[Any]\") \n[assignment]\n            sanitized = {}\n                        ^~\nsrc/dgdn/utils/security.py: note: In function \"compute_model_hash\":\nsrc/dgdn/utils/security.py:201:1: error: Function is missing a type annotation\nfor one or more arguments  [no-untyped-def]\n    def compute_model_hash(model) -> str:\n    ^\nsrc/dgdn/utils/security.py: note: In function \"check_model_integrity\":\nsrc/dgdn/utils/security.py:221:1: error: Function is missing a type annotation\nfor one or more arguments  [no-untyped-def]\n    def check_model_integrity(model, expected_hash: str) -> bool:\n    ^\nsrc/dgdn/utils/security.py: note: In function \"secure_model_save\":\nsrc/dgdn/utils/security.py:245:1: error: Function is missing a type annotation\nfor one or more arguments  [no-untyped-def]\n    def secure_model_save(model, file_path: Union[str, Path], include_hash...\n    ^\nsrc/dgdn/utils/security.py:275:21: error: Argument 1 to \"write\" of\n\"_TextIOBase\" has incompatible type \"Optional[str]\"; expected \"str\"  [arg-type]\n                f.write(model_hash)\n                        ^~~~~~~~~~\nsrc/dgdn/utils/security.py:279:12: error: Incompatible return value type (got\n\"Optional[str]\", expected \"str\")  [return-value]\n        return model_hash\n               ^~~~~~~~~~\nsrc/dgdn/utils/security.py: note: In function \"secure_model_load\":\nsrc/dgdn/utils/security.py:282:1: error: Function is missing a return type\nannotation  [no-untyped-def]\n    def secure_model_load(model, file_path: Union[str, Path], verify_hash:...\n    ^\nsrc/dgdn/utils/security.py:282:1: error: Function is missing a type annotation\nfor one or more arguments  [no-untyped-def]\n    def secure_model_load(model, file_path: Union[str, Path], verify_hash:...\n    ^\nsrc/dgdn/utils/security.py: note: In member \"add_noise_to_gradients\" of class \"DifferentialPrivacyManager\":\nsrc/dgdn/utils/security.py:349:5: error: Function is missing a type annotation\nfor one or more arguments  [no-untyped-def]\n        def add_noise_to_gradients(self, model) -> None:\n        ^\nsrc/dgdn/data/loaders.py: note: In class \"DynamicBatchSampler\":\nsrc/dgdn/data/loaders.py:10:27: error: Class cannot subclass \"Sampler\" (has\ntype \"Any\")  [misc]\n    class DynamicBatchSampler(Sampler):\n                              ^~~~~~~\nsrc/dgdn/data/loaders.py: note: In member \"_compute_complexity_metrics\" of class \"DynamicBatchSampler\":\nsrc/dgdn/data/loaders.py:43:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def _compute_complexity_metrics(self):\n        ^\nsrc/dgdn/data/loaders.py:43:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/data/loaders.py: note: In member \"__iter__\" of class \"DynamicBatchSampler\":\nsrc/dgdn/data/loaders.py:80:9: error: Need type annotation for \"batch\" (hint:\n\"batch: list[<type>] = ...\")  [var-annotated]\n            batch = []\n            ^~~~~\nsrc/dgdn/data/loaders.py: note: In member \"__init__\" of class \"TemporalDataLoader\":\nsrc/dgdn/data/loaders.py:129:30: error: Missing type parameters for generic\ntype \"Callable\"  [type-arg]\n            collate_fn: Optional[Callable] = None\n                                 ^\nsrc/dgdn/data/loaders.py: note: In member \"_create_indexed_dataset\" of class \"TemporalDataLoader\":\nsrc/dgdn/data/loaders.py:183:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def _create_indexed_dataset(self):\n        ^\nsrc/dgdn/data/loaders.py: note: In member \"__iter__\" of class \"TemporalDataLoader\":\nsrc/dgdn/data/loaders.py:191:5: error: Function is missing a type annotation \n[no-untyped-def]\n        def __iter__(self):\n        ^\nsrc/dgdn/data/loaders.py: note: In member \"__len__\" of class \"TemporalDataLoader\":\nsrc/dgdn/data/loaders.py:195:5: error: Function is missing a type annotation \n[no-untyped-def]\n        def __len__(self):\n        ^\nsrc/dgdn/data/loaders.py: note: In member \"_create_windows\" of class \"IndexedTemporalDataset\":\nsrc/dgdn/data/loaders.py:216:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def _create_windows(self):\n        ^\nsrc/dgdn/data/loaders.py:216:5: note: Use \"-> None\" if function does not return a value\nsrc/dgdn/data/loaders.py: note: In class \"TemporalBatchSampler\":\nsrc/dgdn/data/loaders.py:253:28: error: Class cannot subclass \"Sampler\" (has\ntype \"Any\")  [misc]\n    class TemporalBatchSampler(Sampler):\n                               ^~~~~~~\nsrc/dgdn/data/loaders.py: note: In function \"create_data_loaders\":\nsrc/dgdn/data/loaders.py:306:6: error: Missing type parameters for generic type\n\"tuple\"  [type-arg]\n    ) -> tuple:\n         ^\nsrc/dgdn/data/loaders.py:340:5: error: Statement is unreachable  [unreachable]\n        train_loader = TemporalDataLoader(\n        ^\nsrc/dgdn/training/trainer.py:20:1: error: Module \"dgdn.optimization\" has no\nattribute \"MixedPrecisionTrainer\"  [attr-defined]\n    from ..optimization import MixedPrecisionTrainer, MemoryOptimizer, Par...\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...\nsrc/dgdn/training/trainer.py:20:1: error: Module \"dgdn.optimization\" has no\nattribute \"ParallelismManager\"  [attr-defined]\n    from ..optimization import MixedPrecisionTrainer, MemoryOptimizer, Par...\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~...\nsrc/dgdn/training/trainer.py: note: In member \"__init__\" of class \"DGDNTrainer\":\nsrc/dgdn/training/trainer.py:43:5: error: Function is missing a type annotation\nfor one or more arguments  [no-untyped-def]\n        def __init__(\n        ^\nsrc/dgdn/training/trainer.py:88:28: error: Incompatible types in assignment\n(expression has type \"NodeClassificationMetrics\", variable has type\n\"EdgePredictionMetrics\")  [assignment]\n                self.metrics = NodeClassificationMetrics()\n                               ^~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/training/trainer.py:90:28: error: Incompatible types in assignment\n(expression has type \"DGDNMetrics\", variable has type \"EdgePredictionMetrics\") \n[assignment]\n                self.metrics = DGDNMetrics(task=task)\n                               ^~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/training/trainer.py:98:23: error: Name \"SummaryWriter\" is not defined \n[name-defined]\n            self.writer = SummaryWriter(log_dir)\n                          ^~~~~~~~~~~~~\nsrc/dgdn/training/trainer.py:103:33: error: Need type annotation for\n\"training_history\"  [var-annotated]\n            self.training_history = {\"train\": [], \"val\": []}\n                                    ^~~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/training/trainer.py: note: In member \"fit\" of class \"DGDNTrainer\":\nsrc/dgdn/training/trainer.py:197:40: error: Incompatible types in assignment\n(expression has type \"Optional[int]\", variable has type \"None\")  [assignment]\n            self.early_stopping_patience = early_stopping_patience\n                                           ^~~~~~~~~~~~~~~~~~~~~~~\nsrc/dgdn/training/trainer.py:205:13: error: Statement is unreachable \n[unreachable]\n                train_loader, val_loader, _ = create_data_loaders(\n                ^\nsrc/dgdn/training/trainer.py: note: In member \"_train_epoch\" of class \"DGDNTrainer\":\nsrc/dgdn/training/trainer.py:269:5: error: Function is missing a type\nannotation for one or more arguments  [no-untyped-def]\n        def _train_epoch(self, train_loader, verbose: bool = True) -> Dict...\n        ^\nsrc/dgdn/training/trainer.py: note: In member \"_validate_epoch\" of class \"DGDNTrainer\":\nsrc/dgdn/training/trainer.py:345:5: error: Function is missing a type\nannotation for one or more arguments  [no-untyped-def]\n        def _validate_epoch(self, val_loader, verbose: bool = True) -> Dic...\n        ^\nsrc/dgdn/training/trainer.py: note: In member \"_extract_predictions\" of class \"DGDNTrainer\":\nsrc/dgdn/training/trainer.py:382:5: error: Function is missing a type\nannotation for one or more arguments  [no-untyped-def]\n        def _extract_predictions(self, model_output: Dict, batch_data) -> ...\n        ^\nsrc/dgdn/training/trainer.py:382:50: error: Missing type parameters for generic\ntype \"Dict\"  [type-arg]\n        def _extract_predictions(self, model_output: Dict, batch_data) -> ...\n                                                     ^\nsrc/dgdn/training/trainer.py: note: In member \"_extract_uncertainties\" of class \"DGDNTrainer\":\nsrc/dgdn/training/trainer.py:404:5: error: Function is missing a type\nannotation for one or more arguments  [no-untyped-def]\n        def _extract_uncertainties(self, model_output: Dict, batch_data, t...\n        ^\nsrc/dgdn/training/trainer.py:404:52: error: Missing type parameters for generic\ntype \"Dict\"  [type-arg]\n    ...  def _extract_uncertainties(self, model_output: Dict, batch_data, tar...\n                                                        ^\nsrc/dgdn/training/trainer.py: note: In member \"_should_stop_early\" of class \"DGDNTrainer\":\nsrc/dgdn/training/trainer.py:438:9: error: Statement is unreachable \n[unreachable]\n            if self.task == \"edge_prediction\":\n            ^\nsrc/dgdn/training/trainer.py: note: In member \"_log_metrics\" of class \"DGDNTrainer\":\nsrc/dgdn/training/trainer.py:456:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def _log_metrics(\n        ^\nsrc/dgdn/training/trainer.py: note: In member \"_print_progress\" of class \"DGDNTrainer\":\nsrc/dgdn/training/trainer.py:476:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def _print_progress(\n        ^\nsrc/dgdn/training/trainer.py: note: In member \"_save_checkpoint\" of class \"DGDNTrainer\":\nsrc/dgdn/training/trainer.py:535:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def _save_checkpoint(self, filename: str):\n        ^\nsrc/dgdn/training/trainer.py: note: In member \"load_checkpoint\" of class \"DGDNTrainer\":\nsrc/dgdn/training/trainer.py:550:5: error: Function is missing a return type\nannotation  [no-untyped-def]\n        def load_checkpoint(self, filename: str):\n        ^\nsrc/dgdn/training/trainer.py: note: In member \"predict\" of class \"DGDNTrainer\":\nsrc/dgdn/training/trainer.py:564:5: error: Function is missing a type\nannotation for one or more arguments  [no-untyped-def]\n        def predict(self, data, return_uncertainty: bool = False) -> Dict[...\n        ^\nsrc/dgdn/training/trainer.py: note: In member \"_validate_init_parameters\" of class \"DGDNTrainer\":\nsrc/dgdn/training/trainer.py:611:5: error: Function is missing a type\nannotation  [no-untyped-def]\n        def _validate_init_parameters(self, learning_rate, weight_decay, \n        ^\nsrc/dgdn/training/trainer.py: note: In member \"_validate_training_data\" of class \"DGDNTrainer\":\nsrc/dgdn/training/trainer.py:630:5: error: Function is missing a type\nannotation  [no-untyped-def]\n        def _validate_training_data(self, train_data, val_data=None):\n        ^\nsrc/dgdn/training/trainer.py: note: In member \"_log_training_progress\" of class \"DGDNTrainer\":\nsrc/dgdn/training/trainer.py:666:5: error: Function is missing a type\nannotation  [no-untyped-def]\n        def _log_training_progress(self, epoch, train_metrics, val_metrics...\n        ^\nFound 331 errors in 25 files (checked 36 source files)\n",
      "error": "mypy.ini: [mypy]: python_version: Python 3.8 is not supported (must be 3.9 or higher)\n"
    },
    "code_formatting": {
      "name": "Code Formatting",
      "passed": false,
      "duration": 0.04406404495239258,
      "output": "Would reformat: src/dgdn/__init__.py\nWould reformat: src/dgdn/compliance/__init__.py\nWould reformat: src/dgdn/compliance/ccpa.py\nWould reformat: src/dgdn/compliance/data_protection.py\nWould reformat: src/dgdn/compliance/gdpr.py\nWould reformat: src/dgdn/compliance/pdpa.py\nWould reformat: src/dgdn/compliance/privacy_manager.py\nWould reformat: src/dgdn/deployment/__init__.py\nWould reformat: src/dgdn/deployment/region_manager.py\nWould reformat: src/dgdn/i18n/__init__.py\nWould reformat: src/dgdn/i18n/locales.py\nWould reformat: src/dgdn/i18n/messages.py\nWould reformat: src/dgdn/i18n/translator.py\nWould reformat: src/dgdn/optimization/__init__.py\nWould reformat: src/dgdn/optimization/caching.py\nWould reformat: src/dgdn/optimization/computation.py\nWould reformat: src/dgdn/optimization/memory.py\nWould reformat: src/dgdn/temporal/__init__.py\nWould reformat: src/dgdn/temporal/diffusion.py\nWould reformat: src/dgdn/temporal/encoding.py\nWould reformat: src/dgdn/training/__init__.py\nWould reformat: src/dgdn/training/losses.py\nWould reformat: src/dgdn/training/metrics.py\nWould reformat: src/dgdn/training/trainer.py\nWould reformat: src/dgdn/utils/__init__.py\nWould reformat: src/dgdn/utils/config.py\nWould reformat: src/dgdn/utils/logging.py\nWould reformat: src/dgdn/utils/monitoring.py\nWould reformat: src/dgdn/utils/security.py\nWould reformat: src/dgdn/utils/validation.py\n30 files would be reformatted\n",
      "error": "warning: The top-level linter settings are deprecated in favour of their counterparts in the `lint` section. Please update the following options in `pyproject.toml`:\n  - 'ignore' -> 'lint.ignore'\n  - 'select' -> 'lint.select'\n  - 'per-file-ignores' -> 'lint.per-file-ignores'\n"
    },
    "linting": {
      "name": "Linting",
      "passed": false,
      "duration": 0.09900426864624023,
      "violations": 14655,
      "output": "src/dgdn/__init__.py:13:1: I001 [*] Import block is un-sorted or un-formatted\n   |\n12 |   # Core model imports\n13 | / from .models import DynamicGraphDiffusionNet, DGDNLayer, MultiHeadTemporalAttention\n14 | |\n15 | | # Data handling imports\n16 | | from .data import TemporalData, TemporalDataset, TemporalGraphDataset, TemporalDataLoader\n17 | |\n18 | | # Temporal processing imports\n19 | | from .temporal import EdgeTimeEncoder, VariationalDiffusion\n   | |___________________________________________________________^ I001\n20 |\n21 |   # Training imports - optional for basic functionality\n   |\n   = help: Organize imports\n\nsrc/dgdn/__init__.py:36:17: W291 [*] Trailing whitespace\n   |\n34 |     # Core models\n35 |     \"DynamicGraphDiffusionNet\",\n36 |     \"DGDNLayer\", \n   |                 ^ W291\n37 |     \"MultiHeadTemporalAttention\",\n38 |     # Data structures\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/__init__.py:41:28: W291 [*] Trailing whitespace\n   |\n39 |     \"TemporalData\",\n40 |     \"TemporalDataset\",\n41 |     \"TemporalGraphDataset\", \n   |                            ^ W291\n42 |     \"TemporalDataLoader\",\n43 |     # Temporal processing\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/__init__.py:46:2: W292 [*] No newline at end of file\n   |\n44 |     \"EdgeTimeEncoder\",\n45 |     \"VariationalDiffusion\",\n46 | ]\n   |  ^ W292\n   |\n   = help: Add trailing newline\n\nsrc/dgdn/compliance/__init__.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n   |\n 1 |   \"\"\"Compliance and privacy features for DGDN library.\"\"\"\n 2 |\n 3 | / from .gdpr import GDPRCompliance\n 4 | | from .ccpa import CCPACompliance  \n 5 | | from .pdpa import PDPACompliance\n 6 | | from .privacy_manager import (\n 7 | |     PrivacyManager, \n 8 | |     DataCategory, \n 9 | |     ProcessingPurpose, \n10 | |     PrivacyRegime\n11 | | )\n12 | | from .data_protection import DataProtectionManager\n   | |__________________________________________________^ I001\n13 |\n14 |   __all__ = [\n   |\n   = help: Organize imports\n\nsrc/dgdn/compliance/__init__.py:4:33: W291 [*] Trailing whitespace\n  |\n3 | from .gdpr import GDPRCompliance\n4 | from .ccpa import CCPACompliance  \n  |                                 ^^ W291\n5 | from .pdpa import PDPACompliance\n6 | from .privacy_manager import (\n  |\n  = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/__init__.py:7:20: W291 [*] Trailing whitespace\n  |\n5 | from .pdpa import PDPACompliance\n6 | from .privacy_manager import (\n7 |     PrivacyManager, \n  |                    ^ W291\n8 |     DataCategory, \n9 |     ProcessingPurpose, \n  |\n  = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/__init__.py:8:18: W291 [*] Trailing whitespace\n   |\n 6 | from .privacy_manager import (\n 7 |     PrivacyManager, \n 8 |     DataCategory, \n   |                  ^ W291\n 9 |     ProcessingPurpose, \n10 |     PrivacyRegime\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/__init__.py:9:23: W291 [*] Trailing whitespace\n   |\n 7 |     PrivacyManager, \n 8 |     DataCategory, \n 9 |     ProcessingPurpose, \n   |                       ^ W291\n10 |     PrivacyRegime\n11 | )\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/__init__.py:15:22: W291 [*] Trailing whitespace\n   |\n14 | __all__ = [\n15 |     \"GDPRCompliance\", \n   |                      ^ W291\n16 |     \"CCPACompliance\", \n17 |     \"PDPACompliance\",\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/__init__.py:16:22: W291 [*] Trailing whitespace\n   |\n14 | __all__ = [\n15 |     \"GDPRCompliance\", \n16 |     \"CCPACompliance\", \n   |                      ^ W291\n17 |     \"PDPACompliance\",\n18 |     \"PrivacyManager\",\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/__init__.py:20:25: W291 [*] Trailing whitespace\n   |\n18 |     \"PrivacyManager\",\n19 |     \"DataCategory\",\n20 |     \"ProcessingPurpose\", \n   |                         ^ W291\n21 |     \"PrivacyRegime\",\n22 |     \"DataProtectionManager\"\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/__init__.py:23:2: W292 [*] No newline at end of file\n   |\n21 |     \"PrivacyRegime\",\n22 |     \"DataProtectionManager\"\n23 | ]\n   |  ^ W292\n   |\n   = help: Add trailing newline\n\nsrc/dgdn/compliance/ccpa.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n  |\n1 |   \"\"\"CCPA compliance implementation for DGDN.\"\"\"\n2 |\n3 | / import logging\n4 | | from datetime import datetime, timedelta\n5 | | from typing import Dict, Any, List, Optional\n6 | | from enum import Enum\n  | |_____________________^ I001\n  |\n  = help: Organize imports\n\nsrc/dgdn/compliance/ccpa.py:37:1: W293 [*] Blank line contains whitespace\n   |\n35 | class CCPACompliance:\n36 |     \"\"\"CCPA compliance system for DGDN.\"\"\"\n37 |     \n   | ^^^^ W293\n38 |     def __init__(self):\n39 |         \"\"\"Initialize CCPA compliance system.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:45:1: W293 [*] Blank line contains whitespace\n   |\n43 |         self.opt_out_requests = {}\n44 |         self.data_sales_log = []  # DGDN doesn't sell data, but tracking for compliance\n45 |         \n   | ^^^^^^^^ W293\n46 |         # CCPA response timeframes\n47 |         self.response_timeframes = {\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:52:1: W293 [*] Blank line contains whitespace\n   |\n50 |             'opt_out': timedelta(days=15)  # Must honor within 15 business days\n51 |         }\n52 |         \n   | ^^^^^^^^ W293\n53 |         self.logger.info(\"CCPA compliance system initialized\")\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:54:1: W293 [*] Blank line contains whitespace\n   |\n53 |         self.logger.info(\"CCPA compliance system initialized\")\n54 |     \n   | ^^^^ W293\n55 |     def check_processing_lawfulness(self, data_category: str, purpose: str, \n56 |                                   data_subject_id: Optional[str] = None) -> Dict[str, Any]:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:55:76: W291 [*] Trailing whitespace\n   |\n53 |         self.logger.info(\"CCPA compliance system initialized\")\n54 |     \n55 |     def check_processing_lawfulness(self, data_category: str, purpose: str, \n   |                                                                            ^ W291\n56 |                                   data_subject_id: Optional[str] = None) -> Dict[str, Any]:\n57 |         \"\"\"Check if data processing complies with CCPA.\"\"\"\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/ccpa.py:64:1: W293 [*] Blank line contains whitespace\n   |\n62 |             'note': ''\n63 |         }\n64 |         \n   | ^^^^^^^^ W293\n65 |         # Map purpose to CCPA business purpose\n66 |         ccpa_purpose = self._map_to_ccpa_purpose(purpose)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:67:1: W293 [*] Blank line contains whitespace\n   |\n65 |         # Map purpose to CCPA business purpose\n66 |         ccpa_purpose = self._map_to_ccpa_purpose(purpose)\n67 |         \n   | ^^^^^^^^ W293\n68 |         if ccpa_purpose:\n69 |             lawfulness_check['legal_basis'].append(ccpa_purpose.value)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:72:1: W293 [*] Blank line contains whitespace\n   |\n70 |         else:\n71 |             lawfulness_check['legal_basis'].append('business_purpose_other')\n72 |         \n   | ^^^^^^^^ W293\n73 |         # Check if consumer has opted out\n74 |         if self._has_opted_out(data_subject_id):\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:79:1: W293 [*] Blank line contains whitespace\n   |\n77 |                 lawfulness_check['note'] = 'Consumer has opted out of sale/sharing'\n78 |                 lawfulness_check['required_actions'].append('honor_opt_out')\n79 |         \n   | ^^^^^^^^ W293\n80 |         # Verify privacy notice compliance\n81 |         if not self._has_privacy_notice_compliance(purpose):\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:83:1: W293 [*] Blank line contains whitespace\n   |\n81 |         if not self._has_privacy_notice_compliance(purpose):\n82 |             lawfulness_check['required_actions'].append('update_privacy_notice')\n83 |         \n   | ^^^^^^^^ W293\n84 |         # Check sensitive personal information handling\n85 |         if self._is_sensitive_personal_info(data_category):\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:87:1: W293 [*] Blank line contains whitespace\n   |\n85 |         if self._is_sensitive_personal_info(data_category):\n86 |             lawfulness_check['required_actions'].append('limit_sensitive_data_use')\n87 |         \n   | ^^^^^^^^ W293\n88 |         self.logger.debug(f\"CCPA lawfulness check: {lawfulness_check}\")\n89 |         return lawfulness_check\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:90:1: W293 [*] Blank line contains whitespace\n   |\n88 |         self.logger.debug(f\"CCPA lawfulness check: {lawfulness_check}\")\n89 |         return lawfulness_check\n90 |     \n   | ^^^^ W293\n91 |     def handle_data_subject_request(self, request_type: str, consumer_id: str) -> Dict[str, Any]:\n92 |         \"\"\"Handle CCPA consumer rights requests.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:94:1: W293 [*] Blank line contains whitespace\n   |\n92 |         \"\"\"Handle CCPA consumer rights requests.\"\"\"\n93 |         request_id = f\"ccpa_{request_type}_{consumer_id}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n94 |         \n   | ^^^^^^^^ W293\n95 |         response = {\n96 |             'request_id': request_id,\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:107:1: W293 [*] Blank line contains whitespace\n    |\n105 |             'verification_required': True\n106 |         }\n107 |         \n    | ^^^^^^^^ W293\n108 |         if request_type == 'access':\n109 |             # CCPA Right to Know\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:123:1: W293 [*] Blank line contains whitespace\n    |\n121 |             # CCPA Right to Limit Sensitive Personal Information\n122 |             response.update(self._handle_ccpa_limit_sensitive_request(consumer_id))\n123 |         \n    | ^^^^^^^^ W293\n124 |         self.consumer_requests.append(response)\n125 |         return response\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:126:1: W293 [*] Blank line contains whitespace\n    |\n124 |         self.consumer_requests.append(response)\n125 |         return response\n126 |     \n    | ^^^^ W293\n127 |     def _handle_ccpa_access_request(self, consumer_id: str) -> Dict[str, Any]:\n128 |         \"\"\"Handle CCPA right to know request.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:145:1: W293 [*] Blank line contains whitespace\n    |\n143 |             }\n144 |         }\n145 |     \n    | ^^^^ W293\n146 |     def _handle_ccpa_deletion_request(self, consumer_id: str) -> Dict[str, Any]:\n147 |         \"\"\"Handle CCPA right to delete request.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:150:1: W293 [*] Blank line contains whitespace\n    |\n148 |         # Check if deletion exceptions apply\n149 |         deletion_exceptions = self._check_deletion_exceptions(consumer_id)\n150 |         \n    | ^^^^^^^^ W293\n151 |         if deletion_exceptions['exceptions_apply']:\n152 |             return {\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:166:1: W293 [*] Blank line contains whitespace\n    |\n164 |                 'verification_method': 'identity_verified_through_secure_process'\n165 |             }\n166 |     \n    | ^^^^ W293\n167 |     def _handle_ccpa_opt_out_request(self, consumer_id: str) -> Dict[str, Any]:\n168 |         \"\"\"Handle CCPA opt-out request.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:176:1: W293 [*] Blank line contains whitespace\n    |\n174 |             'method': 'web_form'  # Could be 'do_not_sell_link', 'email', etc.\n175 |         }\n176 |         \n    | ^^^^^^^^ W293\n177 |         return {\n178 |             'opt_out_honored': True,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:185:1: W293 [*] Blank line contains whitespace\n    |\n183 |             'third_party_notification': 'Partners notified of opt-out status'\n184 |         }\n185 |     \n    | ^^^^ W293\n186 |     def _handle_ccpa_correction_request(self, consumer_id: str) -> Dict[str, Any]:\n187 |         \"\"\"Handle CCPA right to correct request.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:196:1: W293 [*] Blank line contains whitespace\n    |\n194 |             'third_party_correction': 'Service providers will be notified of corrections'\n195 |         }\n196 |     \n    | ^^^^ W293\n197 |     def _handle_ccpa_limit_sensitive_request(self, consumer_id: str) -> Dict[str, Any]:\n198 |         \"\"\"Handle request to limit use of sensitive personal information.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:215:1: W293 [*] Blank line contains whitespace\n    |\n213 |             'effective_date': datetime.utcnow().isoformat()\n214 |         }\n215 |     \n    | ^^^^ W293\n216 |     def create_privacy_notice_disclosure(self) -> Dict[str, Any]:\n217 |         \"\"\"Create CCPA-compliant privacy notice disclosure.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:259:1: W293 [*] Blank line contains whitespace\n    |\n257 |             'last_updated': datetime.utcnow().isoformat()\n258 |         }\n259 |     \n    | ^^^^ W293\n260 |     # Helper methods\n261 |     def _map_to_ccpa_purpose(self, purpose: str) -> Optional[CCPABusinessPurpose]:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:271:1: W293 [*] Blank line contains whitespace\n    |\n269 |         }\n270 |         return purpose_map.get(purpose)\n271 |     \n    | ^^^^ W293\n272 |     def _has_opted_out(self, consumer_id: Optional[str]) -> bool:\n273 |         \"\"\"Check if consumer has opted out of sale/sharing.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:277:1: W293 [*] Blank line contains whitespace\n    |\n275 |             return False\n276 |         return consumer_id in self.opt_out_requests\n277 |     \n    | ^^^^ W293\n278 |     def _has_privacy_notice_compliance(self, purpose: str) -> bool:\n279 |         \"\"\"Check if privacy notice adequately discloses purpose.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:282:1: W293 [*] Blank line contains whitespace\n    |\n280 |         # Simplified check - in production, verify against actual privacy notice\n281 |         return True\n282 |     \n    | ^^^^ W293\n283 |     def _is_sensitive_personal_info(self, data_category: str) -> bool:\n284 |         \"\"\"Check if data category is sensitive personal information under CCPA.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:287:27: W291 [*] Trailing whitespace\n    |\n285 |         sensitive_categories = {\n286 |             'biometric_info',\n287 |             'geolocation', \n    |                           ^ W291\n288 |             'racial_ethnic_origin',\n289 |             'religious_beliefs',\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/ccpa.py:295:1: W293 [*] Blank line contains whitespace\n    |\n293 |         }\n294 |         return data_category in sensitive_categories\n295 |     \n    | ^^^^ W293\n296 |     def _check_deletion_exceptions(self, consumer_id: str) -> Dict[str, Any]:\n297 |         \"\"\"Check if CCPA deletion exceptions apply.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:300:1: W293 [*] Blank line contains whitespace\n    |\n298 |         # CCPA Section 1798.105(d) exceptions\n299 |         exceptions = []\n300 |         \n    | ^^^^^^^^ W293\n301 |         # Check each exception\n302 |         if self._has_transaction_records(consumer_id):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:304:1: W293 [*] Blank line contains whitespace\n    |\n302 |         if self._has_transaction_records(consumer_id):\n303 |             exceptions.append('complete_transaction')\n304 |         \n    | ^^^^^^^^ W293\n305 |         if self._has_security_needs(consumer_id):\n306 |             exceptions.append('detect_security_incidents')\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:307:1: W293 [*] Blank line contains whitespace\n    |\n305 |         if self._has_security_needs(consumer_id):\n306 |             exceptions.append('detect_security_incidents')\n307 |         \n    | ^^^^^^^^ W293\n308 |         if self._has_legal_obligations(consumer_id):\n309 |             exceptions.append('comply_legal_obligation')\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:310:1: W293 [*] Blank line contains whitespace\n    |\n308 |         if self._has_legal_obligations(consumer_id):\n309 |             exceptions.append('comply_legal_obligation')\n310 |         \n    | ^^^^^^^^ W293\n311 |         if self._has_internal_research_use(consumer_id):\n312 |             exceptions.append('internal_research_compatible_with_relationship')\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:313:1: W293 [*] Blank line contains whitespace\n    |\n311 |         if self._has_internal_research_use(consumer_id):\n312 |             exceptions.append('internal_research_compatible_with_relationship')\n313 |         \n    | ^^^^^^^^ W293\n314 |         return {\n315 |             'exceptions_apply': len(exceptions) > 0,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:320:1: W293 [*] Blank line contains whitespace\n    |\n318 |             'partial_deletion': len(exceptions) > 0  # Can delete some data\n319 |         }\n320 |     \n    | ^^^^ W293\n321 |     def _get_collected_categories(self, consumer_id: str) -> List[str]:\n322 |         \"\"\"Get categories of personal information collected.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:328:1: W293 [*] Blank line contains whitespace\n    |\n326 |             CCPADataCategory.INFERENCES.value\n327 |         ]\n328 |     \n    | ^^^^ W293\n329 |     def _get_sold_shared_categories(self, consumer_id: str) -> List[str]:\n330 |         \"\"\"Get categories sold or shared.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:332:1: W293 [*] Blank line contains whitespace\n    |\n330 |         \"\"\"Get categories sold or shared.\"\"\"\n331 |         return []  # DGDN doesn't sell or share PI\n332 |     \n    | ^^^^ W293\n333 |     def _get_disclosed_categories(self, consumer_id: str) -> List[str]:\n334 |         \"\"\"Get categories disclosed for business purposes.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:339:1: W293 [*] Blank line contains whitespace\n    |\n337 |             CCPADataCategory.INTERNET_ACTIVITY.value  # For analytics\n338 |         ]\n339 |     \n    | ^^^^ W293\n340 |     def _get_business_purposes(self, consumer_id: str) -> List[str]:\n341 |         \"\"\"Get business purposes for processing.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:348:1: W293 [*] Blank line contains whitespace\n    |\n346 |             CCPABusinessPurpose.SECURITY.value\n347 |         ]\n348 |     \n    | ^^^^ W293\n349 |     def _get_collection_sources(self, consumer_id: str) -> List[str]:\n350 |         \"\"\"Get sources of personal information collection.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:356:1: W293 [*] Blank line contains whitespace\n    |\n354 |             'service_usage_data'\n355 |         ]\n356 |     \n    | ^^^^ W293\n357 |     def _get_third_parties(self, consumer_id: str) -> List[str]:\n358 |         \"\"\"Get third parties that receive personal information.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:363:1: W293 [*] Blank line contains whitespace\n    |\n361 |             'research_partners_anonymized_data_only'\n362 |         ]\n363 |     \n    | ^^^^ W293\n364 |     def _get_ccpa_retention_info(self, consumer_id: str) -> Dict[str, Any]:\n365 |         \"\"\"Get retention information per CCPA requirements.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:372:1: W293 [*] Blank line contains whitespace\n    |\n370 |             'exception_handling': 'Legal obligations may extend retention'\n371 |         }\n372 |     \n    | ^^^^ W293\n373 |     def _get_specific_pieces(self, consumer_id: str) -> Dict[str, Any]:\n374 |         \"\"\"Get specific pieces of personal information.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:381:1: W293 [*] Blank line contains whitespace\n    |\n379 |             'delivery_method': 'Secure portal or encrypted email'\n380 |         }\n381 |     \n    | ^^^^ W293\n382 |     def _get_deletable_categories(self, consumer_id: str) -> List[str]:\n383 |         \"\"\"Get categories that can be deleted.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:388:1: W293 [*] Blank line contains whitespace\n    |\n386 |             CCPADataCategory.INFERENCES.value\n387 |         ]\n388 |     \n    | ^^^^ W293\n389 |     def _get_sensitive_categories(self, consumer_id: str) -> List[str]:\n390 |         \"\"\"Get sensitive personal information categories.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:392:1: W293 [*] Blank line contains whitespace\n    |\n390 |         \"\"\"Get sensitive personal information categories.\"\"\"\n391 |         return []  # DGDN typically doesn't process sensitive PI\n392 |     \n    | ^^^^ W293\n393 |     def _has_transaction_records(self, consumer_id: str) -> bool:\n394 |         \"\"\"Check if consumer has transaction records.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:396:1: W293 [*] Blank line contains whitespace\n    |\n394 |         \"\"\"Check if consumer has transaction records.\"\"\"\n395 |         return False  # DGDN is research-focused, not transactional\n396 |     \n    | ^^^^ W293\n397 |     def _has_security_needs(self, consumer_id: str) -> bool:\n398 |         \"\"\"Check if data needed for security purposes.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:400:1: W293 [*] Blank line contains whitespace\n    |\n398 |         \"\"\"Check if data needed for security purposes.\"\"\"\n399 |         return True  # Always need some data for security\n400 |     \n    | ^^^^ W293\n401 |     def _has_legal_obligations(self, consumer_id: str) -> bool:\n402 |         \"\"\"Check if legal obligations require data retention.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:404:1: W293 [*] Blank line contains whitespace\n    |\n402 |         \"\"\"Check if legal obligations require data retention.\"\"\"\n403 |         return False  # Simplified - would check actual legal requirements\n404 |     \n    | ^^^^ W293\n405 |     def _has_internal_research_use(self, consumer_id: str) -> bool:\n406 |         \"\"\"Check if data used for internal research.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/ccpa.py:407:58: W292 [*] No newline at end of file\n    |\n405 |     def _has_internal_research_use(self, consumer_id: str) -> bool:\n406 |         \"\"\"Check if data used for internal research.\"\"\"\n407 |         return True  # DGDN's primary purpose is research\n    |                                                          ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/compliance/data_protection.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n  |\n1 |   \"\"\"Data protection manager for multi-region compliance.\"\"\"\n2 |\n3 | / import logging\n4 | | import hashlib\n5 | | from datetime import datetime, timedelta\n6 | | from typing import Dict, Any, List, Optional, Set, Union\n7 | | from enum import Enum\n8 | | import torch\n  | |____________^ I001\n  |\n  = help: Organize imports\n\nsrc/dgdn/compliance/data_protection.py:6:37: F401 [*] `typing.Optional` imported but unused\n  |\n4 | import hashlib\n5 | from datetime import datetime, timedelta\n6 | from typing import Dict, Any, List, Optional, Set, Union\n  |                                     ^^^^^^^^ F401\n7 | from enum import Enum\n8 | import torch\n  |\n  = help: Remove unused import\n\nsrc/dgdn/compliance/data_protection.py:6:47: F401 [*] `typing.Set` imported but unused\n  |\n4 | import hashlib\n5 | from datetime import datetime, timedelta\n6 | from typing import Dict, Any, List, Optional, Set, Union\n  |                                               ^^^ F401\n7 | from enum import Enum\n8 | import torch\n  |\n  = help: Remove unused import\n\nsrc/dgdn/compliance/data_protection.py:6:52: F401 [*] `typing.Union` imported but unused\n  |\n4 | import hashlib\n5 | from datetime import datetime, timedelta\n6 | from typing import Dict, Any, List, Optional, Set, Union\n  |                                                    ^^^^^ F401\n7 | from enum import Enum\n8 | import torch\n  |\n  = help: Remove unused import\n\nsrc/dgdn/compliance/data_protection.py:29:1: W293 [*] Blank line contains whitespace\n   |\n27 | class DataProtectionManager:\n28 |     \"\"\"Multi-region data protection manager.\"\"\"\n29 |     \n   | ^^^^ W293\n30 |     def __init__(self, region: str = \"global\", compliance_regimes: List[str] = None):\n31 |         \"\"\"Initialize data protection manager.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:35:1: W293 [*] Blank line contains whitespace\n   |\n33 |         self.compliance_regimes = compliance_regimes or [\"gdpr\", \"ccpa\", \"pdpa\"]\n34 |         self.logger = logging.getLogger(__name__)\n35 |         \n   | ^^^^^^^^ W293\n36 |         # Protection policies by region and data type\n37 |         self.protection_policies = self._initialize_protection_policies()\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:38:1: W293 [*] Blank line contains whitespace\n   |\n36 |         # Protection policies by region and data type\n37 |         self.protection_policies = self._initialize_protection_policies()\n38 |         \n   | ^^^^^^^^ W293\n39 |         # Encryption keys (in production, use proper key management)\n40 |         self.encryption_keys = self._initialize_encryption()\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:41:1: W293 [*] Blank line contains whitespace\n   |\n39 |         # Encryption keys (in production, use proper key management)\n40 |         self.encryption_keys = self._initialize_encryption()\n41 |         \n   | ^^^^^^^^ W293\n42 |         # Audit trail\n43 |         self.audit_log = []\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:44:1: W293 [*] Blank line contains whitespace\n   |\n42 |         # Audit trail\n43 |         self.audit_log = []\n44 |         \n   | ^^^^^^^^ W293\n45 |         self.logger.info(f\"Data protection manager initialized for region: {region}\")\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:46:1: W293 [*] Blank line contains whitespace\n   |\n45 |         self.logger.info(f\"Data protection manager initialized for region: {region}\")\n46 |     \n   | ^^^^ W293\n47 |     def _initialize_protection_policies(self) -> Dict[str, Dict[str, Any]]:\n48 |         \"\"\"Initialize protection policies for different regions.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:87:1: W293 [*] Blank line contains whitespace\n   |\n85 |             }\n86 |         }\n87 |     \n   | ^^^^ W293\n88 |     def _initialize_encryption(self) -> Dict[str, Any]:\n89 |         \"\"\"Initialize encryption system.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:96:1: W293 [*] Blank line contains whitespace\n   |\n94 |             \"initialized\": datetime.utcnow().isoformat()\n95 |         }\n96 |     \n   | ^^^^ W293\n97 |     def classify_data_protection_level(self, data: Any, context: Dict[str, Any] = None) -> DataProtectionLevel:\n98 |         \"\"\"Classify data protection level based on content and context.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:100:1: W293 [*] Blank line contains whitespace\n    |\n 98 |         \"\"\"Classify data protection level based on content and context.\"\"\"\n 99 |         context = context or {}\n100 |         \n    | ^^^^^^^^ W293\n101 |         # Default classification\n102 |         protection_level = DataProtectionLevel.INTERNAL\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:103:1: W293 [*] Blank line contains whitespace\n    |\n101 |         # Default classification\n102 |         protection_level = DataProtectionLevel.INTERNAL\n103 |         \n    | ^^^^^^^^ W293\n104 |         # Check for sensitive indicators\n105 |         if self._contains_personal_identifiers(data, context):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:107:1: W293 [*] Blank line contains whitespace\n    |\n105 |         if self._contains_personal_identifiers(data, context):\n106 |             protection_level = DataProtectionLevel.CONFIDENTIAL\n107 |         \n    | ^^^^^^^^ W293\n108 |         if self._contains_sensitive_personal_data(data, context):\n109 |             protection_level = DataProtectionLevel.RESTRICTED\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:110:1: W293 [*] Blank line contains whitespace\n    |\n108 |         if self._contains_sensitive_personal_data(data, context):\n109 |             protection_level = DataProtectionLevel.RESTRICTED\n110 |         \n    | ^^^^^^^^ W293\n111 |         if context.get('data_category') == 'public':\n112 |             protection_level = DataProtectionLevel.PUBLIC\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:113:1: W293 [*] Blank line contains whitespace\n    |\n111 |         if context.get('data_category') == 'public':\n112 |             protection_level = DataProtectionLevel.PUBLIC\n113 |         \n    | ^^^^^^^^ W293\n114 |         # Apply regional policy\n115 |         regional_policy = self.protection_policies.get(self.region, self.protection_policies[\"global\"])\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:117:1: W293 [*] Blank line contains whitespace\n    |\n115 |         regional_policy = self.protection_policies.get(self.region, self.protection_policies[\"global\"])\n116 |         min_level = regional_policy[\"min_protection_level\"]\n117 |         \n    | ^^^^^^^^ W293\n118 |         # Use higher protection level\n119 |         levels = [DataProtectionLevel.PUBLIC, DataProtectionLevel.INTERNAL, \n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:119:76: W291 [*] Trailing whitespace\n    |\n118 |         # Use higher protection level\n119 |         levels = [DataProtectionLevel.PUBLIC, DataProtectionLevel.INTERNAL, \n    |                                                                            ^ W291\n120 |                  DataProtectionLevel.CONFIDENTIAL, DataProtectionLevel.RESTRICTED]\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/data_protection.py:121:1: W293 [*] Blank line contains whitespace\n    |\n119 |         levels = [DataProtectionLevel.PUBLIC, DataProtectionLevel.INTERNAL, \n120 |                  DataProtectionLevel.CONFIDENTIAL, DataProtectionLevel.RESTRICTED]\n121 |         \n    | ^^^^^^^^ W293\n122 |         current_index = levels.index(protection_level)\n123 |         min_index = levels.index(min_level)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:124:1: W293 [*] Blank line contains whitespace\n    |\n122 |         current_index = levels.index(protection_level)\n123 |         min_index = levels.index(min_level)\n124 |         \n    | ^^^^^^^^ W293\n125 |         final_level = levels[max(current_index, min_index)]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:126:1: W293 [*] Blank line contains whitespace\n    |\n125 |         final_level = levels[max(current_index, min_index)]\n126 |         \n    | ^^^^^^^^ W293\n127 |         self._log_audit_event(\"data_classification\", {\n128 |             \"protection_level\": final_level.value,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:132:1: W293 [*] Blank line contains whitespace\n    |\n130 |             \"region\": self.region\n131 |         })\n132 |         \n    | ^^^^^^^^ W293\n133 |         return final_level\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:134:1: W293 [*] Blank line contains whitespace\n    |\n133 |         return final_level\n134 |     \n    | ^^^^ W293\n135 |     def apply_data_protection(self, data: Any, protection_level: DataProtectionLevel, \n136 |                             purpose: str) -> Dict[str, Any]:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:135:86: W291 [*] Trailing whitespace\n    |\n133 |         return final_level\n134 |     \n135 |     def apply_data_protection(self, data: Any, protection_level: DataProtectionLevel, \n    |                                                                                      ^ W291\n136 |                             purpose: str) -> Dict[str, Any]:\n137 |         \"\"\"Apply appropriate data protection measures.\"\"\"\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/data_protection.py:148:1: W293 [*] Blank line contains whitespace\n    |\n146 |             }\n147 |         }\n148 |         \n    | ^^^^^^^^ W293\n149 |         # Apply protections based on level\n150 |         if protection_level in [DataProtectionLevel.CONFIDENTIAL, DataProtectionLevel.RESTRICTED]:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:156:1: W293 [*] Blank line contains whitespace\n    |\n154 |             protected_data[\"encryption_metadata\"] = encrypted_data[\"metadata\"]\n155 |             protected_data[\"protections_applied\"].append(\"encryption\")\n156 |             \n    | ^^^^^^^^^^^^ W293\n157 |             # Apply pseudonymization if required\n158 |             regional_policy = self.protection_policies.get(self.region, self.protection_policies[\"global\"])\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:164:1: W293 [*] Blank line contains whitespace\n    |\n162 |                 protected_data[\"pseudonym_mapping\"] = pseudonym_data[\"mapping\"]\n163 |                 protected_data[\"protections_applied\"].append(\"pseudonymization\")\n164 |         \n    | ^^^^^^^^ W293\n165 |         if protection_level == DataProtectionLevel.RESTRICTED:\n166 |             # Apply additional protections for restricted data\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:171:1: W293 [*] Blank line contains whitespace\n    |\n169 |             protected_data[\"anonymization_metadata\"] = anonymized_data[\"metadata\"]\n170 |             protected_data[\"protections_applied\"].append(\"anonymization\")\n171 |             \n    | ^^^^^^^^^^^^ W293\n172 |             # Apply differential privacy\n173 |             if isinstance(data, torch.Tensor):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:178:1: W293 [*] Blank line contains whitespace\n    |\n176 |                 protected_data[\"privacy_budget\"] = dp_data[\"epsilon\"]\n177 |                 protected_data[\"protections_applied\"].append(\"differential_privacy\")\n178 |         \n    | ^^^^^^^^ W293\n179 |         # Log protection application\n180 |         self._log_audit_event(\"protection_applied\", {\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:185:1: W293 [*] Blank line contains whitespace\n    |\n183 |             \"purpose\": purpose\n184 |         })\n185 |         \n    | ^^^^^^^^ W293\n186 |         return protected_data\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:187:1: W293 [*] Blank line contains whitespace\n    |\n186 |         return protected_data\n187 |     \n    | ^^^^ W293\n188 |     def _encrypt_data(self, data: Any, method: EncryptionMethod) -> Dict[str, Any]:\n189 |         \"\"\"Encrypt data using specified method.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:194:1: W293 [*] Blank line contains whitespace\n    |\n192 |             data_bytes = data.cpu().numpy().tobytes()\n193 |             encrypted_hash = hashlib.sha256(data_bytes + b\"encryption_key\").hexdigest()\n194 |             \n    | ^^^^^^^^^^^^ W293\n195 |             return {\n196 |                 \"encrypted_data\": encrypted_hash,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:208:1: W293 [*] Blank line contains whitespace\n    |\n206 |             data_str = str(data)\n207 |             encrypted_hash = hashlib.sha256(data_str.encode() + b\"encryption_key\").hexdigest()\n208 |             \n    | ^^^^^^^^^^^^ W293\n209 |             return {\n210 |                 \"encrypted_data\": encrypted_hash,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:217:1: W293 [*] Blank line contains whitespace\n    |\n215 |                 }\n216 |             }\n217 |     \n    | ^^^^ W293\n218 |     def _pseudonymize_data(self, data: Any) -> Dict[str, Any]:\n219 |         \"\"\"Create pseudonymized version of data.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:224:1: W293 [*] Blank line contains whitespace\n    |\n222 |             unique_values = torch.unique(data.flatten())\n223 |             pseudonym_mapping = {}\n224 |             \n    | ^^^^^^^^^^^^ W293\n225 |             for i, value in enumerate(unique_values):\n226 |                 pseudonym_hash = hashlib.sha256(f\"pseudonym_{value.item()}\".encode()).hexdigest()[:8]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:225:17: B007 Loop control variable `i` not used within loop body\n    |\n223 |             pseudonym_mapping = {}\n224 |             \n225 |             for i, value in enumerate(unique_values):\n    |                 ^ B007\n226 |                 pseudonym_hash = hashlib.sha256(f\"pseudonym_{value.item()}\".encode()).hexdigest()[:8]\n227 |                 pseudonym_mapping[value.item()] = pseudonym_hash\n    |\n    = help: Rename unused `i` to `_i`\n\nsrc/dgdn/compliance/data_protection.py:228:1: W293 [*] Blank line contains whitespace\n    |\n226 |                 pseudonym_hash = hashlib.sha256(f\"pseudonym_{value.item()}\".encode()).hexdigest()[:8]\n227 |                 pseudonym_mapping[value.item()] = pseudonym_hash\n228 |             \n    | ^^^^^^^^^^^^ W293\n229 |             # Apply pseudonymization (simplified)\n230 |             pseudonymized = data.clone().float()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:234:1: W293 [*] Blank line contains whitespace\n    |\n232 |                 mask = data == original\n233 |                 pseudonymized[mask] = hash(pseudo) % 10000  # Simple numeric pseudonym\n234 |             \n    | ^^^^^^^^^^^^ W293\n235 |             return {\n236 |                 \"pseudonymized\": pseudonymized,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:248:1: W293 [*] Blank line contains whitespace\n    |\n246 |                 \"method\": \"hash_based\"\n247 |             }\n248 |     \n    | ^^^^ W293\n249 |     def _anonymize_data(self, data: Any) -> Dict[str, Any]:\n250 |         \"\"\"Create anonymized version of data.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:255:1: W293 [*] Blank line contains whitespace\n    |\n253 |             k = 3  # K-anonymity parameter\n254 |             anonymized = data.clone()\n255 |             \n    | ^^^^^^^^^^^^ W293\n256 |             # Generalize values to achieve k-anonymity\n257 |             if data.numel() > k:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:261:1: W293 [*] Blank line contains whitespace\n    |\n259 |                 sorted_data, indices = torch.sort(data.flatten())\n260 |                 group_size = len(sorted_data) // k\n261 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n262 |                 for i in range(0, len(sorted_data), group_size):\n263 |                     end_idx = min(i + group_size, len(sorted_data))\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:265:1: W293 [*] Blank line contains whitespace\n    |\n263 |                     end_idx = min(i + group_size, len(sorted_data))\n264 |                     group_mean = torch.mean(sorted_data[i:end_idx])\n265 |                     \n    | ^^^^^^^^^^^^^^^^^^^^ W293\n266 |                     # Replace group values with mean\n267 |                     for j in range(i, end_idx):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:270:1: W293 [*] Blank line contains whitespace\n    |\n268 |                         original_pos = indices[j]\n269 |                         anonymized.flatten()[original_pos] = group_mean\n270 |             \n    | ^^^^^^^^^^^^ W293\n271 |             return {\n272 |                 \"anonymized\": anonymized,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:288:1: W293 [*] Blank line contains whitespace\n    |\n286 |                 }\n287 |             }\n288 |     \n    | ^^^^ W293\n289 |     def _apply_differential_privacy(self, data: torch.Tensor, epsilon: float = 1.0) -> Dict[str, Any]:\n290 |         \"\"\"Apply differential privacy to tensor data.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:293:1: W293 [*] Blank line contains whitespace\n    |\n291 |         sensitivity = 1.0  # L2 sensitivity\n292 |         noise_scale = sensitivity / epsilon\n293 |         \n    | ^^^^^^^^ W293\n294 |         # Add calibrated Gaussian noise\n295 |         noise = torch.randn_like(data) * noise_scale\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:297:1: W293 [*] Blank line contains whitespace\n    |\n295 |         noise = torch.randn_like(data) * noise_scale\n296 |         noisy_data = data + noise\n297 |         \n    | ^^^^^^^^ W293\n298 |         return {\n299 |             \"noisy_data\": noisy_data,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:306:1: W293 [*] Blank line contains whitespace\n    |\n304 |             \"method\": \"gaussian_mechanism\"\n305 |         }\n306 |     \n    | ^^^^ W293\n307 |     def check_cross_border_transfer_compliance(self, target_region: str, \n308 |                                              data_category: str) -> Dict[str, Any]:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:307:73: W291 [*] Trailing whitespace\n    |\n305 |         }\n306 |     \n307 |     def check_cross_border_transfer_compliance(self, target_region: str, \n    |                                                                         ^ W291\n308 |                                              data_category: str) -> Dict[str, Any]:\n309 |         \"\"\"Check if cross-border transfer is compliant.\"\"\"\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/data_protection.py:311:9: F841 Local variable `target_policy` is assigned to but never used\n    |\n309 |         \"\"\"Check if cross-border transfer is compliant.\"\"\"\n310 |         source_policy = self.protection_policies.get(self.region, self.protection_policies[\"global\"])\n311 |         target_policy = self.protection_policies.get(target_region, self.protection_policies[\"global\"])\n    |         ^^^^^^^^^^^^^ F841\n312 |         \n313 |         compliance_check = {\n    |\n    = help: Remove assignment to unused variable `target_policy`\n\nsrc/dgdn/compliance/data_protection.py:312:1: W293 [*] Blank line contains whitespace\n    |\n310 |         source_policy = self.protection_policies.get(self.region, self.protection_policies[\"global\"])\n311 |         target_policy = self.protection_policies.get(target_region, self.protection_policies[\"global\"])\n312 |         \n    | ^^^^^^^^ W293\n313 |         compliance_check = {\n314 |             \"transfer_allowed\": True,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:319:1: W293 [*] Blank line contains whitespace\n    |\n317 |             \"adequacy_decision\": False\n318 |         }\n319 |         \n    | ^^^^^^^^ W293\n320 |         # Check if source region has cross-border restrictions\n321 |         if source_policy.get(\"cross_border_restrictions\"):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:323:1: W293 [*] Blank line contains whitespace\n    |\n321 |         if source_policy.get(\"cross_border_restrictions\"):\n322 |             compliance_check[\"requirements\"].append(\"adequacy_decision_or_safeguards\")\n323 |             \n    | ^^^^^^^^^^^^ W293\n324 |             # Check adequacy (simplified - would use real adequacy decisions)\n325 |             adequate_regions = {\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:329:1: W293 [*] Blank line contains whitespace\n    |\n327 |                 \"sg\": [\"eu\"]   # Reciprocal\n328 |             }\n329 |             \n    | ^^^^^^^^^^^^ W293\n330 |             if target_region in adequate_regions.get(self.region, []):\n331 |                 compliance_check[\"adequacy_decision\"] = True\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:338:1: W293 [*] Blank line contains whitespace\n    |\n336 |                     \"certification_mechanism\"\n337 |                 ])\n338 |         \n    | ^^^^^^^^ W293\n339 |         # Additional protections for sensitive data\n340 |         if data_category in [\"sensitive_personal_data\", \"special_category\"]:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:346:1: W293 [*] Blank line contains whitespace\n    |\n344 |                 \"audit_logging\"\n345 |             ])\n346 |         \n    | ^^^^^^^^ W293\n347 |         self._log_audit_event(\"transfer_compliance_check\", {\n348 |             \"source_region\": self.region,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:353:1: W293 [*] Blank line contains whitespace\n    |\n351 |             \"allowed\": compliance_check[\"transfer_allowed\"]\n352 |         })\n353 |         \n    | ^^^^^^^^ W293\n354 |         return compliance_check\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:355:1: W293 [*] Blank line contains whitespace\n    |\n354 |         return compliance_check\n355 |     \n    | ^^^^ W293\n356 |     def apply_retention_policy(self, data_age: timedelta, data_category: str, \n357 |                              purpose: str) -> Dict[str, Any]:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:356:78: W291 [*] Trailing whitespace\n    |\n354 |         return compliance_check\n355 |     \n356 |     def apply_retention_policy(self, data_age: timedelta, data_category: str, \n    |                                                                              ^ W291\n357 |                              purpose: str) -> Dict[str, Any]:\n358 |         \"\"\"Apply data retention policy.\"\"\"\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/data_protection.py:361:1: W293 [*] Blank line contains whitespace\n    |\n359 |         regional_policy = self.protection_policies.get(self.region, self.protection_policies[\"global\"])\n360 |         retention_limits = regional_policy.get(\"retention_limits\", {})\n361 |         \n    | ^^^^^^^^ W293\n362 |         # Determine retention period\n363 |         retention_period = timedelta(days=retention_limits.get(data_category, \n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:363:78: W291 [*] Trailing whitespace\n    |\n362 |         # Determine retention period\n363 |         retention_period = timedelta(days=retention_limits.get(data_category, \n    |                                                                              ^ W291\n364 |                                                              retention_limits.get(\"default\", 1095)))\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/data_protection.py:365:1: W293 [*] Blank line contains whitespace\n    |\n363 |         retention_period = timedelta(days=retention_limits.get(data_category, \n364 |                                                              retention_limits.get(\"default\", 1095)))\n365 |         \n    | ^^^^^^^^ W293\n366 |         retention_decision = {\n367 |             \"retain\": data_age < retention_period,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:372:1: W293 [*] Blank line contains whitespace\n    |\n370 |             \"action_required\": \"none\"\n371 |         }\n372 |         \n    | ^^^^^^^^ W293\n373 |         if data_age >= retention_period:\n374 |             retention_decision[\"action_required\"] = \"delete_or_anonymize\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:379:1: W293 [*] Blank line contains whitespace\n    |\n377 |             retention_decision[\"action_required\"] = \"review_retention_need\"\n378 |             retention_decision[\"review_date\"] = (datetime.utcnow() + timedelta(days=30)).isoformat()\n379 |         \n    | ^^^^^^^^ W293\n380 |         self._log_audit_event(\"retention_policy_applied\", {\n381 |             \"data_category\": data_category,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:386:1: W293 [*] Blank line contains whitespace\n    |\n384 |             \"action\": retention_decision[\"action_required\"]\n385 |         })\n386 |         \n    | ^^^^^^^^ W293\n387 |         return retention_decision\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:388:1: W293 [*] Blank line contains whitespace\n    |\n387 |         return retention_decision\n388 |     \n    | ^^^^ W293\n389 |     def _contains_personal_identifiers(self, data: Any, context: Dict[str, Any]) -> bool:\n390 |         \"\"\"Check if data contains personal identifiers.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:394:1: W293 [*] Blank line contains whitespace\n    |\n392 |         if context.get(\"contains_pii\", False):\n393 |             return True\n394 |         \n    | ^^^^^^^^ W293\n395 |         if isinstance(data, torch.Tensor):\n396 |             # Check for patterns that might indicate IDs\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:400:1: W293 [*] Blank line contains whitespace\n    |\n398 |                 if context.get(\"data_type\") in [\"user_ids\", \"node_ids\"]:\n399 |                     return True\n400 |         \n    | ^^^^^^^^ W293\n401 |         return False\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:402:1: W293 [*] Blank line contains whitespace\n    |\n401 |         return False\n402 |     \n    | ^^^^ W293\n403 |     def _contains_sensitive_personal_data(self, data: Any, context: Dict[str, Any]) -> bool:\n404 |         \"\"\"Check if data contains sensitive personal information.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:406:66: W291 [*] Trailing whitespace\n    |\n404 |         \"\"\"Check if data contains sensitive personal information.\"\"\"\n405 |         sensitive_indicators = [\n406 |             \"biometric\", \"health\", \"genetic\", \"racial\", \"ethnic\", \n    |                                                                  ^ W291\n407 |             \"political\", \"religious\", \"sexual\", \"criminal\"\n408 |         ]\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/data_protection.py:409:1: W293 [*] Blank line contains whitespace\n    |\n407 |             \"political\", \"religious\", \"sexual\", \"criminal\"\n408 |         ]\n409 |         \n    | ^^^^^^^^ W293\n410 |         data_description = context.get(\"description\", \"\").lower()\n411 |         return any(indicator in data_description for indicator in sensitive_indicators)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:412:1: W293 [*] Blank line contains whitespace\n    |\n410 |         data_description = context.get(\"description\", \"\").lower()\n411 |         return any(indicator in data_description for indicator in sensitive_indicators)\n412 |     \n    | ^^^^ W293\n413 |     def _log_audit_event(self, event_type: str, details: Dict[str, Any]):\n414 |         \"\"\"Log audit event.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:421:1: W293 [*] Blank line contains whitespace\n    |\n419 |             \"details\": details\n420 |         }\n421 |         \n    | ^^^^^^^^ W293\n422 |         self.audit_log.append(audit_entry)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:423:1: W293 [*] Blank line contains whitespace\n    |\n422 |         self.audit_log.append(audit_entry)\n423 |         \n    | ^^^^^^^^ W293\n424 |         # Keep only recent audit entries\n425 |         if len(self.audit_log) > 1000:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:427:1: W293 [*] Blank line contains whitespace\n    |\n425 |         if len(self.audit_log) > 1000:\n426 |             self.audit_log = self.audit_log[-1000:]\n427 |         \n    | ^^^^^^^^ W293\n428 |         self.logger.debug(f\"Audit event logged: {event_type}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:429:1: W293 [*] Blank line contains whitespace\n    |\n428 |         self.logger.debug(f\"Audit event logged: {event_type}\")\n429 |     \n    | ^^^^ W293\n430 |     def get_protection_report(self) -> Dict[str, Any]:\n431 |         \"\"\"Generate data protection compliance report.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:441:1: W293 [*] Blank line contains whitespace\n    |\n439 |             \"report_generated\": datetime.utcnow().isoformat()\n440 |         }\n441 |     \n    | ^^^^ W293\n442 |     def validate_compliance_configuration(self) -> Dict[str, Any]:\n443 |         \"\"\"Validate current compliance configuration.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:450:1: W293 [*] Blank line contains whitespace\n    |\n448 |             \"recommendations\": []\n449 |         }\n450 |         \n    | ^^^^^^^^ W293\n451 |         # Check regional policy exists\n452 |         if self.region not in self.protection_policies:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:454:1: W293 [*] Blank line contains whitespace\n    |\n452 |         if self.region not in self.protection_policies:\n453 |             validation_results[\"warnings\"].append(f\"No specific policy for region '{self.region}', using global policy\")\n454 |         \n    | ^^^^^^^^ W293\n455 |         # Check encryption is available\n456 |         if not self.encryption_keys.get(\"initialized\"):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:459:1: W293 [*] Blank line contains whitespace\n    |\n457 |             validation_results[\"errors\"].append(\"Encryption system not properly initialized\")\n458 |             validation_results[\"valid\"] = False\n459 |         \n    | ^^^^^^^^ W293\n460 |         # Check compliance regime coverage\n461 |         supported_regimes = [\"gdpr\", \"ccpa\", \"pdpa\"]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:465:1: W293 [*] Blank line contains whitespace\n    |\n463 |             if regime not in supported_regimes:\n464 |                 validation_results[\"warnings\"].append(f\"Compliance regime '{regime}' not fully supported\")\n465 |         \n    | ^^^^^^^^ W293\n466 |         # Recommendations\n467 |         validation_results[\"recommendations\"].extend([\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:473:1: W293 [*] Blank line contains whitespace\n    |\n471 |             \"Enable real-time compliance monitoring\"\n472 |         ])\n473 |         \n    | ^^^^^^^^ W293\n474 |         return validation_results\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/data_protection.py:474:34: W292 [*] No newline at end of file\n    |\n472 |         ])\n473 |         \n474 |         return validation_results\n    |                                  ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/compliance/gdpr.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n  |\n1 |   \"\"\"GDPR compliance implementation for DGDN.\"\"\"\n2 |\n3 | / import logging\n4 | | from datetime import datetime, timedelta\n5 | | from typing import Dict, Any, List, Optional\n6 | | from enum import Enum\n  | |_____________________^ I001\n  |\n  = help: Organize imports\n\nsrc/dgdn/compliance/gdpr.py:28:1: W293 [*] Blank line contains whitespace\n   |\n26 | class GDPRCompliance:\n27 |     \"\"\"GDPR compliance system for DGDN.\"\"\"\n28 |     \n   | ^^^^ W293\n29 |     def __init__(self):\n30 |         \"\"\"Initialize GDPR compliance system.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:35:1: W293 [*] Blank line contains whitespace\n   |\n33 |         self.processing_records = []\n34 |         self.data_subject_requests = []\n35 |         \n   | ^^^^^^^^ W293\n36 |         # GDPR compliance settings\n37 |         self.retention_periods = {\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:42:1: W293 [*] Blank line contains whitespace\n   |\n40 |             'criminal_data': timedelta(days=2555)    # 7 years\n41 |         }\n42 |         \n   | ^^^^^^^^ W293\n43 |         self.logger.info(\"GDPR compliance system initialized\")\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:44:1: W293 [*] Blank line contains whitespace\n   |\n43 |         self.logger.info(\"GDPR compliance system initialized\")\n44 |     \n   | ^^^^ W293\n45 |     def check_processing_lawfulness(self, data_category: str, purpose: str, \n46 |                                   data_subject_id: Optional[str] = None) -> Dict[str, Any]:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:45:76: W291 [*] Trailing whitespace\n   |\n43 |         self.logger.info(\"GDPR compliance system initialized\")\n44 |     \n45 |     def check_processing_lawfulness(self, data_category: str, purpose: str, \n   |                                                                            ^ W291\n46 |                                   data_subject_id: Optional[str] = None) -> Dict[str, Any]:\n47 |         \"\"\"Check if data processing is lawful under GDPR.\"\"\"\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/gdpr.py:54:1: W293 [*] Blank line contains whitespace\n   |\n52 |             'note': ''\n53 |         }\n54 |         \n   | ^^^^^^^^ W293\n55 |         # Determine appropriate legal basis\n56 |         if data_category == 'special_category':\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:64:1: W293 [*] Blank line contains whitespace\n   |\n62 |                 lawfulness_check['required_actions'].append('obtain_explicit_consent')\n63 |                 lawfulness_check['note'] = 'Special category data requires explicit consent'\n64 |         \n   | ^^^^^^^^ W293\n65 |         elif purpose in ['research', 'ml_training']:\n66 |             # Research purposes can use legitimate interests with safeguards\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:71:1: W293 [*] Blank line contains whitespace\n   |\n69 |             lawfulness_check['required_actions'].append('conduct_balancing_test')\n70 |             lawfulness_check['required_actions'].append('implement_safeguards')\n71 |         \n   | ^^^^^^^^ W293\n72 |         elif purpose in ['analytics', 'performance']:\n73 |             # Performance optimization can use legitimate interests\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:77:1: W293 [*] Blank line contains whitespace\n   |\n75 |             lawfulness_check['legal_basis'].append(GDPRLegalBasis.LEGITIMATE_INTERESTS.value)\n76 |             lawfulness_check['required_actions'].append('provide_opt_out')\n77 |         \n   | ^^^^^^^^ W293\n78 |         else:\n79 |             # Default to consent requirement\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:85:1: W293 [*] Blank line contains whitespace\n   |\n83 |             else:\n84 |                 lawfulness_check['required_actions'].append('obtain_consent')\n85 |         \n   | ^^^^^^^^ W293\n86 |         # Check data minimization compliance\n87 |         if not self._check_data_minimization(purpose):\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:89:1: W293 [*] Blank line contains whitespace\n   |\n87 |         if not self._check_data_minimization(purpose):\n88 |             lawfulness_check['required_actions'].append('apply_data_minimization')\n89 |         \n   | ^^^^^^^^ W293\n90 |         # Check retention compliance\n91 |         if not self._check_retention_compliance(data_category):\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:93:1: W293 [*] Blank line contains whitespace\n   |\n91 |         if not self._check_retention_compliance(data_category):\n92 |             lawfulness_check['required_actions'].append('review_retention_policy')\n93 |         \n   | ^^^^^^^^ W293\n94 |         self.logger.debug(f\"GDPR lawfulness check: {lawfulness_check}\")\n95 |         return lawfulness_check\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:96:1: W293 [*] Blank line contains whitespace\n   |\n94 |         self.logger.debug(f\"GDPR lawfulness check: {lawfulness_check}\")\n95 |         return lawfulness_check\n96 |     \n   | ^^^^ W293\n97 |     def record_consent(self, consent_record: Dict[str, Any]):\n98 |         \"\"\"Record consent under GDPR requirements.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:115:1: W293 [*] Blank line contains whitespace\n    |\n113 |             }\n114 |         }\n115 |         \n    | ^^^^^^^^ W293\n116 |         self.consent_records[consent_record['consent_id']] = gdpr_consent\n117 |         self.logger.info(f\"GDPR-compliant consent recorded: {consent_record['consent_id']}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:118:1: W293 [*] Blank line contains whitespace\n    |\n116 |         self.consent_records[consent_record['consent_id']] = gdpr_consent\n117 |         self.logger.info(f\"GDPR-compliant consent recorded: {consent_record['consent_id']}\")\n118 |     \n    | ^^^^ W293\n119 |     def handle_data_subject_request(self, request_type: str, data_subject_id: str) -> Dict[str, Any]:\n120 |         \"\"\"Handle GDPR data subject rights requests.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:122:1: W293 [*] Blank line contains whitespace\n    |\n120 |         \"\"\"Handle GDPR data subject rights requests.\"\"\"\n121 |         request_id = f\"gdpr_{request_type}_{data_subject_id}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n122 |         \n    | ^^^^^^^^ W293\n123 |         response = {\n124 |             'request_id': request_id,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:132:1: W293 [*] Blank line contains whitespace\n    |\n130 |             'status': 'processing'\n131 |         }\n132 |         \n    | ^^^^^^^^ W293\n133 |         if request_type == 'access':\n134 |             # Article 15 - Right of access\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:151:1: W293 [*] Blank line contains whitespace\n    |\n149 |             # Article 21 - Right to object\n150 |             response.update(self._handle_gdpr_objection_request(data_subject_id))\n151 |         \n    | ^^^^^^^^ W293\n152 |         self.data_subject_requests.append(response)\n153 |         return response\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:154:1: W293 [*] Blank line contains whitespace\n    |\n152 |         self.data_subject_requests.append(response)\n153 |         return response\n154 |     \n    | ^^^^ W293\n155 |     def _handle_gdpr_access_request(self, data_subject_id: str) -> Dict[str, Any]:\n156 |         \"\"\"Handle GDPR Article 15 access request.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:172:1: W293 [*] Blank line contains whitespace\n    |\n170 |             }\n171 |         }\n172 |     \n    | ^^^^ W293\n173 |     def _handle_gdpr_erasure_request(self, data_subject_id: str) -> Dict[str, Any]:\n174 |         \"\"\"Handle GDPR Article 17 erasure request.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:177:1: W293 [*] Blank line contains whitespace\n    |\n175 |         # Check if erasure is possible\n176 |         erasure_grounds = self._check_erasure_grounds(data_subject_id)\n177 |         \n    | ^^^^^^^^ W293\n178 |         if erasure_grounds['erasure_possible']:\n179 |             return {\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:192:1: W293 [*] Blank line contains whitespace\n    |\n190 |                 'alternative_measures': 'Data processing restricted where possible'\n191 |             }\n192 |     \n    | ^^^^ W293\n193 |     def _handle_gdpr_portability_request(self, data_subject_id: str) -> Dict[str, Any]:\n194 |         \"\"\"Handle GDPR Article 20 portability request.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:197:1: W293 [*] Blank line contains whitespace\n    |\n195 |         # Only applies to data processed by automated means based on consent or contract\n196 |         portable_data = self._get_portable_data(data_subject_id)\n197 |         \n    | ^^^^^^^^ W293\n198 |         return {\n199 |             'data_portable': len(portable_data) > 0,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:207:1: W293 [*] Blank line contains whitespace\n    |\n205 |             'export_data': portable_data\n206 |         }\n207 |     \n    | ^^^^ W293\n208 |     def _handle_gdpr_restriction_request(self, data_subject_id: str) -> Dict[str, Any]:\n209 |         \"\"\"Handle GDPR Article 18 restriction request.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:216:1: W293 [*] Blank line contains whitespace\n    |\n214 |             'notification_requirement': 'Data subject will be informed before lifting restriction'\n215 |         }\n216 |     \n    | ^^^^ W293\n217 |     def _handle_gdpr_objection_request(self, data_subject_id: str) -> Dict[str, Any]:\n218 |         \"\"\"Handle GDPR Article 21 objection request.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:221:1: W293 [*] Blank line contains whitespace\n    |\n219 |         # Check if compelling legitimate grounds exist\n220 |         compelling_grounds = self._assess_compelling_grounds(data_subject_id)\n221 |         \n    | ^^^^^^^^ W293\n222 |         return {\n223 |             'objection_upheld': not compelling_grounds['exist'],\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:228:1: W293 [*] Blank line contains whitespace\n    |\n226 |             'alternative_measures': 'Data anonymization where objection cannot be honored'\n227 |         }\n228 |     \n    | ^^^^ W293\n229 |     def _handle_gdpr_rectification_request(self, data_subject_id: str) -> Dict[str, Any]:\n230 |         \"\"\"Handle GDPR Article 16 rectification request.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:238:1: W293 [*] Blank line contains whitespace\n    |\n236 |             'third_parties_notified': 'Recipients of incorrect data will be informed'\n237 |         }\n238 |     \n    | ^^^^ W293\n239 |     # Helper methods\n240 |     def _has_consent(self, data_subject_id: Optional[str], purpose: str) -> bool:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:244:1: W293 [*] Blank line contains whitespace\n    |\n242 |         if not data_subject_id:\n243 |             return False\n244 |         \n    | ^^^^^^^^ W293\n245 |         for consent in self.consent_records.values():\n246 |             if (consent['data_subject_id'] == data_subject_id and \n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:246:66: W291 [*] Trailing whitespace\n    |\n245 |         for consent in self.consent_records.values():\n246 |             if (consent['data_subject_id'] == data_subject_id and \n    |                                                                  ^ W291\n247 |                 consent['purpose'] == purpose and\n248 |                 consent['status'] == 'granted' and\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/gdpr.py:252:1: W293 [*] Blank line contains whitespace\n    |\n250 |                 return True\n251 |         return False\n252 |     \n    | ^^^^ W293\n253 |     def _has_explicit_consent(self, data_subject_id: Optional[str], purpose: str) -> bool:\n254 |         \"\"\"Check if explicit consent exists for special category data.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:257:1: W293 [*] Blank line contains whitespace\n    |\n255 |         if not data_subject_id:\n256 |             return False\n257 |         \n    | ^^^^^^^^ W293\n258 |         for consent in self.consent_records.values():\n259 |             if (consent['data_subject_id'] == data_subject_id and \n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:259:66: W291 [*] Trailing whitespace\n    |\n258 |         for consent in self.consent_records.values():\n259 |             if (consent['data_subject_id'] == data_subject_id and \n    |                                                                  ^ W291\n260 |                 consent['purpose'] == purpose and\n261 |                 consent['status'] == 'granted' and\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/gdpr.py:266:1: W293 [*] Blank line contains whitespace\n    |\n264 |                 return True\n265 |         return False\n266 |     \n    | ^^^^ W293\n267 |     def _is_consent_expired(self, consent: Dict[str, Any]) -> bool:\n268 |         \"\"\"Check if consent has expired.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:273:1: W293 [*] Blank line contains whitespace\n    |\n271 |             return datetime.utcnow() > expiry.replace(tzinfo=None)\n272 |         return False\n273 |     \n    | ^^^^ W293\n274 |     def _check_data_minimization(self, purpose: str) -> bool:\n275 |         \"\"\"Check data minimization compliance.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:278:1: W293 [*] Blank line contains whitespace\n    |\n276 |         # Simplified check - in production, implement proper data minimization assessment\n277 |         return True  # Assume compliant for now\n278 |     \n    | ^^^^ W293\n279 |     def _check_retention_compliance(self, data_category: str) -> bool:\n280 |         \"\"\"Check retention period compliance.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:283:1: W293 [*] Blank line contains whitespace\n    |\n281 |         # Simplified check - in production, implement proper retention tracking\n282 |         return True  # Assume compliant for now\n283 |     \n    | ^^^^ W293\n284 |     def _check_erasure_grounds(self, data_subject_id: str) -> Dict[str, Any]:\n285 |         \"\"\"Check grounds for erasure under Article 17.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:293:1: W293 [*] Blank line contains whitespace\n    |\n291 |             'refusal_reasons': []\n292 |         }\n293 |     \n    | ^^^^ W293\n294 |     def _get_processing_purposes(self, data_subject_id: str) -> List[str]:\n295 |         \"\"\"Get processing purposes for data subject.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:301:1: W293 [*] Blank line contains whitespace\n    |\n299 |                 purposes.add(consent['purpose'])\n300 |         return list(purposes)\n301 |     \n    | ^^^^ W293\n302 |     def _get_data_categories(self, data_subject_id: str) -> List[str]:\n303 |         \"\"\"Get data categories for data subject.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:309:1: W293 [*] Blank line contains whitespace\n    |\n307 |                 categories.update(consent.get('data_categories', []))\n308 |         return list(categories)\n309 |     \n    | ^^^^ W293\n310 |     def _get_data_recipients(self, data_subject_id: str) -> List[str]:\n311 |         \"\"\"Get data recipients/processors.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:313:1: W293 [*] Blank line contains whitespace\n    |\n311 |         \"\"\"Get data recipients/processors.\"\"\"\n312 |         return ['DGDN_processing_system', 'authorized_researchers']\n313 |     \n    | ^^^^ W293\n314 |     def _get_retention_info(self, data_subject_id: str) -> Dict[str, Any]:\n315 |         \"\"\"Get retention information.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:321:1: W293 [*] Blank line contains whitespace\n    |\n319 |             'legal_basis': 'legitimate_interests_research'\n320 |         }\n321 |     \n    | ^^^^ W293\n322 |     def _get_data_source_info(self, data_subject_id: str) -> Dict[str, Any]:\n323 |         \"\"\"Get data source information.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:329:1: W293 [*] Blank line contains whitespace\n    |\n327 |             'collection_date': 'recorded_with_consent'\n328 |         }\n329 |     \n    | ^^^^ W293\n330 |     def _get_automated_decisions(self, data_subject_id: str) -> Dict[str, Any]:\n331 |         \"\"\"Get automated decision making information.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:338:1: W293 [*] Blank line contains whitespace\n    |\n336 |             'human_intervention_available': True\n337 |         }\n338 |     \n    | ^^^^ W293\n339 |     def _get_transfer_info(self, data_subject_id: str) -> Dict[str, Any]:\n340 |         \"\"\"Get third country transfer information.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:346:1: W293 [*] Blank line contains whitespace\n    |\n344 |             'adequacy_decisions': 'not_applicable'\n345 |         }\n346 |     \n    | ^^^^ W293\n347 |     def _get_rights_information(self) -> Dict[str, str]:\n348 |         \"\"\"Get data subject rights information.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:358:1: W293 [*] Blank line contains whitespace\n    |\n356 |             'complaint': 'Article 77 GDPR - Right to lodge complaint with supervisory authority'\n357 |         }\n358 |     \n    | ^^^^ W293\n359 |     def _get_portable_data(self, data_subject_id: str) -> Dict[str, Any]:\n360 |         \"\"\"Get data that is subject to portability.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:362:1: W293 [*] Blank line contains whitespace\n    |\n360 |         \"\"\"Get data that is subject to portability.\"\"\"\n361 |         portable_data = {}\n362 |         \n    | ^^^^^^^^ W293\n363 |         # Only data processed by automated means based on consent/contract\n364 |         for consent in self.consent_records.values():\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:365:66: W291 [*] Trailing whitespace\n    |\n363 |         # Only data processed by automated means based on consent/contract\n364 |         for consent in self.consent_records.values():\n365 |             if (consent['data_subject_id'] == data_subject_id and \n    |                                                                  ^ W291\n366 |                 consent.get('legal_basis') == 'consent'):\n367 |                 portable_data[consent['purpose']] = {\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/gdpr.py:372:1: W293 [*] Blank line contains whitespace\n    |\n370 |                     'processing_history': 'available_upon_request'\n371 |                 }\n372 |         \n    | ^^^^^^^^ W293\n373 |         return portable_data\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:374:1: W293 [*] Blank line contains whitespace\n    |\n373 |         return portable_data\n374 |     \n    | ^^^^ W293\n375 |     def _assess_compelling_grounds(self, data_subject_id: str) -> Dict[str, Any]:\n376 |         \"\"\"Assess compelling legitimate grounds for processing.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/gdpr.py:382:10: W292 [*] No newline at end of file\n    |\n380 |             'assessment': 'No compelling grounds override data subject rights',\n381 |             'balancing_test': 'completed'\n382 |         }\n    |          ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/compliance/pdpa.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n  |\n1 |   \"\"\"PDPA compliance implementation for DGDN.\"\"\"\n2 |\n3 | / import logging\n4 | | from datetime import datetime, timedelta\n5 | | from typing import Dict, Any, List, Optional\n6 | | from enum import Enum\n  | |_____________________^ I001\n  |\n  = help: Organize imports\n\nsrc/dgdn/compliance/pdpa.py:27:1: W293 [*] Blank line contains whitespace\n   |\n25 | class PDPACompliance:\n26 |     \"\"\"PDPA compliance system for DGDN (Singapore Personal Data Protection Act).\"\"\"\n27 |     \n   | ^^^^ W293\n28 |     def __init__(self):\n29 |         \"\"\"Initialize PDPA compliance system.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:34:1: W293 [*] Blank line contains whitespace\n   |\n32 |         self.processing_records = []\n33 |         self.data_subject_requests = []\n34 |         \n   | ^^^^^^^^ W293\n35 |         # PDPA specific requirements\n36 |         self.dpo_contact = {\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:41:1: W293 [*] Blank line contains whitespace\n   |\n39 |             'phone': '+65-XXXX-XXXX'\n40 |         }\n41 |         \n   | ^^^^^^^^ W293\n42 |         # Data retention policies\n43 |         self.retention_periods = {\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:47:1: W293 [*] Blank line contains whitespace\n   |\n45 |             'sensitive_personal_data': timedelta(days=365)  # 1 year\n46 |         }\n47 |         \n   | ^^^^^^^^ W293\n48 |         self.logger.info(\"PDPA compliance system initialized\")\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:49:1: W293 [*] Blank line contains whitespace\n   |\n48 |         self.logger.info(\"PDPA compliance system initialized\")\n49 |     \n   | ^^^^ W293\n50 |     def check_processing_lawfulness(self, data_category: str, purpose: str, \n51 |                                   data_subject_id: Optional[str] = None) -> Dict[str, Any]:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:50:76: W291 [*] Trailing whitespace\n   |\n48 |         self.logger.info(\"PDPA compliance system initialized\")\n49 |     \n50 |     def check_processing_lawfulness(self, data_category: str, purpose: str, \n   |                                                                            ^ W291\n51 |                                   data_subject_id: Optional[str] = None) -> Dict[str, Any]:\n52 |         \"\"\"Check if data processing is lawful under PDPA.\"\"\"\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/pdpa.py:59:1: W293 [*] Blank line contains whitespace\n   |\n57 |             'note': ''\n58 |         }\n59 |         \n   | ^^^^^^^^ W293\n60 |         # PDPA requires consent for most processing unless exception applies\n61 |         if data_category == 'sensitive_personal_data':\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:69:1: W293 [*] Blank line contains whitespace\n   |\n67 |                 lawfulness_check['required_actions'].append('obtain_explicit_consent')\n68 |                 lawfulness_check['note'] = 'Sensitive data requires explicit consent under PDPA'\n69 |         \n   | ^^^^^^^^ W293\n70 |         elif purpose in ['research', 'ml_training']:\n71 |             # Check if research exception applies\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:81:1: W293 [*] Blank line contains whitespace\n   |\n79 |             else:\n80 |                 lawfulness_check['required_actions'].append('obtain_consent_or_qualify_exception')\n81 |         \n   | ^^^^^^^^ W293\n82 |         else:\n83 |             # General processing requires consent or legitimate interests\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:93:1: W293 [*] Blank line contains whitespace\n   |\n91 |             else:\n92 |                 lawfulness_check['required_actions'].append('obtain_consent')\n93 |         \n   | ^^^^^^^^ W293\n94 |         # Check purpose limitation compliance\n95 |         if not self._check_purpose_limitation(purpose):\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:97:1: W293 [*] Blank line contains whitespace\n   |\n95 |         if not self._check_purpose_limitation(purpose):\n96 |             lawfulness_check['required_actions'].append('ensure_purpose_limitation')\n97 |         \n   | ^^^^^^^^ W293\n98 |         # Check data minimization\n99 |         if not self._check_data_minimization(purpose):\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:101:1: W293 [*] Blank line contains whitespace\n    |\n 99 |         if not self._check_data_minimization(purpose):\n100 |             lawfulness_check['required_actions'].append('apply_data_minimization')\n101 |         \n    | ^^^^^^^^ W293\n102 |         self.logger.debug(f\"PDPA lawfulness check: {lawfulness_check}\")\n103 |         return lawfulness_check\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:104:1: W293 [*] Blank line contains whitespace\n    |\n102 |         self.logger.debug(f\"PDPA lawfulness check: {lawfulness_check}\")\n103 |         return lawfulness_check\n104 |     \n    | ^^^^ W293\n105 |     def record_consent(self, consent_record: Dict[str, Any]):\n106 |         \"\"\"Record consent under PDPA requirements.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:123:1: W293 [*] Blank line contains whitespace\n    |\n121 |             }\n122 |         }\n123 |         \n    | ^^^^^^^^ W293\n124 |         self.consent_records[consent_record['consent_id']] = pdpa_consent\n125 |         self.logger.info(f\"PDPA-compliant consent recorded: {consent_record['consent_id']}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:126:1: W293 [*] Blank line contains whitespace\n    |\n124 |         self.consent_records[consent_record['consent_id']] = pdpa_consent\n125 |         self.logger.info(f\"PDPA-compliant consent recorded: {consent_record['consent_id']}\")\n126 |     \n    | ^^^^ W293\n127 |     def handle_data_subject_request(self, request_type: str, data_subject_id: str) -> Dict[str, Any]:\n128 |         \"\"\"Handle PDPA data subject rights requests.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:130:1: W293 [*] Blank line contains whitespace\n    |\n128 |         \"\"\"Handle PDPA data subject rights requests.\"\"\"\n129 |         request_id = f\"pdpa_{request_type}_{data_subject_id}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n130 |         \n    | ^^^^^^^^ W293\n131 |         response = {\n132 |             'request_id': request_id,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:141:1: W293 [*] Blank line contains whitespace\n    |\n139 |             'dpo_contact': self.dpo_contact\n140 |         }\n141 |         \n    | ^^^^^^^^ W293\n142 |         if request_type == 'access':\n143 |             # Right to access personal data\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:154:1: W293 [*] Blank line contains whitespace\n    |\n152 |             # Right to request cessation of processing\n153 |             response.update(self._handle_pdpa_stop_processing(data_subject_id))\n154 |         \n    | ^^^^^^^^ W293\n155 |         self.data_subject_requests.append(response)\n156 |         return response\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:157:1: W293 [*] Blank line contains whitespace\n    |\n155 |         self.data_subject_requests.append(response)\n156 |         return response\n157 |     \n    | ^^^^ W293\n158 |     def _handle_pdpa_access_request(self, data_subject_id: str) -> Dict[str, Any]:\n159 |         \"\"\"Handle PDPA access request.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:174:1: W293 [*] Blank line contains whitespace\n    |\n172 |             }\n173 |         }\n174 |     \n    | ^^^^ W293\n175 |     def _handle_pdpa_correction_request(self, data_subject_id: str) -> Dict[str, Any]:\n176 |         \"\"\"Handle PDPA correction request.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:186:1: W293 [*] Blank line contains whitespace\n    |\n184 |             'no_fee_policy': 'No fee charged for correction unless frivolous or excessive'\n185 |         }\n186 |     \n    | ^^^^ W293\n187 |     def _handle_pdpa_withdraw_consent(self, data_subject_id: str) -> Dict[str, Any]:\n188 |         \"\"\"Handle consent withdrawal request.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:196:1: W293 [*] Blank line contains whitespace\n    |\n194 |                 consent['withdrawal_date'] = datetime.utcnow().isoformat()\n195 |                 withdrawn_consents.append(consent_id)\n196 |         \n    | ^^^^^^^^ W293\n197 |         return {\n198 |             'withdrawal_processed': True,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:205:1: W293 [*] Blank line contains whitespace\n    |\n203 |             'consequences_explained': True\n204 |         }\n205 |     \n    | ^^^^ W293\n206 |     def _handle_pdpa_stop_processing(self, data_subject_id: str) -> Dict[str, Any]:\n207 |         \"\"\"Handle request to stop processing.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:209:1: W293 [*] Blank line contains whitespace\n    |\n207 |         \"\"\"Handle request to stop processing.\"\"\"\n208 |         processing_assessment = self._assess_processing_cessation(data_subject_id)\n209 |         \n    | ^^^^^^^^ W293\n210 |         return {\n211 |             'cessation_possible': processing_assessment['can_stop'],\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:218:1: W293 [*] Blank line contains whitespace\n    |\n216 |             'effective_date': datetime.utcnow().isoformat() if processing_assessment['can_stop'] else None\n217 |         }\n218 |     \n    | ^^^^ W293\n219 |     def create_privacy_policy_disclosure(self) -> Dict[str, Any]:\n220 |         \"\"\"Create PDPA-compliant privacy policy disclosure.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:296:1: W293 [*] Blank line contains whitespace\n    |\n294 |             'last_updated': datetime.utcnow().isoformat()\n295 |         }\n296 |     \n    | ^^^^ W293\n297 |     # Helper methods\n298 |     def _has_consent(self, data_subject_id: Optional[str], purpose: str) -> bool:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:302:1: W293 [*] Blank line contains whitespace\n    |\n300 |         if not data_subject_id:\n301 |             return False\n302 |         \n    | ^^^^^^^^ W293\n303 |         for consent in self.consent_records.values():\n304 |             if (consent['data_subject_id'] == data_subject_id and \n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:304:66: W291 [*] Trailing whitespace\n    |\n303 |         for consent in self.consent_records.values():\n304 |             if (consent['data_subject_id'] == data_subject_id and \n    |                                                                  ^ W291\n305 |                 consent['purpose'] == purpose and\n306 |                 consent['status'] == 'granted' and\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/pdpa.py:310:1: W293 [*] Blank line contains whitespace\n    |\n308 |                 return True\n309 |         return False\n310 |     \n    | ^^^^ W293\n311 |     def _has_explicit_consent(self, data_subject_id: Optional[str], purpose: str) -> bool:\n312 |         \"\"\"Check if explicit consent exists for sensitive data.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:315:1: W293 [*] Blank line contains whitespace\n    |\n313 |         if not data_subject_id:\n314 |             return False\n315 |         \n    | ^^^^^^^^ W293\n316 |         for consent in self.consent_records.values():\n317 |             if (consent['data_subject_id'] == data_subject_id and \n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:317:66: W291 [*] Trailing whitespace\n    |\n316 |         for consent in self.consent_records.values():\n317 |             if (consent['data_subject_id'] == data_subject_id and \n    |                                                                  ^ W291\n318 |                 consent['purpose'] == purpose and\n319 |                 consent['status'] == 'granted' and\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/pdpa.py:324:1: W293 [*] Blank line contains whitespace\n    |\n322 |                 return True\n323 |         return False\n324 |     \n    | ^^^^ W293\n325 |     def _qualifies_for_research_exception(self, purpose: str) -> bool:\n326 |         \"\"\"Check if processing qualifies for research exception.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:329:1: W293 [*] Blank line contains whitespace\n    |\n327 |         research_purposes = ['research', 'ml_training']\n328 |         return purpose in research_purposes\n329 |     \n    | ^^^^ W293\n330 |     def _has_legitimate_interests(self, purpose: str) -> bool:\n331 |         \"\"\"Check if legitimate interests basis applies.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:334:1: W293 [*] Blank line contains whitespace\n    |\n332 |         legitimate_purposes = ['performance', 'security', 'analytics']\n333 |         return purpose in legitimate_purposes\n334 |     \n    | ^^^^ W293\n335 |     def _is_consent_expired(self, consent: Dict[str, Any]) -> bool:\n336 |         \"\"\"Check if consent has expired.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:341:1: W293 [*] Blank line contains whitespace\n    |\n339 |             return datetime.utcnow() > expiry.replace(tzinfo=None)\n340 |         return False\n341 |     \n    | ^^^^ W293\n342 |     def _check_purpose_limitation(self, purpose: str) -> bool:\n343 |         \"\"\"Check purpose limitation compliance.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:346:1: W293 [*] Blank line contains whitespace\n    |\n344 |         # Simplified check - in production, verify against disclosed purposes\n345 |         return True\n346 |     \n    | ^^^^ W293\n347 |     def _check_data_minimization(self, purpose: str) -> bool:\n348 |         \"\"\"Check data minimization compliance.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:351:1: W293 [*] Blank line contains whitespace\n    |\n349 |         # Simplified check - in production, verify minimal data collection\n350 |         return True\n351 |     \n    | ^^^^ W293\n352 |     def _get_personal_data_categories(self, data_subject_id: str) -> List[str]:\n353 |         \"\"\"Get categories of personal data for individual.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:360:1: W293 [*] Blank line contains whitespace\n    |\n358 |             'interaction_data'\n359 |         ]\n360 |     \n    | ^^^^ W293\n361 |     def _get_processing_purposes(self, data_subject_id: str) -> List[str]:\n362 |         \"\"\"Get processing purposes for individual.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:368:1: W293 [*] Blank line contains whitespace\n    |\n366 |                 purposes.add(consent['purpose'])\n367 |         return list(purposes)\n368 |     \n    | ^^^^ W293\n369 |     def _get_data_sources(self, data_subject_id: str) -> List[str]:\n370 |         \"\"\"Get sources of personal data.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:376:1: W293 [*] Blank line contains whitespace\n    |\n374 |             'derived_from_usage_patterns'\n375 |         ]\n376 |     \n    | ^^^^ W293\n377 |     def _get_third_party_disclosures(self, data_subject_id: str) -> List[Dict[str, str]]:\n378 |         \"\"\"Get third party disclosures.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:391:1: W293 [*] Blank line contains whitespace\n    |\n389 |             }\n390 |         ]\n391 |     \n    | ^^^^ W293\n392 |     def _get_retention_periods(self, data_subject_id: str) -> Dict[str, str]:\n393 |         \"\"\"Get retention periods for different data categories.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:399:1: W293 [*] Blank line contains whitespace\n    |\n397 |             'research_data': 'Duration of research project plus 2 years'\n398 |         }\n399 |     \n    | ^^^^ W293\n400 |     def _get_protection_measures(self) -> List[str]:\n401 |         \"\"\"Get data protection measures implemented.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:410:1: W293 [*] Blank line contains whitespace\n    |\n408 |             'incident_response_procedures'\n409 |         ]\n410 |     \n    | ^^^^ W293\n411 |     def _get_individual_rights(self) -> Dict[str, str]:\n412 |         \"\"\"Get individual rights information.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:420:1: W293 [*] Blank line contains whitespace\n    |\n418 |             'complaint': 'Right to lodge complaint with PDPC'\n419 |         }\n420 |     \n    | ^^^^ W293\n421 |     def _assess_continued_processing(self, data_subject_id: str) -> Dict[str, Any]:\n422 |         \"\"\"Assess continued processing after consent withdrawal.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:429:1: W293 [*] Blank line contains whitespace\n    |\n427 |             'note': 'Processing generally ceases upon consent withdrawal'\n428 |         }\n429 |     \n    | ^^^^ W293\n430 |     def _assess_retention_after_withdrawal(self, data_subject_id: str) -> Dict[str, Any]:\n431 |         \"\"\"Assess data retention after consent withdrawal.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:438:1: W293 [*] Blank line contains whitespace\n    |\n436 |             'subsequent_deletion': 'Secure deletion after retention period'\n437 |         }\n438 |     \n    | ^^^^ W293\n439 |     def _assess_processing_cessation(self, data_subject_id: str) -> Dict[str, Any]:\n440 |         \"\"\"Assess whether processing can be ceased.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/pdpa.py:447:10: W292 [*] No newline at end of file\n    |\n445 |             'alternatives': ['anonymization', 'aggregation'],\n446 |             'note': 'Processing can generally be stopped upon request'\n447 |         }\n    |          ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/compliance/privacy_manager.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n   |\n 1 |   \"\"\"Unified privacy management for DGDN compliance.\"\"\"\n 2 |\n 3 | / import logging\n 4 | | import hashlib\n 5 | | import json\n 6 | | import uuid\n 7 | | from typing import Dict, List, Optional, Any, Set, Union\n 8 | | from datetime import datetime, timedelta\n 9 | | from enum import Enum\n10 | | import torch\n11 | |\n12 | | from .gdpr import GDPRCompliance\n13 | | from .ccpa import CCPACompliance\n14 | | from .pdpa import PDPACompliance\n   | |________________________________^ I001\n   |\n   = help: Organize imports\n\nsrc/dgdn/compliance/privacy_manager.py:7:47: F401 [*] `typing.Set` imported but unused\n  |\n5 | import json\n6 | import uuid\n7 | from typing import Dict, List, Optional, Any, Set, Union\n  |                                               ^^^ F401\n8 | from datetime import datetime, timedelta\n9 | from enum import Enum\n  |\n  = help: Remove unused import\n\nsrc/dgdn/compliance/privacy_manager.py:7:52: F401 [*] `typing.Union` imported but unused\n  |\n5 | import json\n6 | import uuid\n7 | from typing import Dict, List, Optional, Any, Set, Union\n  |                                                    ^^^^^ F401\n8 | from datetime import datetime, timedelta\n9 | from enum import Enum\n  |\n  = help: Remove unused import\n\nsrc/dgdn/compliance/privacy_manager.py:45:1: W293 [*] Blank line contains whitespace\n   |\n43 | class PrivacyManager:\n44 |     \"\"\"Unified privacy management system for DGDN.\"\"\"\n45 |     \n   | ^^^^ W293\n46 |     def __init__(self, active_regimes: List[PrivacyRegime] = None):\n47 |         \"\"\"Initialize privacy manager with compliance systems.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:50:1: W293 [*] Blank line contains whitespace\n   |\n48 |         self.active_regimes = active_regimes or [PrivacyRegime.GDPR]\n49 |         self.logger = logging.getLogger(__name__)\n50 |         \n   | ^^^^^^^^ W293\n51 |         # Initialize compliance systems\n52 |         self.compliance_systems = {}\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:59:1: W293 [*] Blank line contains whitespace\n   |\n57 |         if PrivacyRegime.PDPA in self.active_regimes or PrivacyRegime.ALL in self.active_regimes:\n58 |             self.compliance_systems[PrivacyRegime.PDPA] = PDPACompliance()\n59 |         \n   | ^^^^^^^^ W293\n60 |         # Privacy tracking\n61 |         self.processing_records = []\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:64:1: W293 [*] Blank line contains whitespace\n   |\n62 |         self.consent_records = {}\n63 |         self.data_minimization_policies = {}\n64 |         \n   | ^^^^^^^^ W293\n65 |         self.logger.info(f\"Privacy manager initialized with regimes: {[r.value for r in self.active_regimes]}\")\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:66:1: W293 [*] Blank line contains whitespace\n   |\n65 |         self.logger.info(f\"Privacy manager initialized with regimes: {[r.value for r in self.active_regimes]}\")\n66 |     \n   | ^^^^ W293\n67 |     def classify_data(self, data: Any, context: Dict[str, Any] = None) -> Dict[str, Any]:\n68 |         \"\"\"Classify data according to privacy categories.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:70:1: W293 [*] Blank line contains whitespace\n   |\n68 |         \"\"\"Classify data according to privacy categories.\"\"\"\n69 |         context = context or {}\n70 |         \n   | ^^^^^^^^ W293\n71 |         classification = {\n72 |             'category': DataCategory.TECHNICAL,  # Default safe classification\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:78:1: W293 [*] Blank line contains whitespace\n   |\n76 |             'required_protections': []\n77 |         }\n78 |         \n   | ^^^^^^^^ W293\n79 |         # Analyze data structure and content\n80 |         if isinstance(data, torch.Tensor):\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:87:1: W293 [*] Blank line contains whitespace\n   |\n85 |                 classification['risk_level'] = 'high'\n86 |                 classification['required_protections'] = ['encryption', 'access_control', 'audit_logging']\n87 |         \n   | ^^^^^^^^ W293\n88 |         elif isinstance(data, dict):\n89 |             # Dictionary data analysis\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:95:1: W293 [*] Blank line contains whitespace\n   |\n93 |                 classification['category'] = DataCategory.PERSONAL_IDENTIFIABLE\n94 |                 classification['risk_level'] = 'high'\n95 |         \n   | ^^^^^^^^ W293\n96 |         # Apply additional context-based classification\n97 |         if context.get('data_source') == 'user_input':\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:99:1: W293 [*] Blank line contains whitespace\n    |\n 97 |         if context.get('data_source') == 'user_input':\n 98 |             classification['risk_level'] = 'medium'\n 99 |         \n    | ^^^^^^^^ W293\n100 |         self.logger.debug(f\"Data classified as: {classification}\")\n101 |         return classification\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:102:1: W293 [*] Blank line contains whitespace\n    |\n100 |         self.logger.debug(f\"Data classified as: {classification}\")\n101 |         return classification\n102 |     \n    | ^^^^ W293\n103 |     def _contains_potential_identifiers(self, tensor: torch.Tensor, context: Dict[str, Any]) -> bool:\n104 |         \"\"\"Heuristic check for potential identifiers in tensor data.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:106:1: W293 [*] Blank line contains whitespace\n    |\n104 |         \"\"\"Heuristic check for potential identifiers in tensor data.\"\"\"\n105 |         # This is a simplified heuristic - in production, use more sophisticated methods\n106 |         \n    | ^^^^^^^^ W293\n107 |         # Check tensor properties that might indicate PII\n108 |         if tensor.dtype in [torch.long, torch.int32, torch.int64]:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:112:1: W293 [*] Blank line contains whitespace\n    |\n110 |             if context.get('contains_node_ids', False):\n111 |                 return True\n112 |             \n    | ^^^^^^^^^^^^ W293\n113 |             # Large integer values might be IDs\n114 |             if tensor.numel() > 0 and torch.max(torch.abs(tensor)) > 1000000:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:116:1: W293 [*] Blank line contains whitespace\n    |\n114 |             if tensor.numel() > 0 and torch.max(torch.abs(tensor)) > 1000000:\n115 |                 return True\n116 |         \n    | ^^^^^^^^ W293\n117 |         # Check for structured data patterns\n118 |         if len(tensor.shape) == 2 and tensor.shape[1] in [64, 128, 256]:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:122:1: W293 [*] Blank line contains whitespace\n    |\n120 |             if context.get('data_type') == 'user_embeddings':\n121 |                 return True\n122 |         \n    | ^^^^^^^^ W293\n123 |         return False\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:124:1: W293 [*] Blank line contains whitespace\n    |\n123 |         return False\n124 |     \n    | ^^^^ W293\n125 |     def request_consent(self, purpose: ProcessingPurpose, data_subject_id: str, \n126 |                        data_categories: List[DataCategory]) -> Dict[str, Any]:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:125:80: W291 [*] Trailing whitespace\n    |\n123 |         return False\n124 |     \n125 |     def request_consent(self, purpose: ProcessingPurpose, data_subject_id: str, \n    |                                                                                ^ W291\n126 |                        data_categories: List[DataCategory]) -> Dict[str, Any]:\n127 |         \"\"\"Request and record consent for data processing.\"\"\"\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/privacy_manager.py:140:1: W293 [*] Blank line contains whitespace\n    |\n138 |             'legal_basis': self._determine_legal_basis(purpose)\n139 |         }\n140 |         \n    | ^^^^^^^^ W293\n141 |         # Store consent record\n142 |         self.consent_records[consent_id] = consent_record\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:143:1: W293 [*] Blank line contains whitespace\n    |\n141 |         # Store consent record\n142 |         self.consent_records[consent_id] = consent_record\n143 |         \n    | ^^^^^^^^ W293\n144 |         # Notify compliance systems\n145 |         for regime, system in self.compliance_systems.items():\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:145:13: B007 Loop control variable `regime` not used within loop body\n    |\n144 |         # Notify compliance systems\n145 |         for regime, system in self.compliance_systems.items():\n    |             ^^^^^^ B007\n146 |             if hasattr(system, 'record_consent'):\n147 |                 system.record_consent(consent_record)\n    |\n    = help: Rename unused `regime` to `_regime`\n\nsrc/dgdn/compliance/privacy_manager.py:148:1: W293 [*] Blank line contains whitespace\n    |\n146 |             if hasattr(system, 'record_consent'):\n147 |                 system.record_consent(consent_record)\n148 |         \n    | ^^^^^^^^ W293\n149 |         self.logger.info(f\"Consent recorded: {consent_id} for purpose {purpose.value}\")\n150 |         return consent_record\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:151:1: W293 [*] Blank line contains whitespace\n    |\n149 |         self.logger.info(f\"Consent recorded: {consent_id} for purpose {purpose.value}\")\n150 |         return consent_record\n151 |     \n    | ^^^^ W293\n152 |     def check_processing_lawfulness(self, data: Any, purpose: ProcessingPurpose, \n153 |                                   data_subject_id: Optional[str] = None) -> Dict[str, Any]:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:152:81: W291 [*] Trailing whitespace\n    |\n150 |         return consent_record\n151 |     \n152 |     def check_processing_lawfulness(self, data: Any, purpose: ProcessingPurpose, \n    |                                                                                 ^ W291\n153 |                                   data_subject_id: Optional[str] = None) -> Dict[str, Any]:\n154 |         \"\"\"Check if data processing is lawful under active regimes.\"\"\"\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/privacy_manager.py:156:1: W293 [*] Blank line contains whitespace\n    |\n154 |         \"\"\"Check if data processing is lawful under active regimes.\"\"\"\n155 |         classification = self.classify_data(data)\n156 |         \n    | ^^^^^^^^ W293\n157 |         lawfulness_check = {\n158 |             'lawful': True,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:163:1: W293 [*] Blank line contains whitespace\n    |\n161 |             'compliance_notes': []\n162 |         }\n163 |         \n    | ^^^^^^^^ W293\n164 |         # Check each active compliance regime\n165 |         for regime, system in self.compliance_systems.items():\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:171:1: W293 [*] Blank line contains whitespace\n    |\n169 |                 data_subject_id=data_subject_id\n170 |             )\n171 |             \n    | ^^^^^^^^^^^^ W293\n172 |             if not regime_check.get('lawful', True):\n173 |                 lawfulness_check['lawful'] = False\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:174:1: W293 [*] Blank line contains whitespace\n    |\n172 |             if not regime_check.get('lawful', True):\n173 |                 lawfulness_check['lawful'] = False\n174 |             \n    | ^^^^^^^^^^^^ W293\n175 |             lawfulness_check['legal_basis'].extend(regime_check.get('legal_basis', []))\n176 |             lawfulness_check['required_actions'].extend(regime_check.get('required_actions', []))\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:178:1: W293 [*] Blank line contains whitespace\n    |\n176 |             lawfulness_check['required_actions'].extend(regime_check.get('required_actions', []))\n177 |             lawfulness_check['compliance_notes'].append(f\"{regime.value}: {regime_check.get('note', 'OK')}\")\n178 |         \n    | ^^^^^^^^ W293\n179 |         # Record processing activity\n180 |         self._record_processing_activity(data, purpose, classification, lawfulness_check)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:181:1: W293 [*] Blank line contains whitespace\n    |\n179 |         # Record processing activity\n180 |         self._record_processing_activity(data, purpose, classification, lawfulness_check)\n181 |         \n    | ^^^^^^^^ W293\n182 |         return lawfulness_check\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:183:1: W293 [*] Blank line contains whitespace\n    |\n182 |         return lawfulness_check\n183 |     \n    | ^^^^ W293\n184 |     def apply_data_minimization(self, data: Any, purpose: ProcessingPurpose) -> Any:\n185 |         \"\"\"Apply data minimization principles.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:188:1: W293 [*] Blank line contains whitespace\n    |\n186 |         if not isinstance(data, torch.Tensor):\n187 |             return data  # Only handle tensor data for now\n188 |         \n    | ^^^^^^^^ W293\n189 |         # Get minimization policy for purpose\n190 |         policy = self.data_minimization_policies.get(purpose, {})\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:191:1: W293 [*] Blank line contains whitespace\n    |\n189 |         # Get minimization policy for purpose\n190 |         policy = self.data_minimization_policies.get(purpose, {})\n191 |         \n    | ^^^^^^^^ W293\n192 |         minimized_data = data.clone()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:193:1: W293 [*] Blank line contains whitespace\n    |\n192 |         minimized_data = data.clone()\n193 |         \n    | ^^^^^^^^ W293\n194 |         # Apply dimension reduction if specified\n195 |         if 'max_dimensions' in policy:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:201:1: W293 [*] Blank line contains whitespace\n    |\n199 |                 minimized_data = data[:, :max_dim]\n200 |                 self.logger.info(f\"Applied dimension reduction: {data.shape} -> {minimized_data.shape}\")\n201 |         \n    | ^^^^^^^^ W293\n202 |         # Apply noise for differential privacy if specified\n203 |         if policy.get('add_noise', False):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:208:1: W293 [*] Blank line contains whitespace\n    |\n206 |             minimized_data = minimized_data + noise\n207 |             self.logger.info(f\"Applied differential privacy noise (scale: {noise_scale})\")\n208 |         \n    | ^^^^^^^^ W293\n209 |         return minimized_data\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:210:1: W293 [*] Blank line contains whitespace\n    |\n209 |         return minimized_data\n210 |     \n    | ^^^^ W293\n211 |     def anonymize_data(self, data: Any, method: str = 'hash') -> Dict[str, Any]:\n212 |         \"\"\"Anonymize data while preserving utility.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:229:1: W293 [*] Blank line contains whitespace\n    |\n227 |                 sensitivity = torch.std(data).item()\n228 |                 noise_scale = sensitivity / epsilon\n229 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n230 |                 noisy_data = data + torch.randn_like(data) * noise_scale\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:231:1: W293 [*] Blank line contains whitespace\n    |\n230 |                 noisy_data = data + torch.randn_like(data) * noise_scale\n231 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n232 |                 return {\n233 |                     'anonymized_data': noisy_data,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:238:1: W293 [*] Blank line contains whitespace\n    |\n236 |                     'preserves_structure': True\n237 |                 }\n238 |         \n    | ^^^^^^^^ W293\n239 |         # Fallback for other data types\n240 |         return {\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:245:1: W293 [*] Blank line contains whitespace\n    |\n243 |             'preserves_structure': False\n244 |         }\n245 |     \n    | ^^^^ W293\n246 |     def handle_data_subject_request(self, request_type: str, data_subject_id: str) -> Dict[str, Any]:\n247 |         \"\"\"Handle data subject rights requests (access, deletion, portability).\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:249:1: W293 [*] Blank line contains whitespace\n    |\n247 |         \"\"\"Handle data subject rights requests (access, deletion, portability).\"\"\"\n248 |         request_id = str(uuid.uuid4())\n249 |         \n    | ^^^^^^^^ W293\n250 |         response = {\n251 |             'request_id': request_id,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:257:1: W293 [*] Blank line contains whitespace\n    |\n255 |             'status': 'processing'\n256 |         }\n257 |         \n    | ^^^^^^^^ W293\n258 |         if request_type == 'access':\n259 |             # Right to access\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:270:1: W293 [*] Blank line contains whitespace\n    |\n268 |             # Right to rectification\n269 |             response.update(self._handle_rectification_request(data_subject_id))\n270 |         \n    | ^^^^^^^^ W293\n271 |         # Forward to all compliance systems\n272 |         for regime, system in self.compliance_systems.items():\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:272:13: B007 Loop control variable `regime` not used within loop body\n    |\n271 |         # Forward to all compliance systems\n272 |         for regime, system in self.compliance_systems.items():\n    |             ^^^^^^ B007\n273 |             if hasattr(system, 'handle_data_subject_request'):\n274 |                 system.handle_data_subject_request(request_type, data_subject_id)\n    |\n    = help: Rename unused `regime` to `_regime`\n\nsrc/dgdn/compliance/privacy_manager.py:275:1: W293 [*] Blank line contains whitespace\n    |\n273 |             if hasattr(system, 'handle_data_subject_request'):\n274 |                 system.handle_data_subject_request(request_type, data_subject_id)\n275 |         \n    | ^^^^^^^^ W293\n276 |         self.logger.info(f\"Data subject request handled: {request_id}\")\n277 |         return response\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:278:1: W293 [*] Blank line contains whitespace\n    |\n276 |         self.logger.info(f\"Data subject request handled: {request_id}\")\n277 |         return response\n278 |     \n    | ^^^^ W293\n279 |     def _handle_access_request(self, data_subject_id: str) -> Dict[str, Any]:\n280 |         \"\"\"Handle right to access request.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:286:1: W293 [*] Blank line contains whitespace\n    |\n284 |             if consent['data_subject_id'] == data_subject_id\n285 |         ]\n286 |         \n    | ^^^^^^^^ W293\n287 |         related_processing = [\n288 |             record for record in self.processing_records\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:291:1: W293 [*] Blank line contains whitespace\n    |\n289 |             if record.get('data_subject_id') == data_subject_id\n290 |         ]\n291 |         \n    | ^^^^^^^^ W293\n292 |         return {\n293 |             'data_found': len(related_consents) + len(related_processing) > 0,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:296:37: C403 Unnecessary list comprehension (rewrite as a set comprehension)\n    |\n294 |               'consent_records': related_consents,\n295 |               'processing_records': related_processing,\n296 |               'data_categories': list(set([\n    |  _____________________________________^\n297 | |                 cat for consent in related_consents \n298 | |                 for cat in consent.get('data_categories', [])\n299 | |             ])),\n    | |______________^ C403\n300 |               'status': 'completed'\n301 |           }\n    |\n    = help: Rewrite as a set comprehension\n\nsrc/dgdn/compliance/privacy_manager.py:297:52: W291 [*] Trailing whitespace\n    |\n295 |             'processing_records': related_processing,\n296 |             'data_categories': list(set([\n297 |                 cat for consent in related_consents \n    |                                                    ^ W291\n298 |                 for cat in consent.get('data_categories', [])\n299 |             ])),\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/privacy_manager.py:302:1: W293 [*] Blank line contains whitespace\n    |\n300 |             'status': 'completed'\n301 |         }\n302 |     \n    | ^^^^ W293\n303 |     def _handle_deletion_request(self, data_subject_id: str) -> Dict[str, Any]:\n304 |         \"\"\"Handle right to deletion/erasure request.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:310:1: W293 [*] Blank line contains whitespace\n    |\n308 |             if consent['data_subject_id'] == data_subject_id\n309 |         ]\n310 |         \n    | ^^^^^^^^ W293\n311 |         for consent_id in deleted_consents:\n312 |             del self.consent_records[consent_id]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:313:1: W293 [*] Blank line contains whitespace\n    |\n311 |         for consent_id in deleted_consents:\n312 |             del self.consent_records[consent_id]\n313 |         \n    | ^^^^^^^^ W293\n314 |         # Mark processing records for deletion\n315 |         deleted_processing = 0\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:321:1: W293 [*] Blank line contains whitespace\n    |\n319 |                 record['deletion_date'] = datetime.utcnow().isoformat()\n320 |                 deleted_processing += 1\n321 |         \n    | ^^^^^^^^ W293\n322 |         return {\n323 |             'deleted_consents': len(deleted_consents),\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:328:1: W293 [*] Blank line contains whitespace\n    |\n326 |             'note': 'Data marked for deletion. Physical deletion may take up to 30 days.'\n327 |         }\n328 |     \n    | ^^^^ W293\n329 |     def _handle_portability_request(self, data_subject_id: str) -> Dict[str, Any]:\n330 |         \"\"\"Handle right to data portability request.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:333:1: W293 [*] Blank line contains whitespace\n    |\n331 |         # Collect portable data\n332 |         portable_data = self._handle_access_request(data_subject_id)\n333 |         \n    | ^^^^^^^^ W293\n334 |         # Format for portability (JSON format)\n335 |         export_data = {\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:342:1: W293 [*] Blank line contains whitespace\n    |\n340 |             'schema_version': '1.0'\n341 |         }\n342 |         \n    | ^^^^^^^^ W293\n343 |         return {\n344 |             'portable_data': json.dumps(export_data, indent=2),\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:349:1: W293 [*] Blank line contains whitespace\n    |\n347 |             'status': 'completed'\n348 |         }\n349 |     \n    | ^^^^ W293\n350 |     def _handle_rectification_request(self, data_subject_id: str) -> Dict[str, Any]:\n351 |         \"\"\"Handle right to rectification request.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:357:1: W293 [*] Blank line contains whitespace\n    |\n355 |             'contact_info': 'Please provide specific details about incorrect data.'\n356 |         }\n357 |     \n    | ^^^^ W293\n358 |     def _record_processing_activity(self, data: Any, purpose: ProcessingPurpose, \n359 |                                   classification: Dict[str, Any], lawfulness_check: Dict[str, Any]):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:358:81: W291 [*] Trailing whitespace\n    |\n356 |         }\n357 |     \n358 |     def _record_processing_activity(self, data: Any, purpose: ProcessingPurpose, \n    |                                                                                 ^ W291\n359 |                                   classification: Dict[str, Any], lawfulness_check: Dict[str, Any]):\n360 |         \"\"\"Record processing activity for compliance audit trail.\"\"\"\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/privacy_manager.py:371:1: W293 [*] Blank line contains whitespace\n    |\n369 |             'processing_id': str(uuid.uuid4())\n370 |         }\n371 |         \n    | ^^^^^^^^ W293\n372 |         self.processing_records.append(record)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:373:1: W293 [*] Blank line contains whitespace\n    |\n372 |         self.processing_records.append(record)\n373 |         \n    | ^^^^^^^^ W293\n374 |         # Keep only recent records (last 1000)\n375 |         if len(self.processing_records) > 1000:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:377:1: W293 [*] Blank line contains whitespace\n    |\n375 |         if len(self.processing_records) > 1000:\n376 |             self.processing_records = self.processing_records[-1000:]\n377 |     \n    | ^^^^ W293\n378 |     def _estimate_data_size(self, data: Any) -> int:\n379 |         \"\"\"Estimate data size in bytes.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:388:1: W293 [*] Blank line contains whitespace\n    |\n386 |         else:\n387 |             return len(str(data).encode('utf-8'))\n388 |     \n    | ^^^^ W293\n389 |     def _generate_withdrawal_instructions(self, consent_id: str) -> str:\n390 |         \"\"\"Generate instructions for withdrawing consent.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:392:1: W293 [*] Blank line contains whitespace\n    |\n390 |         \"\"\"Generate instructions for withdrawing consent.\"\"\"\n391 |         return f\"To withdraw consent {consent_id}, contact privacy@dgdn.ai or use the privacy dashboard.\"\n392 |     \n    | ^^^^ W293\n393 |     def _determine_legal_basis(self, purpose: ProcessingPurpose) -> str:\n394 |         \"\"\"Determine legal basis for processing purpose.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:403:1: W293 [*] Blank line contains whitespace\n    |\n401 |         }\n402 |         return legal_basis_map.get(purpose, \"consent\")\n403 |     \n    | ^^^^ W293\n404 |     def set_data_minimization_policy(self, purpose: ProcessingPurpose, policy: Dict[str, Any]):\n405 |         \"\"\"Set data minimization policy for a processing purpose.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:408:1: W293 [*] Blank line contains whitespace\n    |\n406 |         self.data_minimization_policies[purpose] = policy\n407 |         self.logger.info(f\"Data minimization policy set for {purpose.value}: {policy}\")\n408 |     \n    | ^^^^ W293\n409 |     def get_compliance_report(self) -> Dict[str, Any]:\n410 |         \"\"\"Generate compliance report.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/compliance/privacy_manager.py:415:39: C401 Unnecessary generator (rewrite as a set comprehension)\n    |\n413 |               'total_consent_records': len(self.consent_records),\n414 |               'total_processing_records': len(self.processing_records),\n415 |               'data_subject_count': len(set(\n    |  _______________________________________^\n416 | |                 consent['data_subject_id'] for consent in self.consent_records.values()\n417 | |             )),\n    | |_____________^ C401\n418 |               'processing_purposes': list(set(\n419 |                   record['purpose'] for record in self.processing_records\n    |\n    = help: Rewrite as a set comprehension\n\nsrc/dgdn/compliance/privacy_manager.py:418:41: C401 Unnecessary generator (rewrite as a set comprehension)\n    |\n416 |                   consent['data_subject_id'] for consent in self.consent_records.values()\n417 |               )),\n418 |               'processing_purposes': list(set(\n    |  _________________________________________^\n419 | |                 record['purpose'] for record in self.processing_records\n420 | |             )),\n    | |_____________^ C401\n421 |               'compliance_systems': {\n422 |                   regime.value: system.__class__.__name__ \n    |\n    = help: Rewrite as a set comprehension\n\nsrc/dgdn/compliance/privacy_manager.py:422:56: W291 [*] Trailing whitespace\n    |\n420 |             )),\n421 |             'compliance_systems': {\n422 |                 regime.value: system.__class__.__name__ \n    |                                                        ^ W291\n423 |                 for regime, system in self.compliance_systems.items()\n424 |             },\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/compliance/privacy_manager.py:426:10: W292 [*] No newline at end of file\n    |\n424 |             },\n425 |             'report_date': datetime.utcnow().isoformat()\n426 |         }\n    |          ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/deployment/__init__.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n  |\n1 | \"\"\"Multi-region deployment capabilities for DGDN.\"\"\"\n2 |\n3 | from .region_manager import RegionManager, DeploymentRegion\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ I001\n4 |\n5 | __all__ = [\"RegionManager\", \"DeploymentRegion\"]\n  |\n  = help: Organize imports\n\nsrc/dgdn/deployment/__init__.py:5:48: W292 [*] No newline at end of file\n  |\n3 | from .region_manager import RegionManager, DeploymentRegion\n4 |\n5 | __all__ = [\"RegionManager\", \"DeploymentRegion\"]\n  |                                                ^ W292\n  |\n  = help: Add trailing newline\n\nsrc/dgdn/deployment/region_manager.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n  |\n1 |   \"\"\"Multi-region deployment management for DGDN.\"\"\"\n2 |\n3 | / import logging\n4 | | from datetime import datetime\n5 | | from typing import Dict, Any, List, Optional, Set\n6 | | from enum import Enum\n7 | | import json\n  | |___________^ I001\n  |\n  = help: Organize imports\n\nsrc/dgdn/deployment/region_manager.py:5:47: F401 [*] `typing.Set` imported but unused\n  |\n3 | import logging\n4 | from datetime import datetime\n5 | from typing import Dict, Any, List, Optional, Set\n  |                                               ^^^ F401\n6 | from enum import Enum\n7 | import json\n  |\n  = help: Remove unused import: `typing.Set`\n\nsrc/dgdn/deployment/region_manager.py:7:8: F401 [*] `json` imported but unused\n  |\n5 | from typing import Dict, Any, List, Optional, Set\n6 | from enum import Enum\n7 | import json\n  |        ^^^^ F401\n  |\n  = help: Remove unused import: `json`\n\nsrc/dgdn/deployment/region_manager.py:13:28: W291 [*] Trailing whitespace\n   |\n11 |     \"\"\"Supported deployment regions.\"\"\"\n12 |     US_EAST_1 = \"us-east-1\"\n13 |     US_WEST_2 = \"us-west-2\" \n   |                            ^ W291\n14 |     EU_WEST_1 = \"eu-west-1\"\n15 |     EU_CENTRAL_1 = \"eu-central-1\"\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/deployment/region_manager.py:31:1: W293 [*] Blank line contains whitespace\n   |\n29 | class RegionManager:\n30 |     \"\"\"Multi-region deployment manager for DGDN.\"\"\"\n31 |     \n   | ^^^^ W293\n32 |     def __init__(self):\n33 |         \"\"\"Initialize region manager.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:35:1: W293 [*] Blank line contains whitespace\n   |\n33 |         \"\"\"Initialize region manager.\"\"\"\n34 |         self.logger = logging.getLogger(__name__)\n35 |         \n   | ^^^^^^^^ W293\n36 |         # Region configurations\n37 |         self.regions = {\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:54:45: W291 [*] Trailing whitespace\n   |\n52 |             },\n53 |             DeploymentRegion.EU_WEST_1: {\n54 |                 \"name\": \"EU West (Ireland)\", \n   |                                             ^ W291\n55 |                 \"compliance_regime\": \"gdpr\",\n56 |                 \"data_residency\": \"eu\",\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/deployment/region_manager.py:64:70: W291 [*] Trailing whitespace\n   |\n62 |                 \"endpoints\": {\n63 |                     \"api\": \"https://eu-west-1.api.dgdn.ai\",\n64 |                     \"training\": \"https://eu-west-1.training.dgdn.ai\", \n   |                                                                      ^ W291\n65 |                     \"inference\": \"https://eu-west-1.inference.dgdn.ai\"\n66 |                 }\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/deployment/region_manager.py:71:40: W291 [*] Trailing whitespace\n   |\n69 |                 \"name\": \"Asia Pacific (Singapore)\",\n70 |                 \"compliance_regime\": \"pdpa\",\n71 |                 \"data_residency\": \"sg\", \n   |                                        ^ W291\n72 |                 \"primary_language\": \"en\",\n73 |                 \"supported_languages\": [\"en\", \"zh\", \"ja\"],\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/deployment/region_manager.py:84:1: W293 [*] Blank line contains whitespace\n   |\n82 |             }\n83 |         }\n84 |         \n   | ^^^^^^^^ W293\n85 |         # Region health and metrics\n86 |         self.region_health = {}\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:89:1: W293 [*] Blank line contains whitespace\n   |\n87 |         self.traffic_routing = {}\n88 |         self.deployment_history = []\n89 |         \n   | ^^^^^^^^ W293\n90 |         self._initialize_region_health()\n91 |         self.logger.info(\"Region manager initialized with {} regions\".format(len(self.regions)))\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:91:26: UP032 [*] Use f-string instead of `format` call\n   |\n90 |         self._initialize_region_health()\n91 |         self.logger.info(\"Region manager initialized with {} regions\".format(len(self.regions)))\n   |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ UP032\n92 |     \n93 |     def _initialize_region_health(self):\n   |\n   = help: Convert to f-string\n\nsrc/dgdn/deployment/region_manager.py:92:1: W293 [*] Blank line contains whitespace\n   |\n90 |         self._initialize_region_health()\n91 |         self.logger.info(\"Region manager initialized with {} regions\".format(len(self.regions)))\n92 |     \n   | ^^^^ W293\n93 |     def _initialize_region_health(self):\n94 |         \"\"\"Initialize health monitoring for all regions.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:105:1: W293 [*] Blank line contains whitespace\n    |\n103 |                 \"active_connections\": 150\n104 |             }\n105 |     \n    | ^^^^ W293\n106 |     def get_optimal_region(self, user_location: Optional[str] = None,\n107 |                           compliance_requirements: Optional[List[str]] = None,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:111:1: W293 [*] Blank line contains whitespace\n    |\n109 |         \"\"\"Get optimal deployment region for user.\"\"\"\n110 |         scoring = {}\n111 |         \n    | ^^^^^^^^ W293\n112 |         for region, config in self.regions.items():\n113 |             if config[\"status\"] != RegionStatus.ACTIVE:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:115:1: W293 [*] Blank line contains whitespace\n    |\n113 |             if config[\"status\"] != RegionStatus.ACTIVE:\n114 |                 continue\n115 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n116 |             score = 100  # Base score\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:117:1: W293 [*] Blank line contains whitespace\n    |\n116 |             score = 100  # Base score\n117 |             \n    | ^^^^^^^^^^^^ W293\n118 |             # Geographic proximity scoring\n119 |             if user_location:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:129:1: W293 [*] Blank line contains whitespace\n    |\n127 |                     if \"ap\" in region.value:\n128 |                         score += 50\n129 |             \n    | ^^^^^^^^^^^^ W293\n130 |             # Compliance requirements scoring\n131 |             if compliance_requirements:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:135:1: W293 [*] Blank line contains whitespace\n    |\n133 |                 if region_compliance in compliance_requirements:\n134 |                     score += 30\n135 |             \n    | ^^^^^^^^^^^^ W293\n136 |             # Language preference scoring\n137 |             if language_preference:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:142:1: W293 [*] Blank line contains whitespace\n    |\n140 |                 if language_preference == config[\"primary_language\"]:\n141 |                     score += 10\n142 |             \n    | ^^^^^^^^^^^^ W293\n143 |             # Health and performance scoring\n144 |             health = self.region_health.get(region, {})\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:147:1: W293 [*] Blank line contains whitespace\n    |\n145 |             if health.get(\"status\") == \"healthy\":\n146 |                 score += 10\n147 |             \n    | ^^^^^^^^^^^^ W293\n148 |             response_time = health.get(\"response_time_ms\", 100)\n149 |             if response_time < 100:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:151:1: W293 [*] Blank line contains whitespace\n    |\n149 |             if response_time < 100:\n150 |                 score += (100 - response_time) // 10\n151 |             \n    | ^^^^^^^^^^^^ W293\n152 |             # Capacity scoring\n153 |             capacity = config[\"capacity\"]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:156:1: W293 [*] Blank line contains whitespace\n    |\n154 |             cpu_available = capacity[\"cpu\"] * (1 - health.get(\"cpu_usage\", 0.5))\n155 |             memory_available = capacity[\"memory\"] * (1 - health.get(\"memory_usage\", 0.5))\n156 |             \n    | ^^^^^^^^^^^^ W293\n157 |             if cpu_available > 20 and memory_available > 200:\n158 |                 score += 15\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:159:1: W293 [*] Blank line contains whitespace\n    |\n157 |             if cpu_available > 20 and memory_available > 200:\n158 |                 score += 15\n159 |             \n    | ^^^^^^^^^^^^ W293\n160 |             scoring[region] = score\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:161:1: W293 [*] Blank line contains whitespace\n    |\n160 |             scoring[region] = score\n161 |         \n    | ^^^^^^^^ W293\n162 |         # Return region with highest score\n163 |         if scoring:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:167:1: W293 [*] Blank line contains whitespace\n    |\n165 |             self.logger.info(f\"Optimal region selected: {optimal_region.value} (score: {scoring[optimal_region]})\")\n166 |             return optimal_region\n167 |         \n    | ^^^^^^^^ W293\n168 |         # Fallback to US East\n169 |         return DeploymentRegion.US_EAST_1\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:170:1: W293 [*] Blank line contains whitespace\n    |\n168 |         # Fallback to US East\n169 |         return DeploymentRegion.US_EAST_1\n170 |     \n    | ^^^^ W293\n171 |     def deploy_to_region(self, region: DeploymentRegion, \n172 |                         deployment_config: Dict[str, Any]) -> Dict[str, Any]:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:171:57: W291 [*] Trailing whitespace\n    |\n169 |         return DeploymentRegion.US_EAST_1\n170 |     \n171 |     def deploy_to_region(self, region: DeploymentRegion, \n    |                                                         ^ W291\n172 |                         deployment_config: Dict[str, Any]) -> Dict[str, Any]:\n173 |         \"\"\"Deploy DGDN to specific region.\"\"\"\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/deployment/region_manager.py:176:1: W293 [*] Blank line contains whitespace\n    |\n174 |         if region not in self.regions:\n175 |             raise ValueError(f\"Unsupported region: {region}\")\n176 |         \n    | ^^^^^^^^ W293\n177 |         region_config = self.regions[region]\n178 |         deployment_id = f\"dgdn-{region.value}-{datetime.utcnow().strftime('%Y%m%d-%H%M%S')}\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:179:1: W293 [*] Blank line contains whitespace\n    |\n177 |         region_config = self.regions[region]\n178 |         deployment_id = f\"dgdn-{region.value}-{datetime.utcnow().strftime('%Y%m%d-%H%M%S')}\"\n179 |         \n    | ^^^^^^^^ W293\n180 |         deployment_result = {\n181 |             \"deployment_id\": deployment_id,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:190:1: W293 [*] Blank line contains whitespace\n    |\n188 |             \"data_residency\": region_config[\"data_residency\"]\n189 |         }\n190 |         \n    | ^^^^^^^^ W293\n191 |         try:\n192 |             # Simulate deployment steps\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:194:1: W293 [*] Blank line contains whitespace\n    |\n192 |             # Simulate deployment steps\n193 |             deployment_steps = self._execute_deployment_steps(region, deployment_config)\n194 |             \n    | ^^^^^^^^^^^^ W293\n195 |             deployment_result.update({\n196 |                 \"status\": \"completed\",\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:202:1: W293 [*] Blank line contains whitespace\n    |\n200 |                 \"monitoring_dashboard\": f\"https://monitoring.dgdn.ai/regions/{region.value}\"\n201 |             })\n202 |             \n    | ^^^^^^^^^^^^ W293\n203 |             # Update region status\n204 |             self.regions[region][\"status\"] = RegionStatus.ACTIVE\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:205:1: W293 [*] Blank line contains whitespace\n    |\n203 |             # Update region status\n204 |             self.regions[region][\"status\"] = RegionStatus.ACTIVE\n205 |             \n    | ^^^^^^^^^^^^ W293\n206 |             self.logger.info(f\"Deployment completed successfully: {deployment_id}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:207:1: W293 [*] Blank line contains whitespace\n    |\n206 |             self.logger.info(f\"Deployment completed successfully: {deployment_id}\")\n207 |             \n    | ^^^^^^^^^^^^ W293\n208 |         except Exception as e:\n209 |             deployment_result.update({\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:214:1: W293 [*] Blank line contains whitespace\n    |\n212 |                 \"failed_at\": datetime.utcnow().isoformat()\n213 |             })\n214 |             \n    | ^^^^^^^^^^^^ W293\n215 |             self.logger.error(f\"Deployment failed: {deployment_id} - {e}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:216:1: W293 [*] Blank line contains whitespace\n    |\n215 |             self.logger.error(f\"Deployment failed: {deployment_id} - {e}\")\n216 |         \n    | ^^^^^^^^ W293\n217 |         # Record deployment history\n218 |         self.deployment_history.append(deployment_result)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:219:1: W293 [*] Blank line contains whitespace\n    |\n217 |         # Record deployment history\n218 |         self.deployment_history.append(deployment_result)\n219 |         \n    | ^^^^^^^^ W293\n220 |         return deployment_result\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:221:1: W293 [*] Blank line contains whitespace\n    |\n220 |         return deployment_result\n221 |     \n    | ^^^^ W293\n222 |     def _execute_deployment_steps(self, region: DeploymentRegion, \n223 |                                 config: Dict[str, Any]) -> List[Dict[str, Any]]:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:222:66: W291 [*] Trailing whitespace\n    |\n220 |         return deployment_result\n221 |     \n222 |     def _execute_deployment_steps(self, region: DeploymentRegion, \n    |                                                                  ^ W291\n223 |                                 config: Dict[str, Any]) -> List[Dict[str, Any]]:\n224 |         \"\"\"Execute deployment steps for region.\"\"\"\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/deployment/region_manager.py:232:52: W291 [*] Trailing whitespace\n    |\n230 |             },\n231 |             {\n232 |                 \"step\": \"provision_infrastructure\", \n    |                                                    ^ W291\n233 |                 \"status\": \"completed\",\n234 |                 \"description\": f\"Provision infrastructure in {region.value}\"\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/deployment/region_manager.py:238:39: W291 [*] Trailing whitespace\n    |\n236 |             {\n237 |                 \"step\": \"deploy_application\",\n238 |                 \"status\": \"completed\", \n    |                                       ^ W291\n239 |                 \"description\": \"Deploy DGDN application components\"\n240 |             },\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/deployment/region_manager.py:253:39: W291 [*] Trailing whitespace\n    |\n251 |             {\n252 |                 \"step\": \"configure_i18n\",\n253 |                 \"status\": \"completed\", \n    |                                       ^ W291\n254 |                 \"description\": f\"Configure internationalization for {self.regions[region]['supported_languages']}\"\n255 |             },\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/deployment/region_manager.py:262:1: W293 [*] Blank line contains whitespace\n    |\n260 |             }\n261 |         ]\n262 |         \n    | ^^^^^^^^ W293\n263 |         return steps\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:264:1: W293 [*] Blank line contains whitespace\n    |\n263 |         return steps\n264 |     \n    | ^^^^ W293\n265 |     def configure_traffic_routing(self, routing_rules: Dict[str, Any]) -> Dict[str, Any]:\n266 |         \"\"\"Configure global traffic routing rules.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:272:1: W293 [*] Blank line contains whitespace\n    |\n270 |             \"active\": True\n271 |         }\n272 |         \n    | ^^^^^^^^ W293\n273 |         # Example routing configuration\n274 |         default_routing = {\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:277:56: W291 [*] Trailing whitespace\n    |\n275 |             \"geographic_routing\": {\n276 |                 \"us\": DeploymentRegion.US_EAST_1.value,\n277 |                 \"eu\": DeploymentRegion.EU_WEST_1.value, \n    |                                                        ^ W291\n278 |                 \"asia\": DeploymentRegion.AP_SOUTHEAST_1.value\n279 |             },\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/deployment/region_manager.py:291:1: W293 [*] Blank line contains whitespace\n    |\n289 |             }\n290 |         }\n291 |         \n    | ^^^^^^^^ W293\n292 |         self.traffic_routing[\"rules\"] = {**default_routing, **routing_rules}\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:293:1: W293 [*] Blank line contains whitespace\n    |\n292 |         self.traffic_routing[\"rules\"] = {**default_routing, **routing_rules}\n293 |         \n    | ^^^^^^^^ W293\n294 |         self.logger.info(\"Traffic routing configured\")\n295 |         return self.traffic_routing\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:296:1: W293 [*] Blank line contains whitespace\n    |\n294 |         self.logger.info(\"Traffic routing configured\")\n295 |         return self.traffic_routing\n296 |     \n    | ^^^^ W293\n297 |     def get_region_health(self, region: Optional[DeploymentRegion] = None) -> Dict[str, Any]:\n298 |         \"\"\"Get health status for regions.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:303:1: W293 [*] Blank line contains whitespace\n    |\n301 |                 return {\"error\": f\"No health data for region {region.value}\"}\n302 |             return {region.value: self.region_health[region]}\n303 |         \n    | ^^^^^^^^ W293\n304 |         # Return all region health data\n305 |         return {\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:306:38: W291 [*] Trailing whitespace\n    |\n304 |         # Return all region health data\n305 |         return {\n306 |             region.value: health_data \n    |                                      ^ W291\n307 |             for region, health_data in self.region_health.items()\n308 |         }\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/deployment/region_manager.py:309:1: W293 [*] Blank line contains whitespace\n    |\n307 |             for region, health_data in self.region_health.items()\n308 |         }\n309 |     \n    | ^^^^ W293\n310 |     def update_region_health(self, region: DeploymentRegion, health_metrics: Dict[str, Any]):\n311 |         \"\"\"Update health metrics for a region.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:314:1: W293 [*] Blank line contains whitespace\n    |\n312 |         if region not in self.regions:\n313 |             raise ValueError(f\"Unknown region: {region}\")\n314 |         \n    | ^^^^^^^^ W293\n315 |         self.region_health[region] = {\n316 |             **self.region_health.get(region, {}),\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:320:1: W293 [*] Blank line contains whitespace\n    |\n318 |             \"last_updated\": datetime.utcnow().isoformat()\n319 |         }\n320 |         \n    | ^^^^^^^^ W293\n321 |         # Update region status based on health\n322 |         if health_metrics.get(\"error_rate\", 0) > 0.1:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:328:1: W293 [*] Blank line contains whitespace\n    |\n326 |         else:\n327 |             self.regions[region][\"status\"] = RegionStatus.ACTIVE\n328 |         \n    | ^^^^^^^^ W293\n329 |         self.logger.debug(f\"Health updated for region {region.value}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:330:1: W293 [*] Blank line contains whitespace\n    |\n329 |         self.logger.debug(f\"Health updated for region {region.value}\")\n330 |     \n    | ^^^^ W293\n331 |     def scale_region(self, region: DeploymentRegion, scale_factor: float) -> Dict[str, Any]:\n332 |         \"\"\"Scale resources in a specific region.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:335:1: W293 [*] Blank line contains whitespace\n    |\n333 |         if region not in self.regions:\n334 |             raise ValueError(f\"Unknown region: {region}\")\n335 |         \n    | ^^^^^^^^ W293\n336 |         region_config = self.regions[region]\n337 |         current_capacity = region_config[\"capacity\"]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:338:1: W293 [*] Blank line contains whitespace\n    |\n336 |         region_config = self.regions[region]\n337 |         current_capacity = region_config[\"capacity\"]\n338 |         \n    | ^^^^^^^^ W293\n339 |         # Calculate new capacity\n340 |         new_capacity = {\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:345:1: W293 [*] Blank line contains whitespace\n    |\n343 |             \"storage\": int(current_capacity[\"storage\"] * scale_factor)\n344 |         }\n345 |         \n    | ^^^^^^^^ W293\n346 |         # Update region capacity\n347 |         self.regions[region][\"capacity\"] = new_capacity\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:348:1: W293 [*] Blank line contains whitespace\n    |\n346 |         # Update region capacity\n347 |         self.regions[region][\"capacity\"] = new_capacity\n348 |         \n    | ^^^^^^^^ W293\n349 |         scaling_result = {\n350 |             \"region\": region.value,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:357:1: W293 [*] Blank line contains whitespace\n    |\n355 |             \"status\": \"completed\"\n356 |         }\n357 |         \n    | ^^^^^^^^ W293\n358 |         self.logger.info(f\"Region {region.value} scaled by factor {scale_factor}\")\n359 |         return scaling_result\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:360:1: W293 [*] Blank line contains whitespace\n    |\n358 |         self.logger.info(f\"Region {region.value} scaled by factor {scale_factor}\")\n359 |         return scaling_result\n360 |     \n    | ^^^^ W293\n361 |     def get_deployment_status(self) -> Dict[str, Any]:\n362 |         \"\"\"Get overall deployment status across all regions.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:367:1: W293 [*] Blank line contains whitespace\n    |\n365 |             if config[\"status\"] == RegionStatus.ACTIVE\n366 |         ]\n367 |         \n    | ^^^^^^^^ W293\n368 |         total_capacity = {\n369 |             \"cpu\": sum(config[\"capacity\"][\"cpu\"] for config in self.regions.values()),\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:373:1: W293 [*] Blank line contains whitespace\n    |\n371 |             \"storage\": sum(config[\"capacity\"][\"storage\"] for config in self.regions.values())\n372 |         }\n373 |         \n    | ^^^^^^^^ W293\n374 |         return {\n375 |             \"total_regions\": len(self.regions),\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:384:41: C401 Unnecessary generator (rewrite as a set comprehension)\n    |\n382 |                   \"pdpa\": any(config[\"compliance_regime\"] == \"pdpa\" for config in self.regions.values())\n383 |               },\n384 |               \"supported_languages\": list(set(\n    |  _________________________________________^\n385 | |                 lang for config in self.regions.values() \n386 | |                 for lang in config[\"supported_languages\"]\n387 | |             )),\n    | |_____________^ C401\n388 |               \"traffic_routing_active\": self.traffic_routing.get(\"active\", False),\n389 |               \"last_deployment\": self.deployment_history[-1][\"started_at\"] if self.deployment_history else None,\n    |\n    = help: Rewrite as a set comprehension\n\nsrc/dgdn/deployment/region_manager.py:385:57: W291 [*] Trailing whitespace\n    |\n383 |             },\n384 |             \"supported_languages\": list(set(\n385 |                 lang for config in self.regions.values() \n    |                                                         ^ W291\n386 |                 for lang in config[\"supported_languages\"]\n387 |             )),\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/deployment/region_manager.py:392:1: W293 [*] Blank line contains whitespace\n    |\n390 |             \"status_timestamp\": datetime.utcnow().isoformat()\n391 |         }\n392 |     \n    | ^^^^ W293\n393 |     def get_region_recommendations(self, user_context: Dict[str, Any]) -> List[Dict[str, Any]]:\n394 |         \"\"\"Get region recommendations based on user context.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:396:1: W293 [*] Blank line contains whitespace\n    |\n394 |         \"\"\"Get region recommendations based on user context.\"\"\"\n395 |         recommendations = []\n396 |         \n    | ^^^^^^^^ W293\n397 |         for region, config in self.regions.items():\n398 |             if config[\"status\"] != RegionStatus.ACTIVE:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:400:1: W293 [*] Blank line contains whitespace\n    |\n398 |             if config[\"status\"] != RegionStatus.ACTIVE:\n399 |                 continue\n400 |             \n    | ^^^^^^^^^^^^ W293\n401 |             recommendation = {\n402 |                 \"region\": region.value,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:410:1: W293 [*] Blank line contains whitespace\n    |\n408 |                 \"estimated_latency_ms\": 50  # Would be calculated based on user location\n409 |             }\n410 |             \n    | ^^^^^^^^^^^^ W293\n411 |             # Scoring based on user context\n412 |             user_location = user_context.get(\"location\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:423:1: W293 [*] Blank line contains whitespace\n    |\n421 |                     recommendation[\"score\"] += 50\n422 |                     recommendation[\"reasons\"].append(\"Geographic proximity\")\n423 |             \n    | ^^^^^^^^^^^^ W293\n424 |             user_language = user_context.get(\"language\", \"en\")\n425 |             if user_language in config[\"supported_languages\"]:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:428:1: W293 [*] Blank line contains whitespace\n    |\n426 |                 recommendation[\"score\"] += 20\n427 |                 recommendation[\"reasons\"].append(f\"Supports {user_language} language\")\n428 |             \n    | ^^^^^^^^^^^^ W293\n429 |             compliance_needs = user_context.get(\"compliance_requirements\", [])\n430 |             if config[\"compliance_regime\"] in compliance_needs:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:433:1: W293 [*] Blank line contains whitespace\n    |\n431 |                 recommendation[\"score\"] += 30\n432 |                 recommendation[\"reasons\"].append(f\"{config['compliance_regime'].upper()} compliance\")\n433 |             \n    | ^^^^^^^^^^^^ W293\n434 |             # Health-based scoring\n435 |             health = self.region_health.get(region, {})\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:439:1: W293 [*] Blank line contains whitespace\n    |\n437 |                 recommendation[\"score\"] += 10\n438 |                 recommendation[\"reasons\"].append(\"Healthy region status\")\n439 |             \n    | ^^^^^^^^^^^^ W293\n440 |             recommendations.append(recommendation)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:441:1: W293 [*] Blank line contains whitespace\n    |\n440 |             recommendations.append(recommendation)\n441 |         \n    | ^^^^^^^^ W293\n442 |         # Sort by score descending\n443 |         recommendations.sort(key=lambda x: x[\"score\"], reverse=True)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:444:1: W293 [*] Blank line contains whitespace\n    |\n442 |         # Sort by score descending\n443 |         recommendations.sort(key=lambda x: x[\"score\"], reverse=True)\n444 |         \n    | ^^^^^^^^ W293\n445 |         return recommendations\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/deployment/region_manager.py:445:31: W292 [*] No newline at end of file\n    |\n443 |         recommendations.sort(key=lambda x: x[\"score\"], reverse=True)\n444 |         \n445 |         return recommendations\n    |                               ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/i18n/__init__.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n  |\n1 |   \"\"\"Internationalization (I18n) support for DGDN.\"\"\"\n2 |\n3 | / from .translator import DGDNTranslator, get_translator, set_global_locale\n4 | | from .messages import Messages\n5 | | from .locales import SUPPORTED_LOCALES\n  | |______________________________________^ I001\n6 |\n7 |   __all__ = [\"DGDNTranslator\", \"get_translator\", \"set_global_locale\", \"Messages\", \"SUPPORTED_LOCALES\"]\n  |\n  = help: Organize imports\n\nsrc/dgdn/i18n/__init__.py:7:101: W292 [*] No newline at end of file\n  |\n5 | from .locales import SUPPORTED_LOCALES\n6 |\n7 | __all__ = [\"DGDNTranslator\", \"get_translator\", \"set_global_locale\", \"Messages\", \"SUPPORTED_LOCALES\"]\n  |                                                                                                     ^ W292\n  |\n  = help: Add trailing newline\n\nsrc/dgdn/i18n/locales.py:30:26: W291 [*] Trailing whitespace\n   |\n28 |     },\n29 |     'fr': {\n30 |         'name': 'French', \n   |                          ^ W291\n31 |         'native_name': 'Fran\u00e7ais',\n32 |         'direction': 'ltr',\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/i18n/locales.py:37:34: W291 [*] Trailing whitespace\n   |\n35 |     'de': {\n36 |         'name': 'German',\n37 |         'native_name': 'Deutsch', \n   |                                  ^ W291\n38 |         'direction': 'ltr',\n39 |         'region': 'DE'\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/i18n/locales.py:65:16: W292 [*] No newline at end of file\n   |\n63 | def get_default_locale() -> str:\n64 |     \"\"\"Get the default locale.\"\"\"\n65 |     return 'en'\n   |                ^ W292\n   |\n   = help: Add trailing newline\n\nsrc/dgdn/i18n/messages.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n  |\n1 | \"\"\"Localized messages for DGDN library.\"\"\"\n2 |\n3 | from typing import Dict, Any\n  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ I001\n4 |\n5 | # Message templates for all supported languages\n  |\n  = help: Organize imports\n\nsrc/dgdn/i18n/messages.py:3:26: F401 [*] `typing.Any` imported but unused\n  |\n1 | \"\"\"Localized messages for DGDN library.\"\"\"\n2 |\n3 | from typing import Dict, Any\n  |                          ^^^ F401\n4 |\n5 | # Message templates for all supported languages\n  |\n  = help: Remove unused import: `typing.Any`\n\nsrc/dgdn/i18n/messages.py:15:1: W293 [*] Blank line contains whitespace\n   |\n13 |         'training.early_stop': 'Early stopping at epoch {epoch}',\n14 |         'training.checkpoint_saved': 'Checkpoint saved at {path}',\n15 |         \n   | ^^^^^^^^ W293\n16 |         # Model messages\n17 |         'model.loading': 'Loading model from {path}',\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:22:1: W293 [*] Blank line contains whitespace\n   |\n20 |         'model.validation.success': 'Model validation passed',\n21 |         'model.validation.failed': 'Model validation failed: {error}',\n22 |         \n   | ^^^^^^^^ W293\n23 |         # Data messages\n24 |         'data.loading': 'Loading dataset from {path}',\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:29:1: W293 [*] Blank line contains whitespace\n   |\n27 |         'data.validation.success': 'Data validation passed',\n28 |         'data.validation.failed': 'Data validation failed: {error}',\n29 |         \n   | ^^^^^^^^ W293\n30 |         # Performance messages\n31 |         'perf.optimization.enabled': 'Performance optimizations enabled: {optimizations}',\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:35:1: W293 [*] Blank line contains whitespace\n   |\n33 |         'perf.memory.usage': 'Memory usage: {usage:.1f} MB',\n34 |         'perf.speed_improvement': 'Speed improvement: {improvement:.1%}',\n35 |         \n   | ^^^^^^^^ W293\n36 |         # Error messages\n37 |         'error.invalid_input': 'Invalid input: {details}',\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:42:1: W293 [*] Blank line contains whitespace\n   |\n40 |         'error.unsupported_operation': 'Unsupported operation: {operation}',\n41 |         'error.security.path_traversal': 'Security error: path traversal attempt blocked',\n42 |         \n   | ^^^^^^^^ W293\n43 |         # Security messages\n44 |         'security.validation.passed': 'Security validation passed',\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:47:1: W293 [*] Blank line contains whitespace\n   |\n45 |         'security.input_sanitized': 'Input sanitized for security',\n46 |         'security.access_denied': 'Access denied for security reasons',\n47 |         \n   | ^^^^^^^^ W293\n48 |         # Success messages\n49 |         'success.operation_completed': 'Operation completed successfully',\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:53:1: W293 [*] Blank line contains whitespace\n   |\n51 |         'success.tests_passed': 'All tests passed ({passed}/{total})',\n52 |     },\n53 |     \n   | ^^^^ W293\n54 |     'es': {\n55 |         # Training messages\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:62:1: W293 [*] Blank line contains whitespace\n   |\n60 |         'training.early_stop': 'Parada temprana en \u00e9poca {epoch}',\n61 |         'training.checkpoint_saved': 'Punto de control guardado en {path}',\n62 |         \n   | ^^^^^^^^ W293\n63 |         # Model messages\n64 |         'model.loading': 'Cargando modelo desde {path}',\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:69:1: W293 [*] Blank line contains whitespace\n   |\n67 |         'model.validation.success': 'Validaci\u00f3n del modelo exitosa',\n68 |         'model.validation.failed': 'Validaci\u00f3n del modelo fall\u00f3: {error}',\n69 |         \n   | ^^^^^^^^ W293\n70 |         # Data messages\n71 |         'data.loading': 'Cargando conjunto de datos desde {path}',\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:76:1: W293 [*] Blank line contains whitespace\n   |\n74 |         'data.validation.success': 'Validaci\u00f3n de datos exitosa',\n75 |         'data.validation.failed': 'Validaci\u00f3n de datos fall\u00f3: {error}',\n76 |         \n   | ^^^^^^^^ W293\n77 |         # Performance messages\n78 |         'perf.optimization.enabled': 'Optimizaciones de rendimiento habilitadas: {optimizations}',\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:82:1: W293 [*] Blank line contains whitespace\n   |\n80 |         'perf.memory.usage': 'Uso de memoria: {usage:.1f} MB',\n81 |         'perf.speed_improvement': 'Mejora de velocidad: {improvement:.1%}',\n82 |         \n   | ^^^^^^^^ W293\n83 |         # Error messages\n84 |         'error.invalid_input': 'Entrada inv\u00e1lida: {details}',\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:89:1: W293 [*] Blank line contains whitespace\n   |\n87 |         'error.unsupported_operation': 'Operaci\u00f3n no soportada: {operation}',\n88 |         'error.security.path_traversal': 'Error de seguridad: intento de traversal de path bloqueado',\n89 |         \n   | ^^^^^^^^ W293\n90 |         # Security messages\n91 |         'security.validation.passed': 'Validaci\u00f3n de seguridad exitosa',\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:94:1: W293 [*] Blank line contains whitespace\n   |\n92 |         'security.input_sanitized': 'Entrada sanitizada por seguridad',\n93 |         'security.access_denied': 'Acceso denegado por razones de seguridad',\n94 |         \n   | ^^^^^^^^ W293\n95 |         # Success messages\n96 |         'success.operation_completed': 'Operaci\u00f3n completada exitosamente',\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:100:1: W293 [*] Blank line contains whitespace\n    |\n 98 |         'success.tests_passed': 'Todas las pruebas pasaron ({passed}/{total})',\n 99 |     },\n100 |     \n    | ^^^^ W293\n101 |     'fr': {\n102 |         # Training messages\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:109:1: W293 [*] Blank line contains whitespace\n    |\n107 |         'training.early_stop': 'Arr\u00eat pr\u00e9coce \u00e0 l\\'\u00e9poque {epoch}',\n108 |         'training.checkpoint_saved': 'Point de contr\u00f4le sauvegard\u00e9 \u00e0 {path}',\n109 |         \n    | ^^^^^^^^ W293\n110 |         # Model messages\n111 |         'model.loading': 'Chargement du mod\u00e8le depuis {path}',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:116:1: W293 [*] Blank line contains whitespace\n    |\n114 |         'model.validation.success': 'Validation du mod\u00e8le r\u00e9ussie',\n115 |         'model.validation.failed': 'Validation du mod\u00e8le \u00e9chou\u00e9e: {error}',\n116 |         \n    | ^^^^^^^^ W293\n117 |         # Data messages\n118 |         'data.loading': 'Chargement du jeu de donn\u00e9es depuis {path}',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:123:1: W293 [*] Blank line contains whitespace\n    |\n121 |         'data.validation.success': 'Validation des donn\u00e9es r\u00e9ussie',\n122 |         'data.validation.failed': 'Validation des donn\u00e9es \u00e9chou\u00e9e: {error}',\n123 |         \n    | ^^^^^^^^ W293\n124 |         # Performance messages\n125 |         'perf.optimization.enabled': 'Optimisations de performance activ\u00e9es: {optimizations}',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:129:1: W293 [*] Blank line contains whitespace\n    |\n127 |         'perf.memory.usage': 'Utilisation m\u00e9moire: {usage:.1f} MB',\n128 |         'perf.speed_improvement': 'Am\u00e9lioration de vitesse: {improvement:.1%}',\n129 |         \n    | ^^^^^^^^ W293\n130 |         # Error messages\n131 |         'error.invalid_input': 'Entr\u00e9e invalide: {details}',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:136:1: W293 [*] Blank line contains whitespace\n    |\n134 |         'error.unsupported_operation': 'Op\u00e9ration non support\u00e9e: {operation}',\n135 |         'error.security.path_traversal': 'Erreur de s\u00e9curit\u00e9: tentative de travers\u00e9e de chemin bloqu\u00e9e',\n136 |         \n    | ^^^^^^^^ W293\n137 |         # Security messages\n138 |         'security.validation.passed': 'Validation de s\u00e9curit\u00e9 r\u00e9ussie',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:141:1: W293 [*] Blank line contains whitespace\n    |\n139 |         'security.input_sanitized': 'Entr\u00e9e nettoy\u00e9e pour la s\u00e9curit\u00e9',\n140 |         'security.access_denied': 'Acc\u00e8s refus\u00e9 pour des raisons de s\u00e9curit\u00e9',\n141 |         \n    | ^^^^^^^^ W293\n142 |         # Success messages\n143 |         'success.operation_completed': 'Op\u00e9ration termin\u00e9e avec succ\u00e8s',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:147:1: W293 [*] Blank line contains whitespace\n    |\n145 |         'success.tests_passed': 'Tous les tests r\u00e9ussis ({passed}/{total})',\n146 |     },\n147 |     \n    | ^^^^ W293\n148 |     'de': {\n149 |         # Training messages\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:156:1: W293 [*] Blank line contains whitespace\n    |\n154 |         'training.early_stop': 'Fr\u00fchzeitiger Stopp bei Epoche {epoch}',\n155 |         'training.checkpoint_saved': 'Checkpoint gespeichert unter {path}',\n156 |         \n    | ^^^^^^^^ W293\n157 |         # Model messages\n158 |         'model.loading': 'Modell wird geladen von {path}',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:163:1: W293 [*] Blank line contains whitespace\n    |\n161 |         'model.validation.success': 'Modellvalidierung erfolgreich',\n162 |         'model.validation.failed': 'Modellvalidierung fehlgeschlagen: {error}',\n163 |         \n    | ^^^^^^^^ W293\n164 |         # Data messages\n165 |         'data.loading': 'Datensatz wird geladen von {path}',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:170:1: W293 [*] Blank line contains whitespace\n    |\n168 |         'data.validation.success': 'Datenvalidierung erfolgreich',\n169 |         'data.validation.failed': 'Datenvalidierung fehlgeschlagen: {error}',\n170 |         \n    | ^^^^^^^^ W293\n171 |         # Performance messages\n172 |         'perf.optimization.enabled': 'Leistungsoptimierungen aktiviert: {optimizations}',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:176:1: W293 [*] Blank line contains whitespace\n    |\n174 |         'perf.memory.usage': 'Speicherverbrauch: {usage:.1f} MB',\n175 |         'perf.speed_improvement': 'Geschwindigkeitsverbesserung: {improvement:.1%}',\n176 |         \n    | ^^^^^^^^ W293\n177 |         # Error messages\n178 |         'error.invalid_input': 'Ung\u00fcltige Eingabe: {details}',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:183:1: W293 [*] Blank line contains whitespace\n    |\n181 |         'error.unsupported_operation': 'Nicht unterst\u00fctzte Operation: {operation}',\n182 |         'error.security.path_traversal': 'Sicherheitsfehler: Path-Traversal-Versuch blockiert',\n183 |         \n    | ^^^^^^^^ W293\n184 |         # Security messages\n185 |         'security.validation.passed': 'Sicherheitsvalidierung erfolgreich',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:188:1: W293 [*] Blank line contains whitespace\n    |\n186 |         'security.input_sanitized': 'Eingabe aus Sicherheitsgr\u00fcnden bereinigt',\n187 |         'security.access_denied': 'Zugang aus Sicherheitsgr\u00fcnden verweigert',\n188 |         \n    | ^^^^^^^^ W293\n189 |         # Success messages\n190 |         'success.operation_completed': 'Operation erfolgreich abgeschlossen',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:194:1: W293 [*] Blank line contains whitespace\n    |\n192 |         'success.tests_passed': 'Alle Tests bestanden ({passed}/{total})',\n193 |     },\n194 |     \n    | ^^^^ W293\n195 |     'ja': {\n196 |         # Training messages\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:203:1: W293 [*] Blank line contains whitespace\n    |\n201 |         'training.early_stop': '\u30a8\u30dd\u30c3\u30af{epoch}\u3067\u65e9\u671f\u505c\u6b62',\n202 |         'training.checkpoint_saved': '\u30c1\u30a7\u30c3\u30af\u30dd\u30a4\u30f3\u30c8\u3092{path}\u306b\u4fdd\u5b58\u3057\u307e\u3057\u305f',\n203 |         \n    | ^^^^^^^^ W293\n204 |         # Model messages\n205 |         'model.loading': '{path}\u304b\u3089\u30e2\u30c7\u30eb\u3092\u8aad\u307f\u8fbc\u307f\u4e2d',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:210:1: W293 [*] Blank line contains whitespace\n    |\n208 |         'model.validation.success': '\u30e2\u30c7\u30eb\u691c\u8a3c\u304c\u6210\u529f\u3057\u307e\u3057\u305f',\n209 |         'model.validation.failed': '\u30e2\u30c7\u30eb\u691c\u8a3c\u304c\u5931\u6557\u3057\u307e\u3057\u305f: {error}',\n210 |         \n    | ^^^^^^^^ W293\n211 |         # Data messages\n212 |         'data.loading': '{path}\u304b\u3089\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u8aad\u307f\u8fbc\u307f\u4e2d',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:217:1: W293 [*] Blank line contains whitespace\n    |\n215 |         'data.validation.success': '\u30c7\u30fc\u30bf\u691c\u8a3c\u304c\u6210\u529f\u3057\u307e\u3057\u305f',\n216 |         'data.validation.failed': '\u30c7\u30fc\u30bf\u691c\u8a3c\u304c\u5931\u6557\u3057\u307e\u3057\u305f: {error}',\n217 |         \n    | ^^^^^^^^ W293\n218 |         # Performance messages\n219 |         'perf.optimization.enabled': '\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u6700\u9069\u5316\u304c\u6709\u52b9: {optimizations}',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:223:1: W293 [*] Blank line contains whitespace\n    |\n221 |         'perf.memory.usage': '\u30e1\u30e2\u30ea\u4f7f\u7528\u91cf: {usage:.1f} MB',\n222 |         'perf.speed_improvement': '\u901f\u5ea6\u6539\u5584: {improvement:.1%}',\n223 |         \n    | ^^^^^^^^ W293\n224 |         # Error messages\n225 |         'error.invalid_input': '\u7121\u52b9\u306a\u5165\u529b: {details}',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:230:1: W293 [*] Blank line contains whitespace\n    |\n228 |         'error.unsupported_operation': '\u30b5\u30dd\u30fc\u30c8\u3055\u308c\u3066\u3044\u306a\u3044\u64cd\u4f5c: {operation}',\n229 |         'error.security.path_traversal': '\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30a8\u30e9\u30fc: \u30d1\u30b9\u30c8\u30e9\u30d0\u30fc\u30b5\u30eb\u653b\u6483\u3092\u30d6\u30ed\u30c3\u30af\u3057\u307e\u3057\u305f',\n230 |         \n    | ^^^^^^^^ W293\n231 |         # Security messages\n232 |         'security.validation.passed': '\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u691c\u8a3c\u304c\u6210\u529f\u3057\u307e\u3057\u305f',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:235:1: W293 [*] Blank line contains whitespace\n    |\n233 |         'security.input_sanitized': '\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u306e\u305f\u3081\u5165\u529b\u3092\u30b5\u30cb\u30bf\u30a4\u30ba\u3057\u307e\u3057\u305f',\n234 |         'security.access_denied': '\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u4e0a\u306e\u7406\u7531\u3067\u30a2\u30af\u30bb\u30b9\u304c\u62d2\u5426\u3055\u308c\u307e\u3057\u305f',\n235 |         \n    | ^^^^^^^^ W293\n236 |         # Success messages\n237 |         'success.operation_completed': '\u64cd\u4f5c\u304c\u6b63\u5e38\u306b\u5b8c\u4e86\u3057\u307e\u3057\u305f',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:241:1: W293 [*] Blank line contains whitespace\n    |\n239 |         'success.tests_passed': '\u3059\u3079\u3066\u306e\u30c6\u30b9\u30c8\u304c\u6210\u529f\u3057\u307e\u3057\u305f\uff08{passed}/{total}\uff09',\n240 |     },\n241 |     \n    | ^^^^ W293\n242 |     'zh': {\n243 |         # Training messages\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:250:1: W293 [*] Blank line contains whitespace\n    |\n248 |         'training.early_stop': '\u5728\u8f6e\u6b21{epoch}\u63d0\u524d\u505c\u6b62',\n249 |         'training.checkpoint_saved': '\u68c0\u67e5\u70b9\u5df2\u4fdd\u5b58\u5230{path}',\n250 |         \n    | ^^^^^^^^ W293\n251 |         # Model messages\n252 |         'model.loading': '\u4ece{path}\u52a0\u8f7d\u6a21\u578b',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:257:1: W293 [*] Blank line contains whitespace\n    |\n255 |         'model.validation.success': '\u6a21\u578b\u9a8c\u8bc1\u6210\u529f',\n256 |         'model.validation.failed': '\u6a21\u578b\u9a8c\u8bc1\u5931\u8d25: {error}',\n257 |         \n    | ^^^^^^^^ W293\n258 |         # Data messages\n259 |         'data.loading': '\u4ece{path}\u52a0\u8f7d\u6570\u636e\u96c6',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:264:1: W293 [*] Blank line contains whitespace\n    |\n262 |         'data.validation.success': '\u6570\u636e\u9a8c\u8bc1\u6210\u529f',\n263 |         'data.validation.failed': '\u6570\u636e\u9a8c\u8bc1\u5931\u8d25: {error}',\n264 |         \n    | ^^^^^^^^ W293\n265 |         # Performance messages\n266 |         'perf.optimization.enabled': '\u6027\u80fd\u4f18\u5316\u5df2\u542f\u7528: {optimizations}',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:270:1: W293 [*] Blank line contains whitespace\n    |\n268 |         'perf.memory.usage': '\u5185\u5b58\u4f7f\u7528: {usage:.1f} MB',\n269 |         'perf.speed_improvement': '\u901f\u5ea6\u63d0\u5347: {improvement:.1%}',\n270 |         \n    | ^^^^^^^^ W293\n271 |         # Error messages\n272 |         'error.invalid_input': '\u65e0\u6548\u8f93\u5165: {details}',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:277:1: W293 [*] Blank line contains whitespace\n    |\n275 |         'error.unsupported_operation': '\u4e0d\u652f\u6301\u7684\u64cd\u4f5c: {operation}',\n276 |         'error.security.path_traversal': '\u5b89\u5168\u9519\u8bef\uff1a\u5df2\u963b\u6b62\u8def\u5f84\u904d\u5386\u653b\u51fb',\n277 |         \n    | ^^^^^^^^ W293\n278 |         # Security messages\n279 |         'security.validation.passed': '\u5b89\u5168\u9a8c\u8bc1\u901a\u8fc7',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:282:1: W293 [*] Blank line contains whitespace\n    |\n280 |         'security.input_sanitized': '\u4e3a\u5b89\u5168\u8d77\u89c1\u5df2\u6e05\u7406\u8f93\u5165',\n281 |         'security.access_denied': '\u51fa\u4e8e\u5b89\u5168\u539f\u56e0\u62d2\u7edd\u8bbf\u95ee',\n282 |         \n    | ^^^^^^^^ W293\n283 |         # Success messages\n284 |         'success.operation_completed': '\u64cd\u4f5c\u6210\u529f\u5b8c\u6210',\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:293:1: W293 [*] Blank line contains whitespace\n    |\n291 | class Messages:\n292 |     \"\"\"Message container for localized strings.\"\"\"\n293 |     \n    | ^^^^ W293\n294 |     def __init__(self, locale: str = 'en'):\n295 |         self.locale = locale\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:297:1: W293 [*] Blank line contains whitespace\n    |\n295 |         self.locale = locale\n296 |         self.messages = MESSAGES.get(locale, MESSAGES['en'])\n297 |     \n    | ^^^^ W293\n298 |     def get(self, key: str, **kwargs) -> str:\n299 |         \"\"\"Get localized message with formatting.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:306:1: W293 [*] Blank line contains whitespace\n    |\n304 |             # Fallback to template without formatting if kwargs don't match\n305 |             return template\n306 |     \n    | ^^^^ W293\n307 |     def has(self, key: str) -> bool:\n308 |         \"\"\"Check if message key exists.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:310:1: W293 [*] Blank line contains whitespace\n    |\n308 |         \"\"\"Check if message key exists.\"\"\"\n309 |         return key in self.messages\n310 |     \n    | ^^^^ W293\n311 |     def set_locale(self, locale: str):\n312 |         \"\"\"Change the current locale.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/messages.py:314:61: W292 [*] No newline at end of file\n    |\n312 |         \"\"\"Change the current locale.\"\"\"\n313 |         self.locale = locale\n314 |         self.messages = MESSAGES.get(locale, MESSAGES['en'])\n    |                                                             ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/i18n/translator.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n  |\n1 |   \"\"\"Translation system for DGDN library.\"\"\"\n2 |\n3 | / import os\n4 | | import threading\n5 | | from typing import Optional, Dict, Any\n6 | | from .messages import Messages, MESSAGES\n7 | | from .locales import SUPPORTED_LOCALES, get_default_locale, is_supported_locale\n  | |_______________________________________________________________________________^ I001\n8 |\n9 |   # Global translator instance\n  |\n  = help: Organize imports\n\nsrc/dgdn/i18n/translator.py:5:36: F401 [*] `typing.Any` imported but unused\n  |\n3 | import os\n4 | import threading\n5 | from typing import Optional, Dict, Any\n  |                                    ^^^ F401\n6 | from .messages import Messages, MESSAGES\n7 | from .locales import SUPPORTED_LOCALES, get_default_locale, is_supported_locale\n  |\n  = help: Remove unused import: `typing.Any`\n\nsrc/dgdn/i18n/translator.py:6:33: F401 [*] `.messages.MESSAGES` imported but unused\n  |\n4 | import threading\n5 | from typing import Optional, Dict, Any\n6 | from .messages import Messages, MESSAGES\n  |                                 ^^^^^^^^ F401\n7 | from .locales import SUPPORTED_LOCALES, get_default_locale, is_supported_locale\n  |\n  = help: Remove unused import: `.messages.MESSAGES`\n\nsrc/dgdn/i18n/translator.py:16:1: W293 [*] Blank line contains whitespace\n   |\n14 | class DGDNTranslator:\n15 |     \"\"\"Main translation system for DGDN library.\"\"\"\n16 |     \n   | ^^^^ W293\n17 |     def __init__(self, locale: Optional[str] = None):\n18 |         \"\"\"Initialize translator with locale detection.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:23:1: W293 [*] Blank line contains whitespace\n   |\n21 |         self._fallback_locale = get_default_locale()\n22 |         self._fallback_messages = Messages(self._fallback_locale)\n23 |     \n   | ^^^^ W293\n24 |     def _detect_locale(self, provided_locale: Optional[str]) -> str:\n25 |         \"\"\"Detect locale from various sources.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:32:1: W293 [*] Blank line contains whitespace\n   |\n30 |         # 4. System locale detection\n31 |         # 5. Default fallback\n32 |         \n   | ^^^^^^^^ W293\n33 |         if provided_locale and is_supported_locale(provided_locale):\n34 |             return provided_locale\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:35:1: W293 [*] Blank line contains whitespace\n   |\n33 |         if provided_locale and is_supported_locale(provided_locale):\n34 |             return provided_locale\n35 |         \n   | ^^^^^^^^ W293\n36 |         # Check environment variables\n37 |         env_locale = os.environ.get('DGDN_LOCALE')\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:40:1: W293 [*] Blank line contains whitespace\n   |\n38 |         if env_locale and is_supported_locale(env_locale):\n39 |             return env_locale\n40 |         \n   | ^^^^^^^^ W293\n41 |         # Check system LANG variable\n42 |         lang_var = os.environ.get('LANG', '')\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:48:1: W293 [*] Blank line contains whitespace\n   |\n46 |             if is_supported_locale(lang_code):\n47 |                 return lang_code\n48 |         \n   | ^^^^^^^^ W293\n49 |         # Try to detect system locale\n50 |         try:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:59:1: W293 [*] Blank line contains whitespace\n   |\n57 |         except (ImportError, TypeError):\n58 |             pass\n59 |         \n   | ^^^^^^^^ W293\n60 |         # Fallback to default\n61 |         return get_default_locale()\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:62:1: W293 [*] Blank line contains whitespace\n   |\n60 |         # Fallback to default\n61 |         return get_default_locale()\n62 |     \n   | ^^^^ W293\n63 |     @property\n64 |     def locale(self) -> str:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:67:1: W293 [*] Blank line contains whitespace\n   |\n65 |         \"\"\"Get current locale.\"\"\"\n66 |         return self._locale\n67 |     \n   | ^^^^ W293\n68 |     @locale.setter\n69 |     def locale(self, value: str):\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:76:1: W293 [*] Blank line contains whitespace\n   |\n74 |         else:\n75 |             raise ValueError(f\"Unsupported locale: {value}. Supported: {SUPPORTED_LOCALES}\")\n76 |     \n   | ^^^^ W293\n77 |     def translate(self, key: str, **kwargs) -> str:\n78 |         \"\"\"Translate message key with formatting.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:82:1: W293 [*] Blank line contains whitespace\n   |\n80 |         if self._messages.has(key):\n81 |             return self._messages.get(key, **kwargs)\n82 |         \n   | ^^^^^^^^ W293\n83 |         # Fallback to default locale\n84 |         if self._locale != self._fallback_locale:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:87:1: W293 [*] Blank line contains whitespace\n   |\n85 |             if self._fallback_messages.has(key):\n86 |                 return self._fallback_messages.get(key, **kwargs)\n87 |         \n   | ^^^^^^^^ W293\n88 |         # Ultimate fallback: return key itself\n89 |         return key\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:90:1: W293 [*] Blank line contains whitespace\n   |\n88 |         # Ultimate fallback: return key itself\n89 |         return key\n90 |     \n   | ^^^^ W293\n91 |     def t(self, key: str, **kwargs) -> str:\n92 |         \"\"\"Short alias for translate().\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:94:1: W293 [*] Blank line contains whitespace\n   |\n92 |         \"\"\"Short alias for translate().\"\"\"\n93 |         return self.translate(key, **kwargs)\n94 |     \n   | ^^^^ W293\n95 |     def has_translation(self, key: str) -> bool:\n96 |         \"\"\"Check if translation exists for key.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:98:1: W293 [*] Blank line contains whitespace\n    |\n 96 |         \"\"\"Check if translation exists for key.\"\"\"\n 97 |         return self._messages.has(key) or self._fallback_messages.has(key)\n 98 |     \n    | ^^^^ W293\n 99 |     def get_supported_locales(self) -> set:\n100 |         \"\"\"Get list of supported locales.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:102:1: W293 [*] Blank line contains whitespace\n    |\n100 |         \"\"\"Get list of supported locales.\"\"\"\n101 |         return SUPPORTED_LOCALES.copy()\n102 |     \n    | ^^^^ W293\n103 |     def get_locale_info(self, locale: Optional[str] = None) -> Dict[str, str]:\n104 |         \"\"\"Get information about current or specified locale.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:108:1: W293 [*] Blank line contains whitespace\n    |\n106 |         target_locale = locale or self._locale\n107 |         return get_locale_info(target_locale)\n108 |     \n    | ^^^^ W293\n109 |     def format_number(self, number: float, decimal_places: int = 2) -> str:\n110 |         \"\"\"Format number according to locale conventions.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:121:1: W293 [*] Blank line contains whitespace\n    |\n119 |             # Default English formatting\n120 |             formatted = f\"{number:,.{decimal_places}f}\"\n121 |         \n    | ^^^^^^^^ W293\n122 |         return formatted\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:123:1: W293 [*] Blank line contains whitespace\n    |\n122 |         return formatted\n123 |     \n    | ^^^^ W293\n124 |     def format_percentage(self, value: float, decimal_places: int = 1) -> str:\n125 |         \"\"\"Format percentage according to locale.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:128:1: W293 [*] Blank line contains whitespace\n    |\n126 |         percentage = value * 100\n127 |         formatted_num = self.format_number(percentage, decimal_places)\n128 |         \n    | ^^^^^^^^ W293\n129 |         if self._locale == 'fr':\n130 |             return f\"{formatted_num} %\"  # French has space before %\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:133:1: W293 [*] Blank line contains whitespace\n    |\n131 |         else:\n132 |             return f\"{formatted_num}%\"\n133 |     \n    | ^^^^ W293\n134 |     def pluralize(self, key: str, count: int, **kwargs) -> str:\n135 |         \"\"\"Handle pluralization (simplified).\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:139:1: W293 [*] Blank line contains whitespace\n    |\n137 |         # In production, use proper pluralization rules for each language\n138 |         plural_key = f\"{key}.plural\" if count != 1 else key\n139 |         \n    | ^^^^^^^^ W293\n140 |         if self.has_translation(plural_key):\n141 |             return self.translate(plural_key, count=count, **kwargs)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:149:1: W293 [*] Blank line contains whitespace\n    |\n147 |     \"\"\"Get global translator instance (singleton pattern).\"\"\"\n148 |     global _translator_instance\n149 |     \n    | ^^^^ W293\n150 |     with _translator_lock:\n151 |         if _translator_instance is None or (locale and _translator_instance.locale != locale):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:159:1: W293 [*] Blank line contains whitespace\n    |\n157 |     \"\"\"Set global locale for all translations.\"\"\"\n158 |     global _translator_instance\n159 |     \n    | ^^^^ W293\n160 |     with _translator_lock:\n161 |         if _translator_instance is None:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:183:1: W293 [*] Blank line contains whitespace\n    |\n181 |     \"\"\"Format metric values with proper localization.\"\"\"\n182 |     translator = get_translator(locale)\n183 |     \n    | ^^^^ W293\n184 |     # Common metric formatting\n185 |     if 'percentage' in metric_name or 'rate' in metric_name:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:208:1: W293 [*] Blank line contains whitespace\n    |\n206 |     print(\"\ud83c\udf0d DGDN Internationalization Demo\")\n207 |     print(\"=\" * 50)\n208 |     \n    | ^^^^ W293\n209 |     for locale in SUPPORTED_LOCALES:\n210 |         translator = DGDNTranslator(locale)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/i18n/translator.py:219:23: W292 [*] No newline at end of file\n    |\n218 | if __name__ == \"__main__\":\n219 |     demonstrate_i18n()\n    |                       ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/optimization/__init__.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n   |\n 1 |   \"\"\"Performance optimization modules for DGDN.\"\"\"\n 2 |\n 3 | / from .memory import MemoryOptimizer\n 4 | | from .computation import (\n 5 | |     OptimizedOperations, ComputationOptimizer, TensorOperationOptimizer,\n 6 | |     ParallelProcessor, DynamicBatchSizer, GraphCompiler\n 7 | | )\n 8 | | from .caching import EmbeddingCache, AttentionCache, CacheManager\n   | |_________________________________________________________________^ I001\n 9 |\n10 |   __all__ = [\n   |\n   = help: Organize imports\n\nsrc/dgdn/optimization/__init__.py:14:32: W291 [*] Trailing whitespace\n   |\n12 |     \"OptimizedOperations\",\n13 |     \"ComputationOptimizer\",\n14 |     \"TensorOperationOptimizer\", \n   |                                ^ W291\n15 |     \"ParallelProcessor\",\n16 |     \"DynamicBatchSizer\",\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/optimization/__init__.py:21:2: W292 [*] No newline at end of file\n   |\n19 |     \"AttentionCache\",\n20 |     \"CacheManager\"\n21 | ]\n   |  ^ W292\n   |\n   = help: Add trailing newline\n\nsrc/dgdn/optimization/caching.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n   |\n 1 |   \"\"\"Caching mechanisms for DGDN performance optimization.\"\"\"\n 2 |\n 3 | / import torch\n 4 | | import torch.nn as nn\n 5 | | from typing import Dict, Tuple, Optional, Any, Union\n 6 | | from collections import OrderedDict\n 7 | | import logging\n 8 | | import hashlib\n 9 | | import pickle\n10 | | import time\n   | |___________^ I001\n   |\n   = help: Organize imports\n\nsrc/dgdn/optimization/caching.py:4:20: F401 [*] `torch.nn` imported but unused\n  |\n3 | import torch\n4 | import torch.nn as nn\n  |                    ^^ F401\n5 | from typing import Dict, Tuple, Optional, Any, Union\n6 | from collections import OrderedDict\n  |\n  = help: Remove unused import: `torch.nn`\n\nsrc/dgdn/optimization/caching.py:5:48: F401 [*] `typing.Union` imported but unused\n  |\n3 | import torch\n4 | import torch.nn as nn\n5 | from typing import Dict, Tuple, Optional, Any, Union\n  |                                                ^^^^^ F401\n6 | from collections import OrderedDict\n7 | import logging\n  |\n  = help: Remove unused import: `typing.Union`\n\nsrc/dgdn/optimization/caching.py:15:1: W293 [*] Blank line contains whitespace\n   |\n13 | class EmbeddingCache:\n14 |     \"\"\"Cache for node embeddings to avoid recomputation.\"\"\"\n15 |     \n   | ^^^^ W293\n16 |     def __init__(self, max_size: int = 10000, ttl_seconds: float = 300):\n17 |         \"\"\"Initialize embedding cache.\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:18:1: W293 Blank line contains whitespace\n   |\n16 |     def __init__(self, max_size: int = 10000, ttl_seconds: float = 300):\n17 |         \"\"\"Initialize embedding cache.\n18 |         \n   | ^^^^^^^^ W293\n19 |         Args:\n20 |             max_size: Maximum number of cached embeddings\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:30:1: W293 [*] Blank line contains whitespace\n   |\n28 |         self.miss_count = 0\n29 |         self.logger = logging.getLogger(__name__)\n30 |     \n   | ^^^^ W293\n31 |     def _generate_key(self, node_ids: torch.Tensor, time: float, \n32 |                      model_state: Optional[str] = None) -> str:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:31:65: W291 [*] Trailing whitespace\n   |\n29 |         self.logger = logging.getLogger(__name__)\n30 |     \n31 |     def _generate_key(self, node_ids: torch.Tensor, time: float, \n   |                                                                 ^ W291\n32 |                      model_state: Optional[str] = None) -> str:\n33 |         \"\"\"Generate cache key for embeddings.\"\"\"\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/optimization/caching.py:37:1: W293 [*] Blank line contains whitespace\n   |\n35 |         node_ids_str = str(sorted(node_ids.cpu().tolist()))\n36 |         time_str = f\"{time:.6f}\"\n37 |         \n   | ^^^^^^^^ W293\n38 |         # Include model state if provided (for cache invalidation)\n39 |         if model_state:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:43:1: W293 [*] Blank line contains whitespace\n   |\n41 |         else:\n42 |             key_data = f\"{node_ids_str}_{time_str}\"\n43 |         \n   | ^^^^^^^^ W293\n44 |         return hashlib.sha256(key_data.encode()).hexdigest()\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:45:1: W293 [*] Blank line contains whitespace\n   |\n44 |         return hashlib.sha256(key_data.encode()).hexdigest()\n45 |     \n   | ^^^^ W293\n46 |     def get(self, node_ids: torch.Tensor, time: float, \n47 |             model_state: Optional[str] = None) -> Optional[torch.Tensor]:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:46:55: W291 [*] Trailing whitespace\n   |\n44 |         return hashlib.sha256(key_data.encode()).hexdigest()\n45 |     \n46 |     def get(self, node_ids: torch.Tensor, time: float, \n   |                                                       ^ W291\n47 |             model_state: Optional[str] = None) -> Optional[torch.Tensor]:\n48 |         \"\"\"Get cached embeddings.\"\"\"\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/optimization/caching.py:50:1: W293 [*] Blank line contains whitespace\n   |\n48 |         \"\"\"Get cached embeddings.\"\"\"\n49 |         key = self._generate_key(node_ids, time, model_state)\n50 |         \n   | ^^^^^^^^ W293\n51 |         if key in self.cache:\n52 |             # Check TTL\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:57:1: W293 [*] Blank line contains whitespace\n   |\n55 |                 self.miss_count += 1\n56 |                 return None\n57 |             \n   | ^^^^^^^^^^^^ W293\n58 |             # Move to end (most recently used)\n59 |             embeddings = self.cache[key]\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:64:1: W293 [*] Blank line contains whitespace\n   |\n62 |             self.hit_count += 1\n63 |             return embeddings.clone()  # Return copy to avoid modifications\n64 |         \n   | ^^^^^^^^ W293\n65 |         self.miss_count += 1\n66 |         return None\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:67:1: W293 [*] Blank line contains whitespace\n   |\n65 |         self.miss_count += 1\n66 |         return None\n67 |     \n   | ^^^^ W293\n68 |     def put(self, node_ids: torch.Tensor, time: float, embeddings: torch.Tensor,\n69 |             model_state: Optional[str] = None):\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:72:1: W293 [*] Blank line contains whitespace\n   |\n70 |         \"\"\"Store embeddings in cache.\"\"\"\n71 |         key = self._generate_key(node_ids, time, model_state)\n72 |         \n   | ^^^^^^^^ W293\n73 |         # Evict oldest entries if at capacity\n74 |         while len(self.cache) >= self.max_size:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:78:1: W293 [*] Blank line contains whitespace\n   |\n76 |             if oldest_key in self.access_times:\n77 |                 del self.access_times[oldest_key]\n78 |         \n   | ^^^^^^^^ W293\n79 |         # Store embedding (detached from computation graph)\n80 |         self.cache[key] = embeddings.detach().clone()\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:82:1: W293 [*] Blank line contains whitespace\n   |\n80 |         self.cache[key] = embeddings.detach().clone()\n81 |         self.access_times[key] = time.time()\n82 |     \n   | ^^^^ W293\n83 |     def _evict_key(self, key: str):\n84 |         \"\"\"Evict specific key from cache.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:89:1: W293 [*] Blank line contains whitespace\n   |\n87 |         if key in self.access_times:\n88 |             del self.access_times[key]\n89 |     \n   | ^^^^ W293\n90 |     def clear(self):\n91 |         \"\"\"Clear all cached embeddings.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:96:1: W293 [*] Blank line contains whitespace\n   |\n94 |         self.hit_count = 0\n95 |         self.miss_count = 0\n96 |     \n   | ^^^^ W293\n97 |     def get_stats(self) -> Dict[str, Any]:\n98 |         \"\"\"Get cache statistics.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:101:1: W293 [*] Blank line contains whitespace\n    |\n 99 |         total_requests = self.hit_count + self.miss_count\n100 |         hit_rate = self.hit_count / total_requests if total_requests > 0 else 0\n101 |         \n    | ^^^^^^^^ W293\n102 |         return {\n103 |             'hit_count': self.hit_count,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:110:1: W293 [*] Blank line contains whitespace\n    |\n108 |             'memory_usage_mb': self._estimate_memory_usage() / 1e6\n109 |         }\n110 |     \n    | ^^^^ W293\n111 |     def _estimate_memory_usage(self) -> int:\n112 |         \"\"\"Estimate memory usage of cache in bytes.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:117:1: W293 [*] Blank line contains whitespace\n    |\n115 |             total_bytes += embedding.numel() * embedding.element_size()\n116 |         return total_bytes\n117 |     \n    | ^^^^ W293\n118 |     def cleanup_expired(self):\n119 |         \"\"\"Remove expired cache entries.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:122:1: W293 [*] Blank line contains whitespace\n    |\n120 |         current_time = time.time()\n121 |         expired_keys = []\n122 |         \n    | ^^^^^^^^ W293\n123 |         for key, access_time in self.access_times.items():\n124 |             if current_time - access_time > self.ttl_seconds:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:126:1: W293 [*] Blank line contains whitespace\n    |\n124 |             if current_time - access_time > self.ttl_seconds:\n125 |                 expired_keys.append(key)\n126 |         \n    | ^^^^^^^^ W293\n127 |         for key in expired_keys:\n128 |             self._evict_key(key)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:129:1: W293 [*] Blank line contains whitespace\n    |\n127 |         for key in expired_keys:\n128 |             self._evict_key(key)\n129 |         \n    | ^^^^^^^^ W293\n130 |         if expired_keys:\n131 |             self.logger.debug(f\"Cleaned up {len(expired_keys)} expired cache entries\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:136:1: W293 [*] Blank line contains whitespace\n    |\n134 | class AttentionCache:\n135 |     \"\"\"Cache for attention weights to speed up inference.\"\"\"\n136 |     \n    | ^^^^ W293\n137 |     def __init__(self, max_size: int = 5000):\n138 |         \"\"\"Initialize attention cache.\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:139:1: W293 Blank line contains whitespace\n    |\n137 |     def __init__(self, max_size: int = 5000):\n138 |         \"\"\"Initialize attention cache.\n139 |         \n    | ^^^^^^^^ W293\n140 |         Args:\n141 |             max_size: Maximum number of cached attention patterns\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:146:1: W293 [*] Blank line contains whitespace\n    |\n144 |         self.cache = OrderedDict()\n145 |         self.logger = logging.getLogger(__name__)\n146 |     \n    | ^^^^ W293\n147 |     def _generate_attention_key(self, edge_index: torch.Tensor, \n148 |                                temporal_encoding: torch.Tensor) -> str:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:147:64: W291 [*] Trailing whitespace\n    |\n145 |         self.logger = logging.getLogger(__name__)\n146 |     \n147 |     def _generate_attention_key(self, edge_index: torch.Tensor, \n    |                                                                ^ W291\n148 |                                temporal_encoding: torch.Tensor) -> str:\n149 |         \"\"\"Generate key for attention pattern.\"\"\"\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/optimization/caching.py:153:1: W293 [*] Blank line contains whitespace\n    |\n151 |         edge_hash = hashlib.sha256(edge_index.cpu().numpy().tobytes()).hexdigest()\n152 |         temporal_hash = hashlib.sha256(temporal_encoding.cpu().numpy().tobytes()).hexdigest()\n153 |         \n    | ^^^^^^^^ W293\n154 |         return f\"{edge_hash}_{temporal_hash}\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:155:1: W293 [*] Blank line contains whitespace\n    |\n154 |         return f\"{edge_hash}_{temporal_hash}\"\n155 |     \n    | ^^^^ W293\n156 |     def get_attention(self, edge_index: torch.Tensor, \n157 |                      temporal_encoding: torch.Tensor) -> Optional[torch.Tensor]:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:156:54: W291 [*] Trailing whitespace\n    |\n154 |         return f\"{edge_hash}_{temporal_hash}\"\n155 |     \n156 |     def get_attention(self, edge_index: torch.Tensor, \n    |                                                      ^ W291\n157 |                      temporal_encoding: torch.Tensor) -> Optional[torch.Tensor]:\n158 |         \"\"\"Get cached attention weights.\"\"\"\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/optimization/caching.py:160:1: W293 [*] Blank line contains whitespace\n    |\n158 |         \"\"\"Get cached attention weights.\"\"\"\n159 |         key = self._generate_attention_key(edge_index, temporal_encoding)\n160 |         \n    | ^^^^^^^^ W293\n161 |         if key in self.cache:\n162 |             attention_weights = self.cache[key]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:165:1: W293 [*] Blank line contains whitespace\n    |\n163 |             self.cache.move_to_end(key)  # Mark as recently used\n164 |             return attention_weights.clone()\n165 |         \n    | ^^^^^^^^ W293\n166 |         return None\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:167:1: W293 [*] Blank line contains whitespace\n    |\n166 |         return None\n167 |     \n    | ^^^^ W293\n168 |     def store_attention(self, edge_index: torch.Tensor, \n169 |                        temporal_encoding: torch.Tensor, \n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:168:56: W291 [*] Trailing whitespace\n    |\n166 |         return None\n167 |     \n168 |     def store_attention(self, edge_index: torch.Tensor, \n    |                                                        ^ W291\n169 |                        temporal_encoding: torch.Tensor, \n170 |                        attention_weights: torch.Tensor):\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/optimization/caching.py:169:56: W291 [*] Trailing whitespace\n    |\n168 |     def store_attention(self, edge_index: torch.Tensor, \n169 |                        temporal_encoding: torch.Tensor, \n    |                                                        ^ W291\n170 |                        attention_weights: torch.Tensor):\n171 |         \"\"\"Store attention weights in cache.\"\"\"\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/optimization/caching.py:173:1: W293 [*] Blank line contains whitespace\n    |\n171 |         \"\"\"Store attention weights in cache.\"\"\"\n172 |         key = self._generate_attention_key(edge_index, temporal_encoding)\n173 |         \n    | ^^^^^^^^ W293\n174 |         # Evict oldest if at capacity\n175 |         if len(self.cache) >= self.max_size:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:177:1: W293 [*] Blank line contains whitespace\n    |\n175 |         if len(self.cache) >= self.max_size:\n176 |             self.cache.popitem(last=False)\n177 |         \n    | ^^^^^^^^ W293\n178 |         self.cache[key] = attention_weights.detach().clone()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:183:1: W293 [*] Blank line contains whitespace\n    |\n181 | class ComputationCache:\n182 |     \"\"\"General purpose computation cache for expensive operations.\"\"\"\n183 |     \n    | ^^^^ W293\n184 |     def __init__(self, max_memory_mb: float = 1024):\n185 |         \"\"\"Initialize computation cache.\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:186:1: W293 Blank line contains whitespace\n    |\n184 |     def __init__(self, max_memory_mb: float = 1024):\n185 |         \"\"\"Initialize computation cache.\n186 |         \n    | ^^^^^^^^ W293\n187 |         Args:\n188 |             max_memory_mb: Maximum memory usage in MB\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:195:1: W293 [*] Blank line contains whitespace\n    |\n193 |         self.access_order = OrderedDict()\n194 |         self.logger = logging.getLogger(__name__)\n195 |     \n    | ^^^^ W293\n196 |     def _estimate_size(self, obj: Any) -> int:\n197 |         \"\"\"Estimate object size in bytes.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:203:13: E722 Do not use bare `except`\n    |\n201 |             try:\n202 |                 return len(pickle.dumps(obj))\n203 |             except:\n    |             ^^^^^^ E722\n204 |                 return 1000  # Conservative estimate\n    |\n\nsrc/dgdn/optimization/caching.py:205:1: W293 [*] Blank line contains whitespace\n    |\n203 |             except:\n204 |                 return 1000  # Conservative estimate\n205 |     \n    | ^^^^ W293\n206 |     def _make_key(self, func_name: str, args: Tuple, kwargs: Dict) -> str:\n207 |         \"\"\"Create cache key from function name and arguments.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:218:1: W293 [*] Blank line contains whitespace\n    |\n216 |             else:\n217 |                 return obj\n218 |         \n    | ^^^^^^^^ W293\n219 |         hashable_args = tensorize_args(args)\n220 |         hashable_kwargs = tensorize_args(kwargs)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:221:1: W293 [*] Blank line contains whitespace\n    |\n219 |         hashable_args = tensorize_args(args)\n220 |         hashable_kwargs = tensorize_args(kwargs)\n221 |         \n    | ^^^^^^^^ W293\n222 |         key_data = f\"{func_name}_{hashable_args}_{hashable_kwargs}\"\n223 |         return hashlib.sha256(str(key_data).encode()).hexdigest()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:224:1: W293 [*] Blank line contains whitespace\n    |\n222 |         key_data = f\"{func_name}_{hashable_args}_{hashable_kwargs}\"\n223 |         return hashlib.sha256(str(key_data).encode()).hexdigest()\n224 |     \n    | ^^^^ W293\n225 |     def get(self, func_name: str, args: Tuple, kwargs: Dict) -> Tuple[bool, Any]:\n226 |         \"\"\"Get cached result.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:228:1: W293 [*] Blank line contains whitespace\n    |\n226 |         \"\"\"Get cached result.\"\"\"\n227 |         key = self._make_key(func_name, args, kwargs)\n228 |         \n    | ^^^^^^^^ W293\n229 |         if key in self.cache:\n230 |             # Update access order\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:233:1: W293 [*] Blank line contains whitespace\n    |\n231 |             self.access_order.move_to_end(key)\n232 |             return True, self.cache[key]\n233 |         \n    | ^^^^^^^^ W293\n234 |         return False, None\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:235:1: W293 [*] Blank line contains whitespace\n    |\n234 |         return False, None\n235 |     \n    | ^^^^ W293\n236 |     def put(self, func_name: str, args: Tuple, kwargs: Dict, result: Any):\n237 |         \"\"\"Store computation result.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:240:1: W293 [*] Blank line contains whitespace\n    |\n238 |         key = self._make_key(func_name, args, kwargs)\n239 |         result_size = self._estimate_size(result)\n240 |         \n    | ^^^^^^^^ W293\n241 |         # Evict entries if memory limit would be exceeded\n242 |         while (self.memory_usage + result_size > self.max_memory_bytes and \n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:242:75: W291 [*] Trailing whitespace\n    |\n241 |         # Evict entries if memory limit would be exceeded\n242 |         while (self.memory_usage + result_size > self.max_memory_bytes and \n    |                                                                           ^ W291\n243 |                len(self.cache) > 0):\n244 |             self._evict_oldest()\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/optimization/caching.py:245:1: W293 [*] Blank line contains whitespace\n    |\n243 |                len(self.cache) > 0):\n244 |             self._evict_oldest()\n245 |         \n    | ^^^^^^^^ W293\n246 |         # Store result\n247 |         self.cache[key] = result\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:250:1: W293 [*] Blank line contains whitespace\n    |\n248 |         self.access_order[key] = True\n249 |         self.memory_usage += result_size\n250 |     \n    | ^^^^ W293\n251 |     def _evict_oldest(self):\n252 |         \"\"\"Evict oldest cache entry.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:269:1: W293 [*] Blank line contains whitespace\n    |\n267 |             if hit:\n268 |                 return result\n269 |             \n    | ^^^^^^^^^^^^ W293\n270 |             # Compute and cache result\n271 |             result = func(*args, **kwargs)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:273:1: W293 [*] Blank line contains whitespace\n    |\n271 |             result = func(*args, **kwargs)\n272 |             cache.put(func_name, args, kwargs, result)\n273 |             \n    | ^^^^^^^^^^^^ W293\n274 |             return result\n275 |         return wrapper\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:281:1: W293 [*] Blank line contains whitespace\n    |\n279 | class CacheManager:\n280 |     \"\"\"Unified cache management for DGDN.\"\"\"\n281 |     \n    | ^^^^ W293\n282 |     def __init__(self, config: Optional[Dict[str, Any]] = None):\n283 |         \"\"\"Initialize cache manager with configuration.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:285:1: W293 [*] Blank line contains whitespace\n    |\n283 |         \"\"\"Initialize cache manager with configuration.\"\"\"\n284 |         config = config or {}\n285 |         \n    | ^^^^^^^^ W293\n286 |         # Initialize caches\n287 |         self.embedding_cache = EmbeddingCache(\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:291:1: W293 [*] Blank line contains whitespace\n    |\n289 |             ttl_seconds=config.get('embedding_ttl', 300)\n290 |         )\n291 |         \n    | ^^^^^^^^ W293\n292 |         self.attention_cache = AttentionCache(\n293 |             max_size=config.get('attention_cache_size', 5000)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:295:1: W293 [*] Blank line contains whitespace\n    |\n293 |             max_size=config.get('attention_cache_size', 5000)\n294 |         )\n295 |         \n    | ^^^^^^^^ W293\n296 |         self.computation_cache = ComputationCache(\n297 |             max_memory_mb=config.get('computation_cache_mb', 1024)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:299:1: W293 [*] Blank line contains whitespace\n    |\n297 |             max_memory_mb=config.get('computation_cache_mb', 1024)\n298 |         )\n299 |         \n    | ^^^^^^^^ W293\n300 |         self.logger = logging.getLogger(__name__)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:301:1: W293 [*] Blank line contains whitespace\n    |\n300 |         self.logger = logging.getLogger(__name__)\n301 |         \n    | ^^^^^^^^ W293\n302 |         # Performance tracking\n303 |         self.enabled = config.get('enabled', True)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:309:1: W293 [*] Blank line contains whitespace\n    |\n307 |             'time_saved_ms': 0.0\n308 |         }\n309 |     \n    | ^^^^ W293\n310 |     def clear_all(self):\n311 |         \"\"\"Clear all caches.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:317:1: W293 [*] Blank line contains whitespace\n    |\n315 |         self.computation_cache.access_order.clear()\n316 |         self.computation_cache.memory_usage = 0\n317 |         \n    | ^^^^^^^^ W293\n318 |         self.logger.info(\"Cleared all caches\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:319:1: W293 [*] Blank line contains whitespace\n    |\n318 |         self.logger.info(\"Cleared all caches\")\n319 |     \n    | ^^^^ W293\n320 |     def get_global_stats(self) -> Dict[str, Any]:\n321 |         \"\"\"Get statistics for all caches.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:335:1: W293 [*] Blank line contains whitespace\n    |\n333 |             'global_stats': self.stats\n334 |         }\n335 |     \n    | ^^^^ W293\n336 |     def optimize_cache_sizes(self, memory_budget_mb: float):\n337 |         \"\"\"Optimize cache sizes based on memory budget.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:342:1: W293 [*] Blank line contains whitespace\n    |\n340 |         attention_ratio = 0.2\n341 |         computation_ratio = 0.2\n342 |         \n    | ^^^^^^^^ W293\n343 |         embedding_mb = memory_budget_mb * embedding_ratio\n344 |         attention_mb = memory_budget_mb * attention_ratio\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:344:9: F841 Local variable `attention_mb` is assigned to but never used\n    |\n343 |         embedding_mb = memory_budget_mb * embedding_ratio\n344 |         attention_mb = memory_budget_mb * attention_ratio\n    |         ^^^^^^^^^^^^ F841\n345 |         computation_mb = memory_budget_mb * computation_ratio\n    |\n    = help: Remove assignment to unused variable `attention_mb`\n\nsrc/dgdn/optimization/caching.py:346:1: W293 [*] Blank line contains whitespace\n    |\n344 |         attention_mb = memory_budget_mb * attention_ratio\n345 |         computation_mb = memory_budget_mb * computation_ratio\n346 |         \n    | ^^^^^^^^ W293\n347 |         # Estimate sizes and adjust cache limits\n348 |         # (This is a simplified heuristic - could be more sophisticated)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:351:1: W293 [*] Blank line contains whitespace\n    |\n349 |         avg_embedding_size_mb = 0.01  # Rough estimate\n350 |         new_embedding_size = int(embedding_mb / avg_embedding_size_mb)\n351 |         \n    | ^^^^^^^^ W293\n352 |         self.embedding_cache.max_size = min(new_embedding_size, 50000)\n353 |         self.computation_cache.max_memory_bytes = computation_mb * 1e6\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:354:1: W293 [*] Blank line contains whitespace\n    |\n352 |         self.embedding_cache.max_size = min(new_embedding_size, 50000)\n353 |         self.computation_cache.max_memory_bytes = computation_mb * 1e6\n354 |         \n    | ^^^^^^^^ W293\n355 |         self.logger.info(f\"Optimized cache sizes for {memory_budget_mb}MB budget\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/caching.py:355:83: W292 [*] No newline at end of file\n    |\n353 |         self.computation_cache.max_memory_bytes = computation_mb * 1e6\n354 |         \n355 |         self.logger.info(f\"Optimized cache sizes for {memory_budget_mb}MB budget\")\n    |                                                                                   ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/optimization/computation.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n   |\n 1 |   \"\"\"Computational optimizations for DGDN.\"\"\"\n 2 |\n 3 | / import torch\n 4 | | import torch.nn as nn\n 5 | | from typing import Optional, Dict, Any, Tuple, List\n 6 | | import math\n 7 | | from functools import lru_cache\n 8 | | import threading\n 9 | | from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n10 | | import multiprocessing as mp\n11 | |\n12 | | from ..utils.logging import get_logger\n   | |______________________________________^ I001\n   |\n   = help: Organize imports\n\nsrc/dgdn/optimization/computation.py:5:30: F401 [*] `typing.Dict` imported but unused\n  |\n3 | import torch\n4 | import torch.nn as nn\n5 | from typing import Optional, Dict, Any, Tuple, List\n  |                              ^^^^ F401\n6 | import math\n7 | from functools import lru_cache\n  |\n  = help: Remove unused import\n\nsrc/dgdn/optimization/computation.py:5:36: F401 [*] `typing.Any` imported but unused\n  |\n3 | import torch\n4 | import torch.nn as nn\n5 | from typing import Optional, Dict, Any, Tuple, List\n  |                                    ^^^ F401\n6 | import math\n7 | from functools import lru_cache\n  |\n  = help: Remove unused import\n\nsrc/dgdn/optimization/computation.py:5:41: F401 [*] `typing.Tuple` imported but unused\n  |\n3 | import torch\n4 | import torch.nn as nn\n5 | from typing import Optional, Dict, Any, Tuple, List\n  |                                         ^^^^^ F401\n6 | import math\n7 | from functools import lru_cache\n  |\n  = help: Remove unused import\n\nsrc/dgdn/optimization/computation.py:5:48: F401 [*] `typing.List` imported but unused\n  |\n3 | import torch\n4 | import torch.nn as nn\n5 | from typing import Optional, Dict, Any, Tuple, List\n  |                                                ^^^^ F401\n6 | import math\n7 | from functools import lru_cache\n  |\n  = help: Remove unused import\n\nsrc/dgdn/optimization/computation.py:7:23: F401 [*] `functools.lru_cache` imported but unused\n  |\n5 | from typing import Optional, Dict, Any, Tuple, List\n6 | import math\n7 | from functools import lru_cache\n  |                       ^^^^^^^^^ F401\n8 | import threading\n9 | from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n  |\n  = help: Remove unused import: `functools.lru_cache`\n\nsrc/dgdn/optimization/computation.py:9:52: F401 [*] `concurrent.futures.ProcessPoolExecutor` imported but unused\n   |\n 7 | from functools import lru_cache\n 8 | import threading\n 9 | from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n   |                                                    ^^^^^^^^^^^^^^^^^^^ F401\n10 | import multiprocessing as mp\n   |\n   = help: Remove unused import: `concurrent.futures.ProcessPoolExecutor`\n\nsrc/dgdn/optimization/computation.py:17:1: W293 [*] Blank line contains whitespace\n   |\n15 | class ComputationOptimizer:\n16 |     \"\"\"Optimizer for computational operations in DGDN.\"\"\"\n17 |     \n   | ^^^^ W293\n18 |     def __init__(\n19 |         self,\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:28:1: W293 [*] Blank line contains whitespace\n   |\n26 |         self.enable_graph_compilation = enable_graph_compilation\n27 |         self.logger = get_logger(\"dgdn.optimization\")\n28 |         \n   | ^^^^^^^^ W293\n29 |         # Mixed precision setup\n30 |         if enable_mixed_precision and torch.cuda.is_available():\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:34:1: W293 [*] Blank line contains whitespace\n   |\n32 |         else:\n33 |             self.scaler = None\n34 |         \n   | ^^^^^^^^ W293\n35 |         self.logger.info(f\"Computation optimizer initialized: \"\n36 |                         f\"mixed_precision={enable_mixed_precision}, \"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:38:1: W293 [*] Blank line contains whitespace\n   |\n36 |                         f\"mixed_precision={enable_mixed_precision}, \"\n37 |                         f\"gradient_checkpointing={enable_gradient_checkpointing}\")\n38 |     \n   | ^^^^ W293\n39 |     def optimize_forward_pass(self, model, data):\n40 |         \"\"\"Optimize forward pass with various techniques.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:46:1: W293 [*] Blank line contains whitespace\n   |\n44 |         else:\n45 |             return model(data)\n46 |     \n   | ^^^^ W293\n47 |     def optimize_backward_pass(self, loss, model):\n48 |         \"\"\"Optimize backward pass with scaling and gradient clipping.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:52:1: W293 [*] Blank line contains whitespace\n   |\n50 |             # Scale loss for mixed precision\n51 |             self.scaler.scale(loss).backward()\n52 |             \n   | ^^^^^^^^^^^^ W293\n53 |             # Gradient clipping with scaled gradients\n54 |             self.scaler.unscale_(model.optimizer if hasattr(model, 'optimizer') else None)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:56:1: W293 [*] Blank line contains whitespace\n   |\n54 |             self.scaler.unscale_(model.optimizer if hasattr(model, 'optimizer') else None)\n55 |             torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n56 |             \n   | ^^^^^^^^^^^^ W293\n57 |             # Update with scaled gradients\n58 |             if hasattr(model, 'optimizer'):\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:68:1: W293 [*] Blank line contains whitespace\n   |\n66 | class TensorOperationOptimizer:\n67 |     \"\"\"Optimize tensor operations for better performance.\"\"\"\n68 |     \n   | ^^^^ W293\n69 |     def __init__(self):\n70 |         self.logger = get_logger(\"dgdn.tensor_ops\")\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:73:1: W293 [*] Blank line contains whitespace\n   |\n71 |         self._operation_cache = {}\n72 |         self._cache_lock = threading.Lock()\n73 |     \n   | ^^^^ W293\n74 |     @staticmethod\n75 |     def optimized_attention(query, key, value, mask=None, dropout_p=0.0):\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:79:1: W293 [*] Blank line contains whitespace\n   |\n77 |         # Use scaled dot-product attention with optimizations\n78 |         batch_size, seq_len, embed_dim = query.shape\n79 |         \n   | ^^^^^^^^ W293\n80 |         # Efficient attention computation\n81 |         if torch.cuda.is_available() and hasattr(torch.nn.functional, 'scaled_dot_product_attention'):\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:90:1: W293 [*] Blank line contains whitespace\n   |\n88 |             scale = math.sqrt(embed_dim)\n89 |             scores = torch.matmul(query, key.transpose(-2, -1)) / scale\n90 |             \n   | ^^^^^^^^^^^^ W293\n91 |             if mask is not None:\n92 |                 scores = scores.masked_fill(mask == 0, -1e9)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:93:1: W293 [*] Blank line contains whitespace\n   |\n91 |             if mask is not None:\n92 |                 scores = scores.masked_fill(mask == 0, -1e9)\n93 |             \n   | ^^^^^^^^^^^^ W293\n94 |             attn_weights = torch.softmax(scores, dim=-1)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:95:1: W293 [*] Blank line contains whitespace\n   |\n94 |             attn_weights = torch.softmax(scores, dim=-1)\n95 |             \n   | ^^^^^^^^^^^^ W293\n96 |             if dropout_p > 0.0:\n97 |                 attn_weights = torch.dropout(attn_weights, dropout_p, training=True)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:98:1: W293 [*] Blank line contains whitespace\n   |\n96 |             if dropout_p > 0.0:\n97 |                 attn_weights = torch.dropout(attn_weights, dropout_p, training=True)\n98 |             \n   | ^^^^^^^^^^^^ W293\n99 |             return torch.matmul(attn_weights, value)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:100:1: W293 [*] Blank line contains whitespace\n    |\n 99 |             return torch.matmul(attn_weights, value)\n100 |     \n    | ^^^^ W293\n101 |     @staticmethod\n102 |     def optimized_edge_aggregation(edge_index, edge_attr, num_nodes, aggregation='mean'):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:105:1: W293 [*] Blank line contains whitespace\n    |\n103 |         \"\"\"Optimized edge aggregation for graph operations.\"\"\"\n104 |         src, dst = edge_index\n105 |         \n    | ^^^^^^^^ W293\n106 |         if aggregation == 'mean':\n107 |             # Use scatter operations for efficient aggregation\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:118:1: W293 [*] Blank line contains whitespace\n    |\n116 |                 node_features = torch.zeros(num_nodes, edge_attr.size(-1), device=edge_attr.device)\n117 |                 node_features.scatter_add_(0, dst.unsqueeze(-1).expand(-1, edge_attr.size(-1)), edge_attr)\n118 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n119 |                 # Count edges per node for averaging\n120 |                 edge_counts = torch.zeros(num_nodes, device=edge_attr.device)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:123:1: W293 [*] Blank line contains whitespace\n    |\n121 |                 edge_counts.scatter_add_(0, dst, torch.ones_like(dst, dtype=torch.float))\n122 |                 edge_counts = edge_counts.clamp(min=1).unsqueeze(-1)\n123 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n124 |                 return node_features / edge_counts\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:125:1: W293 [*] Blank line contains whitespace\n    |\n124 |                 return node_features / edge_counts\n125 |         \n    | ^^^^^^^^ W293\n126 |         elif aggregation == 'sum':\n127 |             node_features = torch.zeros(num_nodes, edge_attr.size(-1), device=edge_attr.device)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:129:1: W293 [*] Blank line contains whitespace\n    |\n127 |             node_features = torch.zeros(num_nodes, edge_attr.size(-1), device=edge_attr.device)\n128 |             return node_features.scatter_add_(0, dst.unsqueeze(-1).expand(-1, edge_attr.size(-1)), edge_attr)\n129 |         \n    | ^^^^^^^^ W293\n130 |         elif aggregation == 'max':\n131 |             node_features = torch.full((num_nodes, edge_attr.size(-1)), -float('inf'), device=edge_attr.device)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:133:1: W293 [*] Blank line contains whitespace\n    |\n131 |             node_features = torch.full((num_nodes, edge_attr.size(-1)), -float('inf'), device=edge_attr.device)\n132 |             return node_features.scatter_reduce_(0, dst.unsqueeze(-1).expand(-1, edge_attr.size(-1)), edge_attr, reduce='amax')\n133 |         \n    | ^^^^^^^^ W293\n134 |         else:\n135 |             raise ValueError(f\"Unsupported aggregation: {aggregation}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:136:1: W293 [*] Blank line contains whitespace\n    |\n134 |         else:\n135 |             raise ValueError(f\"Unsupported aggregation: {aggregation}\")\n136 |     \n    | ^^^^ W293\n137 |     def cache_computation(self, key: str, computation_fn, *args, **kwargs):\n138 |         \"\"\"Cache expensive computations.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:143:1: W293 [*] Blank line contains whitespace\n    |\n141 |                 self.logger.debug(f\"Cache hit for operation: {key}\")\n142 |                 return self._operation_cache[key]\n143 |             \n    | ^^^^^^^^^^^^ W293\n144 |             result = computation_fn(*args, **kwargs)\n145 |             self._operation_cache[key] = result\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:148:1: W293 [*] Blank line contains whitespace\n    |\n146 |             self.logger.debug(f\"Cached result for operation: {key}\")\n147 |             return result\n148 |     \n    | ^^^^ W293\n149 |     def clear_cache(self):\n150 |         \"\"\"Clear the operation cache.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:158:1: W293 [*] Blank line contains whitespace\n    |\n156 | class ParallelProcessor:\n157 |     \"\"\"Parallel processing utilities for DGDN operations.\"\"\"\n158 |     \n    | ^^^^ W293\n159 |     def __init__(self, max_workers: Optional[int] = None):\n160 |         self.max_workers = max_workers or min(8, mp.cpu_count())\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:162:1: W293 [*] Blank line contains whitespace\n    |\n160 |         self.max_workers = max_workers or min(8, mp.cpu_count())\n161 |         self.logger = get_logger(\"dgdn.parallel\")\n162 |         \n    | ^^^^^^^^ W293\n163 |         # Thread pool for I/O bound operations\n164 |         self.thread_pool = ThreadPoolExecutor(max_workers=self.max_workers)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:165:1: W293 [*] Blank line contains whitespace\n    |\n163 |         # Thread pool for I/O bound operations\n164 |         self.thread_pool = ThreadPoolExecutor(max_workers=self.max_workers)\n165 |         \n    | ^^^^^^^^ W293\n166 |         # Process pool for CPU bound operations (reduced for safety)\n167 |         self.process_pool = ThreadPoolExecutor(max_workers=min(4, mp.cpu_count()))\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:168:1: W293 [*] Blank line contains whitespace\n    |\n166 |         # Process pool for CPU bound operations (reduced for safety)\n167 |         self.process_pool = ThreadPoolExecutor(max_workers=min(4, mp.cpu_count()))\n168 |         \n    | ^^^^^^^^ W293\n169 |         self.logger.info(f\"Parallel processor initialized with {self.max_workers} workers\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:170:1: W293 [*] Blank line contains whitespace\n    |\n169 |         self.logger.info(f\"Parallel processor initialized with {self.max_workers} workers\")\n170 |     \n    | ^^^^ W293\n171 |     def parallel_batch_processing(self, data_list, process_fn, use_threads=True):\n172 |         \"\"\"Process batches in parallel.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:174:1: W293 [*] Blank line contains whitespace\n    |\n172 |         \"\"\"Process batches in parallel.\"\"\"\n173 |         executor = self.thread_pool if use_threads else self.process_pool\n174 |         \n    | ^^^^^^^^ W293\n175 |         try:\n176 |             futures = [executor.submit(process_fn, data) for data in data_list]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:182:1: W293 [*] Blank line contains whitespace\n    |\n180 |             self.logger.error(f\"Parallel processing failed: {e}\")\n181 |             raise\n182 |     \n    | ^^^^ W293\n183 |     def parallel_graph_processing(self, graphs, model, batch_size=32):\n184 |         \"\"\"Process multiple graphs in parallel.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:192:1: W293 [*] Blank line contains whitespace\n    |\n190 |                     results.append(output)\n191 |                 return results\n192 |         \n    | ^^^^^^^^ W293\n193 |         # Split graphs into batches\n194 |         batches = [graphs[i:i + batch_size] for i in range(0, len(graphs), batch_size)]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:195:1: W293 [*] Blank line contains whitespace\n    |\n193 |         # Split graphs into batches\n194 |         batches = [graphs[i:i + batch_size] for i in range(0, len(graphs), batch_size)]\n195 |         \n    | ^^^^^^^^ W293\n196 |         # Process batches in parallel\n197 |         batch_results = self.parallel_batch_processing(batches, process_batch)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:198:1: W293 [*] Blank line contains whitespace\n    |\n196 |         # Process batches in parallel\n197 |         batch_results = self.parallel_batch_processing(batches, process_batch)\n198 |         \n    | ^^^^^^^^ W293\n199 |         # Flatten results\n200 |         all_results = []\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:203:1: W293 [*] Blank line contains whitespace\n    |\n201 |         for batch_result in batch_results:\n202 |             all_results.extend(batch_result)\n203 |         \n    | ^^^^^^^^ W293\n204 |         return all_results\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:205:1: W293 [*] Blank line contains whitespace\n    |\n204 |         return all_results\n205 |     \n    | ^^^^ W293\n206 |     def cleanup(self):\n207 |         \"\"\"Clean up thread and process pools.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:215:1: W293 [*] Blank line contains whitespace\n    |\n213 | class MemoryOptimizer:\n214 |     \"\"\"Memory optimization utilities.\"\"\"\n215 |     \n    | ^^^^ W293\n216 |     def __init__(self):\n217 |         self.logger = get_logger(\"dgdn.memory\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:219:1: W293 [*] Blank line contains whitespace\n    |\n217 |         self.logger = get_logger(\"dgdn.memory\")\n218 |         self._gradient_checkpointing_enabled = False\n219 |     \n    | ^^^^ W293\n220 |     def enable_gradient_checkpointing(self, model):\n221 |         \"\"\"Enable gradient checkpointing to trade compute for memory.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:226:1: W293 [*] Blank line contains whitespace\n    |\n224 |                 return module(*inputs)\n225 |             return custom_forward\n226 |         \n    | ^^^^^^^^ W293\n227 |         # Wrap model layers with checkpointing\n228 |         for name, module in model.named_modules():\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:228:13: B007 Loop control variable `name` not used within loop body\n    |\n227 |         # Wrap model layers with checkpointing\n228 |         for name, module in model.named_modules():\n    |             ^^^^ B007\n229 |             if isinstance(module, nn.Module) and len(list(module.children())) == 0:\n230 |                 # Leaf modules\n    |\n    = help: Rename unused `name` to `_name`\n\nsrc/dgdn/optimization/computation.py:231:17: F841 Local variable `original_forward` is assigned to but never used\n    |\n229 |             if isinstance(module, nn.Module) and len(list(module.children())) == 0:\n230 |                 # Leaf modules\n231 |                 original_forward = module.forward\n    |                 ^^^^^^^^^^^^^^^^ F841\n232 |                 \n233 |                 def checkpointed_forward(self, *args, **kwargs):\n    |\n    = help: Remove assignment to unused variable `original_forward`\n\nsrc/dgdn/optimization/computation.py:232:1: W293 [*] Blank line contains whitespace\n    |\n230 |                 # Leaf modules\n231 |                 original_forward = module.forward\n232 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n233 |                 def checkpointed_forward(self, *args, **kwargs):\n234 |                     return torch.utils.checkpoint.checkpoint(\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:238:1: W293 [*] Blank line contains whitespace\n    |\n236 |                         self, *args, **kwargs\n237 |                     )\n238 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n239 |                 module.forward = checkpointed_forward.__get__(module, module.__class__)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:240:1: W293 [*] Blank line contains whitespace\n    |\n239 |                 module.forward = checkpointed_forward.__get__(module, module.__class__)\n240 |         \n    | ^^^^^^^^ W293\n241 |         self._gradient_checkpointing_enabled = True\n242 |         self.logger.info(\"Gradient checkpointing enabled\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:243:1: W293 [*] Blank line contains whitespace\n    |\n241 |         self._gradient_checkpointing_enabled = True\n242 |         self.logger.info(\"Gradient checkpointing enabled\")\n243 |     \n    | ^^^^ W293\n244 |     def optimize_memory_usage(self, model, data):\n245 |         \"\"\"Optimize memory usage during forward pass.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:251:1: W293 [*] Blank line contains whitespace\n    |\n249 |                 if hasattr(layer, 'attention') and hasattr(layer.attention, 'enable_memory_efficient'):\n250 |                     layer.attention.enable_memory_efficient = True\n251 |         \n    | ^^^^^^^^ W293\n252 |         # Use memory-efficient data loading\n253 |         if hasattr(data, 'pin_memory'):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:255:1: W293 [*] Blank line contains whitespace\n    |\n253 |         if hasattr(data, 'pin_memory'):\n254 |             data.pin_memory()\n255 |         \n    | ^^^^^^^^ W293\n256 |         return data\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:257:1: W293 [*] Blank line contains whitespace\n    |\n256 |         return data\n257 |     \n    | ^^^^ W293\n258 |     def memory_profiling_context(self):\n259 |         \"\"\"Context manager for memory profiling.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:264:1: W293 [*] Blank line contains whitespace\n    |\n262 |                 self.logger = logger\n263 |                 self.start_memory = 0\n264 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n265 |             def __enter__(self):\n266 |                 if torch.cuda.is_available():\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:270:1: W293 [*] Blank line contains whitespace\n    |\n268 |                     self.start_memory = torch.cuda.memory_allocated()\n269 |                 return self\n270 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n271 |             def __exit__(self, exc_type, exc_val, exc_tb):\n272 |                 if torch.cuda.is_available():\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:277:1: W293 [*] Blank line contains whitespace\n    |\n275 |                     memory_used = (end_memory - self.start_memory) / 1024 / 1024\n276 |                     self.logger.info(f\"Memory used: {memory_used:.2f} MB\")\n277 |         \n    | ^^^^^^^^ W293\n278 |         return MemoryProfiler(self.logger)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:283:1: W293 [*] Blank line contains whitespace\n    |\n281 | class DynamicBatchSizer:\n282 |     \"\"\"Dynamic batch size optimization based on available memory.\"\"\"\n283 |     \n    | ^^^^ W293\n284 |     def __init__(self, initial_batch_size: int = 32, max_batch_size: int = 512):\n285 |         self.initial_batch_size = initial_batch_size\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:289:1: W293 [*] Blank line contains whitespace\n    |\n287 |         self.current_batch_size = initial_batch_size\n288 |         self.logger = get_logger(\"dgdn.batch_sizer\")\n289 |         \n    | ^^^^^^^^ W293\n290 |         self.oom_count = 0\n291 |         self.success_count = 0\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:292:1: W293 [*] Blank line contains whitespace\n    |\n290 |         self.oom_count = 0\n291 |         self.success_count = 0\n292 |         \n    | ^^^^^^^^ W293\n293 |     def get_optimal_batch_size(self, model, sample_data):\n294 |         \"\"\"Find optimal batch size through binary search.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:300:1: W293 [*] Blank line contains whitespace\n    |\n298 |                 with torch.no_grad():\n299 |                     _ = model(sample_data)\n300 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n301 |                 if torch.cuda.is_available():\n302 |                     torch.cuda.empty_cache()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:303:1: W293 [*] Blank line contains whitespace\n    |\n301 |                 if torch.cuda.is_available():\n302 |                     torch.cuda.empty_cache()\n303 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n304 |                 return True\n305 |             except RuntimeError as e:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:312:1: W293 [*] Blank line contains whitespace\n    |\n310 |                 else:\n311 |                     raise e\n312 |         \n    | ^^^^^^^^ W293\n313 |         # Binary search for optimal batch size\n314 |         low, high = 1, min(self.max_batch_size, 64)  # Start with smaller range\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:316:1: W293 [*] Blank line contains whitespace\n    |\n314 |         low, high = 1, min(self.max_batch_size, 64)  # Start with smaller range\n315 |         optimal_size = self.initial_batch_size\n316 |         \n    | ^^^^^^^^ W293\n317 |         while low <= high:\n318 |             mid = (low + high) // 2\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:319:1: W293 [*] Blank line contains whitespace\n    |\n317 |         while low <= high:\n318 |             mid = (low + high) // 2\n319 |             \n    | ^^^^^^^^^^^^ W293\n320 |             if test_batch_size(mid):\n321 |                 optimal_size = mid\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:325:1: W293 [*] Blank line contains whitespace\n    |\n323 |             else:\n324 |                 high = mid - 1\n325 |         \n    | ^^^^^^^^ W293\n326 |         self.current_batch_size = optimal_size\n327 |         self.logger.info(f\"Optimal batch size found: {optimal_size}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:329:1: W293 [*] Blank line contains whitespace\n    |\n327 |         self.logger.info(f\"Optimal batch size found: {optimal_size}\")\n328 |         return optimal_size\n329 |     \n    | ^^^^ W293\n330 |     def adapt_batch_size(self, oom_occurred: bool):\n331 |         \"\"\"Adapt batch size based on OOM events.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:347:1: W293 [*] Blank line contains whitespace\n    |\n345 | class GraphCompiler:\n346 |     \"\"\"Compile and optimize DGDN models for faster execution.\"\"\"\n347 |     \n    | ^^^^ W293\n348 |     def __init__(self):\n349 |         self.logger = get_logger(\"dgdn.compiler\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:351:1: W293 [*] Blank line contains whitespace\n    |\n349 |         self.logger = get_logger(\"dgdn.compiler\")\n350 |         self._compiled_models = {}\n351 |     \n    | ^^^^ W293\n352 |     def compile_model(self, model, sample_input, optimization_level=\"default\"):\n353 |         \"\"\"Compile model for optimized execution.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:355:1: W293 [*] Blank line contains whitespace\n    |\n353 |         \"\"\"Compile model for optimized execution.\"\"\"\n354 |         model_id = id(model)\n355 |         \n    | ^^^^^^^^ W293\n356 |         if model_id in self._compiled_models:\n357 |             self.logger.info(\"Using cached compiled model\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:359:1: W293 [*] Blank line contains whitespace\n    |\n357 |             self.logger.info(\"Using cached compiled model\")\n358 |             return self._compiled_models[model_id]\n359 |         \n    | ^^^^^^^^ W293\n360 |         try:\n361 |             # Use torch.jit.script or torch.compile if available\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:374:1: W293 [*] Blank line contains whitespace\n    |\n372 |                 compiled_model = model\n373 |                 self.logger.info(\"No compilation applied\")\n374 |             \n    | ^^^^^^^^^^^^ W293\n375 |             self._compiled_models[model_id] = compiled_model\n376 |             return compiled_model\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:377:1: W293 [*] Blank line contains whitespace\n    |\n375 |             self._compiled_models[model_id] = compiled_model\n376 |             return compiled_model\n377 |             \n    | ^^^^^^^^^^^^ W293\n378 |         except Exception as e:\n379 |             self.logger.warning(f\"Model compilation failed: {e}, using original model\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:381:1: W293 [*] Blank line contains whitespace\n    |\n379 |             self.logger.warning(f\"Model compilation failed: {e}, using original model\")\n380 |             return model\n381 |     \n    | ^^^^ W293\n382 |     def optimize_for_inference(self, model):\n383 |         \"\"\"Optimize model specifically for inference.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:386:1: W293 [*] Blank line contains whitespace\n    |\n384 |         # Set to evaluation mode\n385 |         model.eval()\n386 |         \n    | ^^^^^^^^ W293\n387 |         # Fuse operations if possible\n388 |         try:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:391:21: B007 Loop control variable `name` not used within loop body\n    |\n389 |             if hasattr(torch.quantization, 'fuse_modules'):\n390 |                 # Attempt to fuse common patterns\n391 |                 for name, module in model.named_modules():\n    |                     ^^^^ B007\n392 |                     if isinstance(module, nn.Sequential):\n393 |                         # Look for fuseable patterns\n    |\n    = help: Rename unused `name` to `_name`\n\nsrc/dgdn/optimization/computation.py:400:1: W293 [*] Blank line contains whitespace\n    |\n398 |         except Exception as e:\n399 |             self.logger.warning(f\"Operation fusion failed: {e}\")\n400 |         \n    | ^^^^^^^^ W293\n401 |         return model\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:407:1: W293 [*] Blank line contains whitespace\n    |\n405 | class OptimizedOperations:\n406 |     \"\"\"Collection of optimized operations for DGDN.\"\"\"\n407 |     \n    | ^^^^ W293\n408 |     def __init__(self):\n409 |         self.computation_optimizer = ComputationOptimizer()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:415:1: W293 [*] Blank line contains whitespace\n    |\n413 |         self.compiler = GraphCompiler()\n414 |         self.parallel_processor = ParallelProcessor()\n415 |     \n    | ^^^^ W293\n416 |     def optimize_model(self, model, sample_data):\n417 |         \"\"\"Apply all optimizations to a model.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:420:1: W293 [*] Blank line contains whitespace\n    |\n418 |         # Compile model\n419 |         optimized_model = self.compiler.compile_model(model, sample_data)\n420 |         \n    | ^^^^^^^^ W293\n421 |         # Enable memory optimizations\n422 |         self.memory_optimizer.optimize_memory_usage(optimized_model, sample_data)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:423:1: W293 [*] Blank line contains whitespace\n    |\n421 |         # Enable memory optimizations\n422 |         self.memory_optimizer.optimize_memory_usage(optimized_model, sample_data)\n423 |         \n    | ^^^^^^^^ W293\n424 |         # Find optimal batch size\n425 |         optimal_batch_size = self.batch_sizer.get_optimal_batch_size(optimized_model, sample_data)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:426:1: W293 [*] Blank line contains whitespace\n    |\n424 |         # Find optimal batch size\n425 |         optimal_batch_size = self.batch_sizer.get_optimal_batch_size(optimized_model, sample_data)\n426 |         \n    | ^^^^^^^^ W293\n427 |         return optimized_model, optimal_batch_size\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:428:1: W293 [*] Blank line contains whitespace\n    |\n427 |         return optimized_model, optimal_batch_size\n428 |     \n    | ^^^^ W293\n429 |     def cleanup(self):\n430 |         \"\"\"Clean up resources.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/computation.py:431:42: W292 [*] No newline at end of file\n    |\n429 |     def cleanup(self):\n430 |         \"\"\"Clean up resources.\"\"\"\n431 |         self.parallel_processor.cleanup()\n    |                                          ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/optimization/memory.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n  |\n1 |   \"\"\"Memory optimization techniques for DGDN.\"\"\"\n2 |\n3 | / import torch\n4 | | import torch.nn as nn\n5 | | from torch.utils.checkpoint import checkpoint\n6 | | from typing import Dict, Any, Optional, Tuple, Callable\n7 | | import gc\n8 | | import psutil\n9 | | import logging\n  | |______________^ I001\n  |\n  = help: Organize imports\n\nsrc/dgdn/optimization/memory.py:6:41: F401 [*] `typing.Tuple` imported but unused\n  |\n4 | import torch.nn as nn\n5 | from torch.utils.checkpoint import checkpoint\n6 | from typing import Dict, Any, Optional, Tuple, Callable\n  |                                         ^^^^^ F401\n7 | import gc\n8 | import psutil\n  |\n  = help: Remove unused import: `typing.Tuple`\n\nsrc/dgdn/optimization/memory.py:14:1: W293 [*] Blank line contains whitespace\n   |\n12 | class MemoryOptimizer:\n13 |     \"\"\"Memory usage optimization for DGDN training.\"\"\"\n14 |     \n   | ^^^^ W293\n15 |     def __init__(self, threshold_gb: float = 0.8):\n16 |         \"\"\"Initialize memory optimizer.\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:17:1: W293 Blank line contains whitespace\n   |\n15 |     def __init__(self, threshold_gb: float = 0.8):\n16 |         \"\"\"Initialize memory optimizer.\n17 |         \n   | ^^^^^^^^ W293\n18 |         Args:\n19 |             threshold_gb: Memory usage threshold as fraction of available RAM\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:23:1: W293 [*] Blank line contains whitespace\n   |\n21 |         self.threshold_gb = threshold_gb\n22 |         self.logger = logging.getLogger(__name__)\n23 |         \n   | ^^^^^^^^ W293\n24 |     def optimize_batch_size(self, initial_batch_size: int, model: nn.Module, \n25 |                            sample_data, device: torch.device) -> int:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:24:77: W291 [*] Trailing whitespace\n   |\n22 |         self.logger = logging.getLogger(__name__)\n23 |         \n24 |     def optimize_batch_size(self, initial_batch_size: int, model: nn.Module, \n   |                                                                             ^ W291\n25 |                            sample_data, device: torch.device) -> int:\n26 |         \"\"\"Dynamically optimize batch size based on memory usage.\"\"\"\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/optimization/memory.py:29:1: W293 [*] Blank line contains whitespace\n   |\n27 |         if not torch.cuda.is_available():\n28 |             return initial_batch_size\n29 |             \n   | ^^^^^^^^^^^^ W293\n30 |         batch_size = initial_batch_size\n31 |         max_batch_size = initial_batch_size * 4\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:30:9: F841 Local variable `batch_size` is assigned to but never used\n   |\n28 |             return initial_batch_size\n29 |             \n30 |         batch_size = initial_batch_size\n   |         ^^^^^^^^^^ F841\n31 |         max_batch_size = initial_batch_size * 4\n   |\n   = help: Remove assignment to unused variable `batch_size`\n\nsrc/dgdn/optimization/memory.py:32:1: W293 [*] Blank line contains whitespace\n   |\n30 |         batch_size = initial_batch_size\n31 |         max_batch_size = initial_batch_size * 4\n32 |         \n   | ^^^^^^^^ W293\n33 |         # Binary search for optimal batch size\n34 |         low, high = 1, max_batch_size\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:36:1: W293 [*] Blank line contains whitespace\n   |\n34 |         low, high = 1, max_batch_size\n35 |         optimal_batch_size = initial_batch_size\n36 |         \n   | ^^^^^^^^ W293\n37 |         while low <= high:\n38 |             mid_batch_size = (low + high) // 2\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:39:1: W293 [*] Blank line contains whitespace\n   |\n37 |         while low <= high:\n38 |             mid_batch_size = (low + high) // 2\n39 |             \n   | ^^^^^^^^^^^^ W293\n40 |             try:\n41 |                 # Test memory usage with this batch size\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:47:1: W293 [*] Blank line contains whitespace\n   |\n45 |                 else:\n46 |                     high = mid_batch_size - 1\n47 |                     \n   | ^^^^^^^^^^^^^^^^^^^^ W293\n48 |             except RuntimeError as e:\n49 |                 if \"out of memory\" in str(e):\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:54:1: W293 [*] Blank line contains whitespace\n   |\n52 |                 else:\n53 |                     raise e\n54 |         \n   | ^^^^^^^^ W293\n55 |         self.logger.info(f\"Optimized batch size: {initial_batch_size} -> {optimal_batch_size}\")\n56 |         return optimal_batch_size\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:57:1: W293 [*] Blank line contains whitespace\n   |\n55 |         self.logger.info(f\"Optimized batch size: {initial_batch_size} -> {optimal_batch_size}\")\n56 |         return optimal_batch_size\n57 |     \n   | ^^^^ W293\n58 |     def _test_memory_usage(self, batch_size: int, model: nn.Module, \n59 |                           sample_data, device: torch.device) -> bool:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:58:68: W291 [*] Trailing whitespace\n   |\n56 |         return optimal_batch_size\n57 |     \n58 |     def _test_memory_usage(self, batch_size: int, model: nn.Module, \n   |                                                                    ^ W291\n59 |                           sample_data, device: torch.device) -> bool:\n60 |         \"\"\"Test if batch size fits in memory.\"\"\"\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/optimization/memory.py:62:1: W293 [*] Blank line contains whitespace\n   |\n60 |         \"\"\"Test if batch size fits in memory.\"\"\"\n61 |         model.train()\n62 |         \n   | ^^^^^^^^ W293\n63 |         # Create larger batch\n64 |         test_data = self._expand_batch(sample_data, batch_size)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:66:1: W293 [*] Blank line contains whitespace\n   |\n64 |         test_data = self._expand_batch(sample_data, batch_size)\n65 |         test_data = test_data.to(device)\n66 |         \n   | ^^^^^^^^ W293\n67 |         try:\n68 |             with torch.no_grad():\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:69:17: F841 Local variable `output` is assigned to but never used\n   |\n67 |         try:\n68 |             with torch.no_grad():\n69 |                 output = model(test_data)\n   |                 ^^^^^^ F841\n70 |                 \n71 |                 # Check GPU memory usage\n   |\n   = help: Remove assignment to unused variable `output`\n\nsrc/dgdn/optimization/memory.py:70:1: W293 [*] Blank line contains whitespace\n   |\n68 |             with torch.no_grad():\n69 |                 output = model(test_data)\n70 |                 \n   | ^^^^^^^^^^^^^^^^ W293\n71 |                 # Check GPU memory usage\n72 |                 if torch.cuda.is_available():\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:76:1: W293 [*] Blank line contains whitespace\n   |\n74 |                     memory_cached = torch.cuda.memory_reserved(device)\n75 |                     total_memory = torch.cuda.get_device_properties(device).total_memory\n76 |                     \n   | ^^^^^^^^^^^^^^^^^^^^ W293\n77 |                     usage_fraction = (memory_allocated + memory_cached) / total_memory\n78 |                     return usage_fraction < self.threshold_gb\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:81:1: W293 [*] Blank line contains whitespace\n   |\n79 |                 else:\n80 |                     return True\n81 |                     \n   | ^^^^^^^^^^^^^^^^^^^^ W293\n82 |         except RuntimeError as e:\n83 |             if \"out of memory\" in str(e):\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:90:1: W293 [*] Blank line contains whitespace\n   |\n88 |             if torch.cuda.is_available():\n89 |                 torch.cuda.empty_cache()\n90 |     \n   | ^^^^ W293\n91 |     def _expand_batch(self, sample_data, target_batch_size: int):\n92 |         \"\"\"Expand sample data to target batch size.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:96:1: W293 [*] Blank line contains whitespace\n   |\n94 |         if current_edges == 0:\n95 |             return sample_data\n96 |             \n   | ^^^^^^^^^^^^ W293\n97 |         # Calculate repetition factor\n98 |         repeat_factor = max(1, target_batch_size // current_edges)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:99:1: W293 [*] Blank line contains whitespace\n    |\n 97 |         # Calculate repetition factor\n 98 |         repeat_factor = max(1, target_batch_size // current_edges)\n 99 |         \n    | ^^^^^^^^ W293\n100 |         # Repeat edge data\n101 |         edge_index = sample_data.edge_index.repeat(1, repeat_factor)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:103:1: W293 [*] Blank line contains whitespace\n    |\n101 |         edge_index = sample_data.edge_index.repeat(1, repeat_factor)\n102 |         timestamps = sample_data.timestamps.repeat(repeat_factor)\n103 |         \n    | ^^^^^^^^ W293\n104 |         # Create new data object\n105 |         expanded_data = type(sample_data)(\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:110:1: W293 [*] Blank line contains whitespace\n    |\n108 |             num_nodes=sample_data.num_nodes\n109 |         )\n110 |         \n    | ^^^^^^^^ W293\n111 |         if hasattr(sample_data, 'edge_attr') and sample_data.edge_attr is not None:\n112 |             expanded_data.edge_attr = sample_data.edge_attr.repeat(repeat_factor, 1)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:115:1: W293 [*] Blank line contains whitespace\n    |\n113 |         if hasattr(sample_data, 'node_features') and sample_data.node_features is not None:\n114 |             expanded_data.node_features = sample_data.node_features\n115 |             \n    | ^^^^^^^^^^^^ W293\n116 |         return expanded_data\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:117:1: W293 [*] Blank line contains whitespace\n    |\n116 |         return expanded_data\n117 |     \n    | ^^^^ W293\n118 |     def monitor_memory_usage(self) -> Dict[str, float]:\n119 |         \"\"\"Monitor current memory usage.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:121:1: W293 [*] Blank line contains whitespace\n    |\n119 |         \"\"\"Monitor current memory usage.\"\"\"\n120 |         memory_info = {}\n121 |         \n    | ^^^^^^^^ W293\n122 |         # System memory\n123 |         process = psutil.Process()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:126:1: W293 [*] Blank line contains whitespace\n    |\n124 |         memory_info['ram_used_gb'] = process.memory_info().rss / 1e9\n125 |         memory_info['ram_percent'] = psutil.virtual_memory().percent\n126 |         \n    | ^^^^^^^^ W293\n127 |         # GPU memory\n128 |         if torch.cuda.is_available():\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:134:1: W293 [*] Blank line contains whitespace\n    |\n132 |                 cached = torch.cuda.memory_reserved(device) / 1e9\n133 |                 total = torch.cuda.get_device_properties(device).total_memory / 1e9\n134 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n135 |                 memory_info[f'gpu_{i}_allocated_gb'] = allocated\n136 |                 memory_info[f'gpu_{i}_cached_gb'] = cached\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:139:1: W293 [*] Blank line contains whitespace\n    |\n137 |                 memory_info[f'gpu_{i}_total_gb'] = total\n138 |                 memory_info[f'gpu_{i}_usage_percent'] = (allocated + cached) / total * 100\n139 |         \n    | ^^^^^^^^ W293\n140 |         return memory_info\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:141:1: W293 [*] Blank line contains whitespace\n    |\n140 |         return memory_info\n141 |     \n    | ^^^^ W293\n142 |     def cleanup_memory(self):\n143 |         \"\"\"Aggressive memory cleanup.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:152:1: W293 [*] Blank line contains whitespace\n    |\n150 | class GradientCheckpointing:\n151 |     \"\"\"Gradient checkpointing to reduce memory usage.\"\"\"\n152 |     \n    | ^^^^ W293\n153 |     def __init__(self, model: nn.Module, checkpoint_every: int = 1):\n154 |         \"\"\"Initialize gradient checkpointing.\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:155:1: W293 Blank line contains whitespace\n    |\n153 |     def __init__(self, model: nn.Module, checkpoint_every: int = 1):\n154 |         \"\"\"Initialize gradient checkpointing.\n155 |         \n    | ^^^^^^^^ W293\n156 |         Args:\n157 |             model: Model to apply checkpointing to\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:163:1: W293 [*] Blank line contains whitespace\n    |\n161 |         self.checkpoint_every = checkpoint_every\n162 |         self.logger = logging.getLogger(__name__)\n163 |         \n    | ^^^^^^^^ W293\n164 |     def enable_checkpointing(self):\n165 |         \"\"\"Enable gradient checkpointing for DGDN layers.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:170:1: W293 [*] Blank line contains whitespace\n    |\n168 |                 if i % self.checkpoint_every == 0:\n169 |                     layer.forward = self._checkpoint_wrapper(layer.forward)\n170 |             \n    | ^^^^^^^^^^^^ W293\n171 |             self.logger.info(f\"Enabled gradient checkpointing for {len(self.model.dgdn_layers)} layers\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:172:1: W293 [*] Blank line contains whitespace\n    |\n171 |             self.logger.info(f\"Enabled gradient checkpointing for {len(self.model.dgdn_layers)} layers\")\n172 |     \n    | ^^^^ W293\n173 |     def _checkpoint_wrapper(self, forward_fn: Callable) -> Callable:\n174 |         \"\"\"Wrap forward function with gradient checkpointing.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:181:1: W293 [*] Blank line contains whitespace\n    |\n179 |             else:\n180 |                 return forward_fn(*args, **kwargs)\n181 |         \n    | ^^^^^^^^ W293\n182 |         return checkpointed_forward\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:183:1: W293 [*] Blank line contains whitespace\n    |\n182 |         return checkpointed_forward\n183 |     \n    | ^^^^ W293\n184 |     def estimate_memory_savings(self, model_size_mb: float) -> Dict[str, float]:\n185 |         \"\"\"Estimate memory savings from checkpointing.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:188:1: W293 [*] Blank line contains whitespace\n    |\n186 |         # Rough estimates based on typical savings\n187 |         base_memory = model_size_mb\n188 |         \n    | ^^^^^^^^ W293\n189 |         # Gradient checkpointing typically saves 50-80% of activation memory\n190 |         activation_memory = base_memory * 2.0  # Typical ratio\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:192:1: W293 [*] Blank line contains whitespace\n    |\n190 |         activation_memory = base_memory * 2.0  # Typical ratio\n191 |         savings = activation_memory * 0.65  # Average savings\n192 |         \n    | ^^^^^^^^ W293\n193 |         return {\n194 |             'base_model_mb': base_memory,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:203:1: W293 [*] Blank line contains whitespace\n    |\n201 | class DataParallelOptimizer:\n202 |     \"\"\"Optimize data parallel training.\"\"\"\n203 |     \n    | ^^^^ W293\n204 |     def __init__(self, model: nn.Module):\n205 |         self.model = model\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:207:1: W293 [*] Blank line contains whitespace\n    |\n205 |         self.model = model\n206 |         self.logger = logging.getLogger(__name__)\n207 |     \n    | ^^^^ W293\n208 |     def setup_data_parallel(self, device_ids: Optional[list] = None) -> nn.Module:\n209 |         \"\"\"Setup data parallel training.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:213:1: W293 [*] Blank line contains whitespace\n    |\n211 |             self.logger.warning(\"CUDA not available, skipping data parallel setup\")\n212 |             return self.model\n213 |         \n    | ^^^^^^^^ W293\n214 |         if device_ids is None:\n215 |             device_ids = list(range(torch.cuda.device_count()))\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:216:1: W293 [*] Blank line contains whitespace\n    |\n214 |         if device_ids is None:\n215 |             device_ids = list(range(torch.cuda.device_count()))\n216 |         \n    | ^^^^^^^^ W293\n217 |         if len(device_ids) > 1:\n218 |             self.model = nn.DataParallel(self.model, device_ids=device_ids)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:220:1: W293 [*] Blank line contains whitespace\n    |\n218 |             self.model = nn.DataParallel(self.model, device_ids=device_ids)\n219 |             self.logger.info(f\"Setup data parallel training on devices: {device_ids}\")\n220 |         \n    | ^^^^^^^^ W293\n221 |         return self.model\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:222:1: W293 [*] Blank line contains whitespace\n    |\n221 |         return self.model\n222 |     \n    | ^^^^ W293\n223 |     def optimize_for_multi_gpu(self) -> Dict[str, Any]:\n224 |         \"\"\"Optimize model for multi-GPU training.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:226:1: W293 [*] Blank line contains whitespace\n    |\n224 |         \"\"\"Optimize model for multi-GPU training.\"\"\"\n225 |         recommendations = {}\n226 |         \n    | ^^^^^^^^ W293\n227 |         if torch.cuda.device_count() > 1:\n228 |             recommendations['use_data_parallel'] = True\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:238:1: W293 [*] Blank line contains whitespace\n    |\n236 |                 'Optimize batch size for memory'\n237 |             ]\n238 |         \n    | ^^^^^^^^ W293\n239 |         return recommendations\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:240:1: W293 [*] Blank line contains whitespace\n    |\n239 |         return recommendations\n240 |     \n    | ^^^^ W293\n241 |     def _calculate_optimal_batch_size(self) -> int:\n242 |         \"\"\"Calculate optimal batch size for multi-GPU setup.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:245:1: W293 [*] Blank line contains whitespace\n    |\n243 |         num_gpus = torch.cuda.device_count()\n244 |         base_batch_size = 32  # Conservative base\n245 |         \n    | ^^^^^^^^ W293\n246 |         # Scale batch size with number of GPUs\n247 |         return base_batch_size * num_gpus\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:248:1: W293 [*] Blank line contains whitespace\n    |\n246 |         # Scale batch size with number of GPUs\n247 |         return base_batch_size * num_gpus\n248 |     \n    | ^^^^ W293\n249 |     def _calculate_gradient_accumulation(self) -> int:\n250 |         \"\"\"Calculate gradient accumulation steps.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:252:1: W293 [*] Blank line contains whitespace\n    |\n250 |         \"\"\"Calculate gradient accumulation steps.\"\"\"\n251 |         num_gpus = torch.cuda.device_count()\n252 |         \n    | ^^^^^^^^ W293\n253 |         # Use gradient accumulation to simulate larger batches\n254 |         if num_gpus >= 4:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/optimization/memory.py:256:17: W292 [*] No newline at end of file\n    |\n254 |         if num_gpus >= 4:\n255 |             return 2  # Accumulate gradients over 2 steps\n256 |         return 1\n    |                 ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/temporal/__init__.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n  |\n1 |   \"\"\"Temporal processing modules for DGDN.\"\"\"\n2 |\n3 | / from .encoding import EdgeTimeEncoder\n4 | | from .diffusion import VariationalDiffusion\n  | |___________________________________________^ I001\n5 |\n6 |   __all__ = [\"EdgeTimeEncoder\", \"VariationalDiffusion\"]\n  |\n  = help: Organize imports\n\nsrc/dgdn/temporal/__init__.py:6:54: W292 [*] No newline at end of file\n  |\n4 | from .diffusion import VariationalDiffusion\n5 |\n6 | __all__ = [\"EdgeTimeEncoder\", \"VariationalDiffusion\"]\n  |                                                      ^ W292\n  |\n  = help: Add trailing newline\n\nsrc/dgdn/temporal/diffusion.py:7:1: I001 [*] Import block is un-sorted or un-formatted\n   |\n 5 |   \"\"\"\n 6 |\n 7 | / import math\n 8 | | import torch\n 9 | | import torch.nn as nn\n10 | | import torch.nn.functional as F\n11 | | from typing import Tuple, Optional, Dict, Any\n12 | | from torch_geometric.nn import MessagePassing\n13 | | from torch_geometric.utils import add_self_loops, degree\n   | |________________________________________________________^ I001\n   |\n   = help: Organize imports\n\nsrc/dgdn/temporal/diffusion.py:11:20: F401 [*] `typing.Tuple` imported but unused\n   |\n 9 | import torch.nn as nn\n10 | import torch.nn.functional as F\n11 | from typing import Tuple, Optional, Dict, Any\n   |                    ^^^^^ F401\n12 | from torch_geometric.nn import MessagePassing\n13 | from torch_geometric.utils import add_self_loops, degree\n   |\n   = help: Remove unused import\n\nsrc/dgdn/temporal/diffusion.py:11:43: F401 [*] `typing.Any` imported but unused\n   |\n 9 | import torch.nn as nn\n10 | import torch.nn.functional as F\n11 | from typing import Tuple, Optional, Dict, Any\n   |                                           ^^^ F401\n12 | from torch_geometric.nn import MessagePassing\n13 | from torch_geometric.utils import add_self_loops, degree\n   |\n   = help: Remove unused import\n\nsrc/dgdn/temporal/diffusion.py:13:35: F401 [*] `torch_geometric.utils.add_self_loops` imported but unused\n   |\n11 | from typing import Tuple, Optional, Dict, Any\n12 | from torch_geometric.nn import MessagePassing\n13 | from torch_geometric.utils import add_self_loops, degree\n   |                                   ^^^^^^^^^^^^^^ F401\n   |\n   = help: Remove unused import\n\nsrc/dgdn/temporal/diffusion.py:13:51: F401 [*] `torch_geometric.utils.degree` imported but unused\n   |\n11 | from typing import Tuple, Optional, Dict, Any\n12 | from torch_geometric.nn import MessagePassing\n13 | from torch_geometric.utils import add_self_loops, degree\n   |                                                   ^^^^^^ F401\n   |\n   = help: Remove unused import\n\nsrc/dgdn/temporal/diffusion.py:18:1: W293 Blank line contains whitespace\n   |\n16 | class VariationalDiffusion(nn.Module):\n17 |     \"\"\"Variational Diffusion Sampler for probabilistic node embeddings.\n18 |     \n   | ^^^^ W293\n19 |     Implements multi-step diffusion process with variational inference framework\n20 |     for uncertainty quantification in dynamic graph learning.\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:21:1: W293 Blank line contains whitespace\n   |\n19 |     Implements multi-step diffusion process with variational inference framework\n20 |     for uncertainty quantification in dynamic graph learning.\n21 |     \n   | ^^^^ W293\n22 |     Args:\n23 |         hidden_dim: Dimension of node embeddings\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:25:58: W291 Trailing whitespace\n   |\n23 |         hidden_dim: Dimension of node embeddings\n24 |         num_diffusion_steps: Number of diffusion steps (default: 5)\n25 |         num_heads: Number of attention heads (default: 8) \n   |                                                          ^ W291\n26 |         dropout: Dropout probability (default: 0.1)\n27 |         activation: Activation function (default: \"relu\")\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/temporal/diffusion.py:30:1: W293 [*] Blank line contains whitespace\n   |\n28 |         noise_schedule: Type of noise schedule (\"linear\", \"cosine\") (default: \"linear\")\n29 |     \"\"\"\n30 |     \n   | ^^^^ W293\n31 |     def __init__(\n32 |         self,\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:45:1: W293 [*] Blank line contains whitespace\n   |\n43 |         self.num_heads = num_heads\n44 |         self.dropout = dropout\n45 |         \n   | ^^^^^^^^ W293\n46 |         # Create diffusion layers\n47 |         self.diffusion_layers = nn.ModuleList([\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:51:1: W293 [*] Blank line contains whitespace\n   |\n49 |             for _ in range(num_diffusion_steps)\n50 |         ])\n51 |         \n   | ^^^^^^^^ W293\n52 |         # Noise schedule parameters\n53 |         self.noise_schedule = noise_schedule\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:57:1: W293 [*] Blank line contains whitespace\n   |\n55 |         self.register_buffer(\"alphas\", 1.0 - self.betas)\n56 |         self.register_buffer(\"alpha_cumprod\", torch.cumprod(self.alphas, dim=0))\n57 |         \n   | ^^^^^^^^ W293\n58 |         # Prior distribution parameters (standard normal)\n59 |         self.register_buffer(\"prior_mean\", torch.zeros(hidden_dim))\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:61:1: W293 [*] Blank line contains whitespace\n   |\n59 |         self.register_buffer(\"prior_mean\", torch.zeros(hidden_dim))\n60 |         self.register_buffer(\"prior_logvar\", torch.zeros(hidden_dim))\n61 |     \n   | ^^^^ W293\n62 |     def _get_noise_schedule(self, num_steps: int) -> torch.Tensor:\n63 |         \"\"\"Generate noise schedule for diffusion process.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:76:1: W293 [*] Blank line contains whitespace\n   |\n74 |         else:\n75 |             raise ValueError(f\"Unknown noise schedule: {self.noise_schedule}\")\n76 |     \n   | ^^^^ W293\n77 |     def forward(\n78 |         self,\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:85:1: W293 Blank line contains whitespace\n   |\n83 |     ) -> Dict[str, torch.Tensor]:\n84 |         \"\"\"Forward diffusion process.\n85 |         \n   | ^^^^^^^^ W293\n86 |         Args:\n87 |             x: Node features [num_nodes, hidden_dim]\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:91:1: W293 Blank line contains whitespace\n   |\n89 |             edge_attr: Edge attributes [num_edges, edge_dim] (optional)\n90 |             return_all_steps: Whether to return intermediate diffusion steps\n91 |             \n   | ^^^^^^^^^^^^ W293\n92 |         Returns:\n93 |             Dictionary containing:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:100:9: F841 Local variable `batch_size` is assigned to but never used\n    |\n 98 |             - all_steps: All intermediate steps (if return_all_steps=True)\n 99 |         \"\"\"\n100 |         batch_size, num_nodes = x.shape[0], x.shape[1] if x.dim() == 3 else x.shape[0]\n    |         ^^^^^^^^^^ F841\n101 |         \n102 |         # Initialize with input features\n    |\n    = help: Remove assignment to unused variable `batch_size`\n\nsrc/dgdn/temporal/diffusion.py:100:21: F841 Local variable `num_nodes` is assigned to but never used\n    |\n 98 |             - all_steps: All intermediate steps (if return_all_steps=True)\n 99 |         \"\"\"\n100 |         batch_size, num_nodes = x.shape[0], x.shape[1] if x.dim() == 3 else x.shape[0]\n    |                     ^^^^^^^^^ F841\n101 |         \n102 |         # Initialize with input features\n    |\n    = help: Remove assignment to unused variable `num_nodes`\n\nsrc/dgdn/temporal/diffusion.py:101:1: W293 [*] Blank line contains whitespace\n    |\n 99 |         \"\"\"\n100 |         batch_size, num_nodes = x.shape[0], x.shape[1] if x.dim() == 3 else x.shape[0]\n101 |         \n    | ^^^^^^^^ W293\n102 |         # Initialize with input features\n103 |         current_mean = x\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:105:1: W293 [*] Blank line contains whitespace\n    |\n103 |         current_mean = x\n104 |         current_logvar = torch.zeros_like(x)\n105 |         \n    | ^^^^^^^^ W293\n106 |         all_steps = [] if return_all_steps else None\n107 |         total_kl_loss = 0.0\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:108:1: W293 [*] Blank line contains whitespace\n    |\n106 |         all_steps = [] if return_all_steps else None\n107 |         total_kl_loss = 0.0\n108 |         \n    | ^^^^^^^^ W293\n109 |         # Forward diffusion process\n110 |         for step, layer in enumerate(self.diffusion_layers):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:113:30: W291 [*] Trailing whitespace\n    |\n111 |             # Apply diffusion layer\n112 |             step_output = layer(\n113 |                 current_mean, \n    |                              ^ W291\n114 |                 current_logvar,\n115 |                 edge_index, \n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/temporal/diffusion.py:115:28: W291 [*] Trailing whitespace\n    |\n113 |                 current_mean, \n114 |                 current_logvar,\n115 |                 edge_index, \n    |                            ^ W291\n116 |                 edge_attr,\n117 |                 step\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/temporal/diffusion.py:119:1: W293 [*] Blank line contains whitespace\n    |\n117 |                 step\n118 |             )\n119 |             \n    | ^^^^^^^^^^^^ W293\n120 |             current_mean = step_output[\"mean\"]\n121 |             current_logvar = step_output[\"logvar\"]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:124:1: W293 [*] Blank line contains whitespace\n    |\n122 |             z_step = step_output[\"z\"]\n123 |             kl_step = step_output[\"kl_loss\"]\n124 |             \n    | ^^^^^^^^^^^^ W293\n125 |             total_kl_loss += kl_step\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:126:1: W293 [*] Blank line contains whitespace\n    |\n125 |             total_kl_loss += kl_step\n126 |             \n    | ^^^^^^^^^^^^ W293\n127 |             if return_all_steps:\n128 |                 all_steps.append({\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:135:1: W293 [*] Blank line contains whitespace\n    |\n133 |                     \"kl_loss\": kl_step\n134 |                 })\n135 |         \n    | ^^^^^^^^ W293\n136 |         # Sample from final distribution\n137 |         if self.training:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:143:1: W293 [*] Blank line contains whitespace\n    |\n141 |         else:\n142 |             final_z = current_mean\n143 |         \n    | ^^^^^^^^ W293\n144 |         result = {\n145 |             \"z\": final_z,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:150:1: W293 [*] Blank line contains whitespace\n    |\n148 |             \"kl_loss\": total_kl_loss,\n149 |         }\n150 |         \n    | ^^^^^^^^ W293\n151 |         if return_all_steps:\n152 |             result[\"all_steps\"] = all_steps\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:153:1: W293 [*] Blank line contains whitespace\n    |\n151 |         if return_all_steps:\n152 |             result[\"all_steps\"] = all_steps\n153 |             \n    | ^^^^^^^^^^^^ W293\n154 |         return result\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:155:1: W293 [*] Blank line contains whitespace\n    |\n154 |         return result\n155 |     \n    | ^^^^ W293\n156 |     def sample(\n157 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:164:1: W293 Blank line contains whitespace\n    |\n162 |     ) -> torch.Tensor:\n163 |         \"\"\"Sample from the learned distribution.\n164 |         \n    | ^^^^^^^^ W293\n165 |         Args:\n166 |             num_nodes: Number of nodes to sample\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:170:1: W293 Blank line contains whitespace\n    |\n168 |             edge_attr: Edge attributes (optional)\n169 |             device: Device to create tensors on\n170 |             \n    | ^^^^^^^^^^^^ W293\n171 |         Returns:\n172 |             Sampled node embeddings\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:176:1: W293 [*] Blank line contains whitespace\n    |\n174 |         if device is None:\n175 |             device = next(self.parameters()).device\n176 |         \n    | ^^^^^^^^ W293\n177 |         # Start from prior (standard normal)\n178 |         z = torch.randn(num_nodes, self.hidden_dim, device=device)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:179:1: W293 [*] Blank line contains whitespace\n    |\n177 |         # Start from prior (standard normal)\n178 |         z = torch.randn(num_nodes, self.hidden_dim, device=device)\n179 |         \n    | ^^^^^^^^ W293\n180 |         # Reverse diffusion process (denoising)\n181 |         with torch.no_grad():\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:186:1: W293 [*] Blank line contains whitespace\n    |\n184 |                 # In sampling, we reverse the process\n185 |                 z = layer.reverse_step(z, edge_index, edge_attr, step)\n186 |         \n    | ^^^^^^^^ W293\n187 |         return z\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:188:1: W293 [*] Blank line contains whitespace\n    |\n187 |         return z\n188 |     \n    | ^^^^ W293\n189 |     def get_uncertainty(self, logvar: torch.Tensor) -> torch.Tensor:\n190 |         \"\"\"Convert log variance to uncertainty measure.\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:191:1: W293 Blank line contains whitespace\n    |\n189 |     def get_uncertainty(self, logvar: torch.Tensor) -> torch.Tensor:\n190 |         \"\"\"Convert log variance to uncertainty measure.\n191 |         \n    | ^^^^^^^^ W293\n192 |         Args:\n193 |             logvar: Log variance tensor\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:194:1: W293 Blank line contains whitespace\n    |\n192 |         Args:\n193 |             logvar: Log variance tensor\n194 |             \n    | ^^^^^^^^^^^^ W293\n195 |         Returns:\n196 |             Uncertainty measure (standard deviation)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:199:1: W293 [*] Blank line contains whitespace\n    |\n197 |         \"\"\"\n198 |         return torch.exp(0.5 * logvar)\n199 |     \n    | ^^^^ W293\n200 |     def compute_mutual_information(\n201 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:210:1: W293 [*] Blank line contains whitespace\n    |\n208 |         entropy_conditional = 0.5 * (1 + z_logvar).sum(dim=-1)\n209 |         entropy_marginal = 0.5 * self.hidden_dim * (1 + math.log(2 * math.pi))\n210 |         \n    | ^^^^^^^^ W293\n211 |         mi = entropy_conditional - entropy_marginal\n212 |         return mi.mean()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:217:1: W293 [*] Blank line contains whitespace\n    |\n215 | class DiffusionLayer(MessagePassing):\n216 |     \"\"\"Single diffusion layer with attention-based message passing.\"\"\"\n217 |     \n    | ^^^^ W293\n218 |     def __init__(\n219 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:226:1: W293 [*] Blank line contains whitespace\n    |\n224 |     ):\n225 |         super().__init__(aggr='add', node_dim=-2)\n226 |         \n    | ^^^^^^^^ W293\n227 |         self.hidden_dim = hidden_dim\n228 |         self.num_heads = num_heads\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:231:1: W293 [*] Blank line contains whitespace\n    |\n229 |         self.head_dim = hidden_dim // num_heads\n230 |         self.dropout = dropout\n231 |         \n    | ^^^^^^^^ W293\n232 |         assert hidden_dim % num_heads == 0, \"hidden_dim must be divisible by num_heads\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:233:1: W293 [*] Blank line contains whitespace\n    |\n232 |         assert hidden_dim % num_heads == 0, \"hidden_dim must be divisible by num_heads\"\n233 |         \n    | ^^^^^^^^ W293\n234 |         # Multi-head attention components\n235 |         self.q_proj = nn.Linear(hidden_dim, hidden_dim)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:239:1: W293 [*] Blank line contains whitespace\n    |\n237 |         self.v_proj = nn.Linear(hidden_dim, hidden_dim)\n238 |         self.out_proj = nn.Linear(hidden_dim, hidden_dim)\n239 |         \n    | ^^^^^^^^ W293\n240 |         # Diffusion network for mean and variance\n241 |         self.diffusion_net = nn.Sequential(\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:249:1: W293 [*] Blank line contains whitespace\n    |\n247 |             nn.Linear(hidden_dim * 2, hidden_dim * 2)  # Output: [mean, logvar]\n248 |         )\n249 |         \n    | ^^^^^^^^ W293\n250 |         # Layer normalization\n251 |         self.layer_norm = nn.LayerNorm(hidden_dim)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:252:1: W293 [*] Blank line contains whitespace\n    |\n250 |         # Layer normalization\n251 |         self.layer_norm = nn.LayerNorm(hidden_dim)\n252 |         \n    | ^^^^^^^^ W293\n253 |         self.reset_parameters()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:254:1: W293 [*] Blank line contains whitespace\n    |\n253 |         self.reset_parameters()\n254 |     \n    | ^^^^ W293\n255 |     def _get_activation(self, activation: str) -> nn.Module:\n256 |         \"\"\"Get activation function by name.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:265:1: W293 [*] Blank line contains whitespace\n    |\n263 |         else:\n264 |             raise ValueError(f\"Unknown activation: {activation}\")\n265 |     \n    | ^^^^ W293\n266 |     def reset_parameters(self):\n267 |         \"\"\"Initialize parameters.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:271:1: W293 [*] Blank line contains whitespace\n    |\n269 |             nn.init.xavier_uniform_(module.weight)\n270 |             nn.init.zeros_(module.bias)\n271 |         \n    | ^^^^^^^^ W293\n272 |         # Initialize diffusion network\n273 |         for module in self.diffusion_net:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:277:1: W293 [*] Blank line contains whitespace\n    |\n275 |                 nn.init.xavier_uniform_(module.weight)\n276 |                 nn.init.zeros_(module.bias)\n277 |     \n    | ^^^^ W293\n278 |     def forward(\n279 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:287:1: W293 [*] Blank line contains whitespace\n    |\n285 |     ) -> Dict[str, torch.Tensor]:\n286 |         \"\"\"Forward pass of diffusion layer.\"\"\"\n287 |         \n    | ^^^^^^^^ W293\n288 |         # Sample from current distribution\n289 |         if self.training:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:295:1: W293 [*] Blank line contains whitespace\n    |\n293 |         else:\n294 |             x = x_mean\n295 |         \n    | ^^^^^^^^ W293\n296 |         # Message passing with attention\n297 |         messages = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:298:1: W293 [*] Blank line contains whitespace\n    |\n296 |         # Message passing with attention\n297 |         messages = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n298 |         \n    | ^^^^^^^^ W293\n299 |         # Combine with current embedding\n300 |         combined = torch.cat([x, messages], dim=-1)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:301:1: W293 [*] Blank line contains whitespace\n    |\n299 |         # Combine with current embedding\n300 |         combined = torch.cat([x, messages], dim=-1)\n301 |         \n    | ^^^^^^^^ W293\n302 |         # Apply diffusion network\n303 |         diffusion_params = self.diffusion_net(combined)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:305:1: W293 [*] Blank line contains whitespace\n    |\n303 |         diffusion_params = self.diffusion_net(combined)\n304 |         new_mean, new_logvar = diffusion_params.chunk(2, dim=-1)\n305 |         \n    | ^^^^^^^^ W293\n306 |         # Residual connection and layer norm\n307 |         new_mean = self.layer_norm(new_mean + x_mean)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:308:1: W293 [*] Blank line contains whitespace\n    |\n306 |         # Residual connection and layer norm\n307 |         new_mean = self.layer_norm(new_mean + x_mean)\n308 |         \n    | ^^^^^^^^ W293\n309 |         # Compute KL divergence with previous step\n310 |         kl_loss = self._compute_kl_loss(x_mean, x_logvar, new_mean, new_logvar)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:311:1: W293 [*] Blank line contains whitespace\n    |\n309 |         # Compute KL divergence with previous step\n310 |         kl_loss = self._compute_kl_loss(x_mean, x_logvar, new_mean, new_logvar)\n311 |         \n    | ^^^^^^^^ W293\n312 |         # Sample from new distribution\n313 |         if self.training:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:319:1: W293 [*] Blank line contains whitespace\n    |\n317 |         else:\n318 |             z = new_mean\n319 |         \n    | ^^^^^^^^ W293\n320 |         return {\n321 |             \"z\": z,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:326:1: W293 [*] Blank line contains whitespace\n    |\n324 |             \"kl_loss\": kl_loss\n325 |         }\n326 |     \n    | ^^^^ W293\n327 |     def message(self, x_j: torch.Tensor, edge_attr: Optional[torch.Tensor] = None) -> torch.Tensor:\n328 |         \"\"\"Compute messages using multi-head attention.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:329:9: F841 Local variable `batch_size` is assigned to but never used\n    |\n327 |     def message(self, x_j: torch.Tensor, edge_attr: Optional[torch.Tensor] = None) -> torch.Tensor:\n328 |         \"\"\"Compute messages using multi-head attention.\"\"\"\n329 |         batch_size, num_edges = x_j.shape[0], x_j.shape[1] if x_j.dim() == 3 else x_j.shape[0]\n    |         ^^^^^^^^^^ F841\n330 |         \n331 |         # Project to query, key, value\n    |\n    = help: Remove assignment to unused variable `batch_size`\n\nsrc/dgdn/temporal/diffusion.py:329:21: F841 Local variable `num_edges` is assigned to but never used\n    |\n327 |     def message(self, x_j: torch.Tensor, edge_attr: Optional[torch.Tensor] = None) -> torch.Tensor:\n328 |         \"\"\"Compute messages using multi-head attention.\"\"\"\n329 |         batch_size, num_edges = x_j.shape[0], x_j.shape[1] if x_j.dim() == 3 else x_j.shape[0]\n    |                     ^^^^^^^^^ F841\n330 |         \n331 |         # Project to query, key, value\n    |\n    = help: Remove assignment to unused variable `num_edges`\n\nsrc/dgdn/temporal/diffusion.py:330:1: W293 [*] Blank line contains whitespace\n    |\n328 |         \"\"\"Compute messages using multi-head attention.\"\"\"\n329 |         batch_size, num_edges = x_j.shape[0], x_j.shape[1] if x_j.dim() == 3 else x_j.shape[0]\n330 |         \n    | ^^^^^^^^ W293\n331 |         # Project to query, key, value\n332 |         q = self.q_proj(x_j)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:335:1: W293 [*] Blank line contains whitespace\n    |\n333 |         k = self.k_proj(x_j)\n334 |         v = self.v_proj(x_j)\n335 |         \n    | ^^^^^^^^ W293\n336 |         # Reshape for multi-head attention\n337 |         q = q.view(-1, self.num_heads, self.head_dim)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:340:1: W293 [*] Blank line contains whitespace\n    |\n338 |         k = k.view(-1, self.num_heads, self.head_dim)\n339 |         v = v.view(-1, self.num_heads, self.head_dim)\n340 |         \n    | ^^^^^^^^ W293\n341 |         # Compute attention scores\n342 |         attn_scores = torch.sum(q * k, dim=-1) / math.sqrt(self.head_dim)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:344:1: W293 [*] Blank line contains whitespace\n    |\n342 |         attn_scores = torch.sum(q * k, dim=-1) / math.sqrt(self.head_dim)\n343 |         attn_weights = F.softmax(attn_scores, dim=-1)\n344 |         \n    | ^^^^^^^^ W293\n345 |         # Apply dropout\n346 |         attn_weights = F.dropout(attn_weights, p=self.dropout, training=self.training)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:347:1: W293 [*] Blank line contains whitespace\n    |\n345 |         # Apply dropout\n346 |         attn_weights = F.dropout(attn_weights, p=self.dropout, training=self.training)\n347 |         \n    | ^^^^^^^^ W293\n348 |         # Apply attention to values\n349 |         attn_output = attn_weights.unsqueeze(-1) * v\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:351:1: W293 [*] Blank line contains whitespace\n    |\n349 |         attn_output = attn_weights.unsqueeze(-1) * v\n350 |         attn_output = attn_output.view(-1, self.hidden_dim)\n351 |         \n    | ^^^^^^^^ W293\n352 |         # Final projection\n353 |         messages = self.out_proj(attn_output)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:354:1: W293 [*] Blank line contains whitespace\n    |\n352 |         # Final projection\n353 |         messages = self.out_proj(attn_output)\n354 |         \n    | ^^^^^^^^ W293\n355 |         return messages\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:356:1: W293 [*] Blank line contains whitespace\n    |\n355 |         return messages\n356 |     \n    | ^^^^ W293\n357 |     def _compute_kl_loss(\n358 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:368:1: W293 [*] Blank line contains whitespace\n    |\n366 |         var1 = torch.exp(logvar1)\n367 |         var2 = torch.exp(logvar2)\n368 |         \n    | ^^^^^^^^ W293\n369 |         kl = 0.5 * (\n370 |             logvar2 - logvar1 +\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:373:1: W293 [*] Blank line contains whitespace\n    |\n371 |             (var1 + (mean1 - mean2) ** 2) / var2 - 1\n372 |         )\n373 |         \n    | ^^^^^^^^ W293\n374 |         return kl.sum(dim=-1).mean()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:375:1: W293 [*] Blank line contains whitespace\n    |\n374 |         return kl.sum(dim=-1).mean()\n375 |     \n    | ^^^^ W293\n376 |     def reverse_step(\n377 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:388:1: W293 [*] Blank line contains whitespace\n    |\n386 |         messages = self.propagate(edge_index, x=z, edge_attr=edge_attr)\n387 |         combined = torch.cat([z, messages], dim=-1)\n388 |         \n    | ^^^^^^^^ W293\n389 |         # Apply reverse transformation (simplified)\n390 |         diffusion_params = self.diffusion_net(combined)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:392:1: W293 [*] Blank line contains whitespace\n    |\n390 |         diffusion_params = self.diffusion_net(combined)\n391 |         new_mean, _ = diffusion_params.chunk(2, dim=-1)\n392 |         \n    | ^^^^^^^^ W293\n393 |         return self.layer_norm(new_mean + z)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/diffusion.py:393:45: W292 [*] No newline at end of file\n    |\n391 |         new_mean, _ = diffusion_params.chunk(2, dim=-1)\n392 |         \n393 |         return self.layer_norm(new_mean + z)\n    |                                             ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/temporal/encoding.py:7:1: I001 [*] Import block is un-sorted or un-formatted\n   |\n 5 |   \"\"\"\n 6 |\n 7 | / import math\n 8 | | import torch\n 9 | | import torch.nn as nn\n10 | | import torch.nn.functional as F\n11 | | from typing import Optional, Tuple\n   | |__________________________________^ I001\n   |\n   = help: Organize imports\n\nsrc/dgdn/temporal/encoding.py:16:1: W293 Blank line contains whitespace\n   |\n14 | class EdgeTimeEncoder(nn.Module):\n15 |     \"\"\"Edge-Time Encoder for continuous temporal modeling.\n16 |     \n   | ^^^^ W293\n17 |     Transforms continuous timestamps into rich temporal embeddings using \n18 |     learnable Fourier features for scale-invariant representations.\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:17:73: W291 Trailing whitespace\n   |\n15 |     \"\"\"Edge-Time Encoder for continuous temporal modeling.\n16 |     \n17 |     Transforms continuous timestamps into rich temporal embeddings using \n   |                                                                         ^ W291\n18 |     learnable Fourier features for scale-invariant representations.\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/temporal/encoding.py:19:1: W293 Blank line contains whitespace\n   |\n17 |     Transforms continuous timestamps into rich temporal embeddings using \n18 |     learnable Fourier features for scale-invariant representations.\n19 |     \n   | ^^^^ W293\n20 |     Args:\n21 |         time_dim: Dimension of the output time embeddings\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:26:1: W293 [*] Blank line contains whitespace\n   |\n24 |         learnable_bases: Whether to make Fourier bases learnable (default: True)\n25 |     \"\"\"\n26 |     \n   | ^^^^ W293\n27 |     def __init__(\n28 |         self,\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:38:1: W293 [*] Blank line contains whitespace\n   |\n36 |         self.num_bases = num_bases\n37 |         self.max_time = max_time\n38 |         \n   | ^^^^^^^^ W293\n39 |         # Initialize Fourier basis frequencies\n40 |         if learnable_bases:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:49:1: W293 [*] Blank line contains whitespace\n   |\n47 |             self.register_buffer('w', frequencies)\n48 |             self.register_buffer('b', torch.zeros(num_bases))\n49 |         \n   | ^^^^^^^^ W293\n50 |         # Projection layer to desired dimension\n51 |         self.projection = nn.Linear(num_bases, time_dim)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:52:1: W293 [*] Blank line contains whitespace\n   |\n50 |         # Projection layer to desired dimension\n51 |         self.projection = nn.Linear(num_bases, time_dim)\n52 |         \n   | ^^^^^^^^ W293\n53 |         # Layer normalization for stability\n54 |         self.layer_norm = nn.LayerNorm(time_dim)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:55:1: W293 [*] Blank line contains whitespace\n   |\n53 |         # Layer normalization for stability\n54 |         self.layer_norm = nn.LayerNorm(time_dim)\n55 |         \n   | ^^^^^^^^ W293\n56 |         self.reset_parameters()\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:57:1: W293 [*] Blank line contains whitespace\n   |\n56 |         self.reset_parameters()\n57 |     \n   | ^^^^ W293\n58 |     def reset_parameters(self):\n59 |         \"\"\"Initialize parameters using Xavier uniform initialization.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:62:1: W293 [*] Blank line contains whitespace\n   |\n60 |         nn.init.xavier_uniform_(self.projection.weight)\n61 |         nn.init.zeros_(self.projection.bias)\n62 |         \n   | ^^^^^^^^ W293\n63 |         if hasattr(self, 'w') and self.w.requires_grad:\n64 |             # Initialize learnable frequencies uniformly in log space\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:68:1: W293 [*] Blank line contains whitespace\n   |\n66 |                 self.w.uniform_(0.1, 10.0)\n67 |                 self.b.uniform_(0, 2 * math.pi)\n68 |     \n   | ^^^^ W293\n69 |     def forward(self, timestamps: torch.Tensor) -> torch.Tensor:\n70 |         \"\"\"Encode timestamps into temporal embeddings.\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:71:1: W293 Blank line contains whitespace\n   |\n69 |     def forward(self, timestamps: torch.Tensor) -> torch.Tensor:\n70 |         \"\"\"Encode timestamps into temporal embeddings.\n71 |         \n   | ^^^^^^^^ W293\n72 |         Args:\n73 |             timestamps: Tensor of shape [num_edges] or [batch_size, num_edges]\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:75:1: W293 Blank line contains whitespace\n   |\n73 |             timestamps: Tensor of shape [num_edges] or [batch_size, num_edges]\n74 |                        containing continuous timestamp values\n75 |                        \n   | ^^^^^^^^^^^^^^^^^^^^^^^ W293\n76 |         Returns:\n77 |             time_encoding: Tensor of shape [..., time_dim] containing temporal embeddings\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:82:1: W293 [*] Blank line contains whitespace\n   |\n80 |         if timestamps.numel() == 0:\n81 |             return torch.empty(0, self.time_dim, device=timestamps.device, dtype=torch.float32)\n82 |         \n   | ^^^^^^^^ W293\n83 |         # Ensure timestamps are float\n84 |         timestamps = timestamps.float()\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:85:1: W293 [*] Blank line contains whitespace\n   |\n83 |         # Ensure timestamps are float\n84 |         timestamps = timestamps.float()\n85 |         \n   | ^^^^^^^^ W293\n86 |         # Normalize timestamps to [0, 1] range\n87 |         normalized_time = timestamps / self.max_time\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:88:1: W293 [*] Blank line contains whitespace\n   |\n86 |         # Normalize timestamps to [0, 1] range\n87 |         normalized_time = timestamps / self.max_time\n88 |         \n   | ^^^^^^^^ W293\n89 |         # Add dimension for broadcasting with basis functions\n90 |         if normalized_time.dim() == 1:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:94:1: W293 [*] Blank line contains whitespace\n   |\n92 |         else:\n93 |             normalized_time = normalized_time.unsqueeze(-1)  # [batch_size, num_edges, 1]\n94 |         \n   | ^^^^^^^^ W293\n95 |         # Compute Fourier features: sin(w * t + b)\n96 |         fourier_features = torch.sin(normalized_time * self.w + self.b)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:97:1: W293 [*] Blank line contains whitespace\n   |\n95 |         # Compute Fourier features: sin(w * t + b)\n96 |         fourier_features = torch.sin(normalized_time * self.w + self.b)\n97 |         \n   | ^^^^^^^^ W293\n98 |         # Project to desired dimension\n99 |         time_encoding = self.projection(fourier_features)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:100:1: W293 [*] Blank line contains whitespace\n    |\n 98 |         # Project to desired dimension\n 99 |         time_encoding = self.projection(fourier_features)\n100 |         \n    | ^^^^^^^^ W293\n101 |         # Apply layer normalization\n102 |         time_encoding = self.layer_norm(time_encoding)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:103:1: W293 [*] Blank line contains whitespace\n    |\n101 |         # Apply layer normalization\n102 |         time_encoding = self.layer_norm(time_encoding)\n103 |         \n    | ^^^^^^^^ W293\n104 |         return time_encoding\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:105:1: W293 [*] Blank line contains whitespace\n    |\n104 |         return time_encoding\n105 |     \n    | ^^^^ W293\n106 |     def get_time_range_encoding(\n107 |         self, \n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:107:14: W291 [*] Trailing whitespace\n    |\n106 |     def get_time_range_encoding(\n107 |         self, \n    |              ^ W291\n108 |         start_time: float, \n109 |         end_time: float, \n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/temporal/encoding.py:108:27: W291 [*] Trailing whitespace\n    |\n106 |     def get_time_range_encoding(\n107 |         self, \n108 |         start_time: float, \n    |                           ^ W291\n109 |         end_time: float, \n110 |         num_steps: int = 100\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/temporal/encoding.py:109:25: W291 [*] Trailing whitespace\n    |\n107 |         self, \n108 |         start_time: float, \n109 |         end_time: float, \n    |                         ^ W291\n110 |         num_steps: int = 100\n111 |     ) -> torch.Tensor:\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/temporal/encoding.py:113:1: W293 Blank line contains whitespace\n    |\n111 |     ) -> torch.Tensor:\n112 |         \"\"\"Generate time encodings for a range of timestamps.\n113 |         \n    | ^^^^^^^^ W293\n114 |         Useful for visualization and analysis of temporal patterns.\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:115:1: W293 Blank line contains whitespace\n    |\n114 |         Useful for visualization and analysis of temporal patterns.\n115 |         \n    | ^^^^^^^^ W293\n116 |         Args:\n117 |             start_time: Starting timestamp\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:118:39: W291 Trailing whitespace\n    |\n116 |         Args:\n117 |             start_time: Starting timestamp\n118 |             end_time: Ending timestamp  \n    |                                       ^^ W291\n119 |             num_steps: Number of time steps to generate\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/temporal/encoding.py:120:1: W293 Blank line contains whitespace\n    |\n118 |             end_time: Ending timestamp  \n119 |             num_steps: Number of time steps to generate\n120 |             \n    | ^^^^^^^^^^^^ W293\n121 |         Returns:\n122 |             encodings: Tensor of shape [num_steps, time_dim]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:126:1: W293 [*] Blank line contains whitespace\n    |\n124 |         timestamps = torch.linspace(start_time, end_time, num_steps)\n125 |         return self.forward(timestamps)\n126 |     \n    | ^^^^ W293\n127 |     def compute_temporal_similarity(\n128 |         self, \n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:128:14: W291 [*] Trailing whitespace\n    |\n127 |     def compute_temporal_similarity(\n128 |         self, \n    |              ^ W291\n129 |         time1: torch.Tensor, \n130 |         time2: torch.Tensor\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/temporal/encoding.py:129:29: W291 [*] Trailing whitespace\n    |\n127 |     def compute_temporal_similarity(\n128 |         self, \n129 |         time1: torch.Tensor, \n    |                             ^ W291\n130 |         time2: torch.Tensor\n131 |     ) -> torch.Tensor:\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/temporal/encoding.py:133:1: W293 Blank line contains whitespace\n    |\n131 |     ) -> torch.Tensor:\n132 |         \"\"\"Compute cosine similarity between temporal encodings.\n133 |         \n    | ^^^^^^^^ W293\n134 |         Args:\n135 |             time1: First set of timestamps\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:137:1: W293 Blank line contains whitespace\n    |\n135 |             time1: First set of timestamps\n136 |             time2: Second set of timestamps\n137 |             \n    | ^^^^^^^^^^^^ W293\n138 |         Returns:\n139 |             similarity: Cosine similarities between encodings\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:143:1: W293 [*] Blank line contains whitespace\n    |\n141 |         enc1 = self.forward(time1)\n142 |         enc2 = self.forward(time2)\n143 |         \n    | ^^^^^^^^ W293\n144 |         return F.cosine_similarity(enc1, enc2, dim=-1)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:145:1: W293 [*] Blank line contains whitespace\n    |\n144 |         return F.cosine_similarity(enc1, enc2, dim=-1)\n145 |     \n    | ^^^^ W293\n146 |     def get_frequency_response(self) -> Tuple[torch.Tensor, torch.Tensor]:\n147 |         \"\"\"Get the frequency response of the encoder.\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:148:1: W293 Blank line contains whitespace\n    |\n146 |     def get_frequency_response(self) -> Tuple[torch.Tensor, torch.Tensor]:\n147 |         \"\"\"Get the frequency response of the encoder.\n148 |         \n    | ^^^^^^^^ W293\n149 |         Returns:\n150 |             frequencies: The learned/fixed frequencies\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:158:1: W293 Blank line contains whitespace\n    |\n156 | class PositionalTimeEncoder(nn.Module):\n157 |     \"\"\"Alternative time encoder using positional encoding similar to Transformers.\n158 |     \n    | ^^^^ W293\n159 |     Uses sine and cosine functions at different frequencies for time encoding.\n160 |     Can be more stable than learnable Fourier features in some cases.\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:162:1: W293 [*] Blank line contains whitespace\n    |\n160 |     Can be more stable than learnable Fourier features in some cases.\n161 |     \"\"\"\n162 |     \n    | ^^^^ W293\n163 |     def __init__(self, time_dim: int, max_time: float = 10000.0):\n164 |         super().__init__()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:167:1: W293 [*] Blank line contains whitespace\n    |\n165 |         self.time_dim = time_dim\n166 |         self.max_time = max_time\n167 |         \n    | ^^^^^^^^ W293\n168 |         # Create position encoding matrix\n169 |         pe = torch.zeros(int(max_time), time_dim)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:171:1: W293 [*] Blank line contains whitespace\n    |\n169 |         pe = torch.zeros(int(max_time), time_dim)\n170 |         position = torch.arange(0, max_time, dtype=torch.float).unsqueeze(1)\n171 |         \n    | ^^^^^^^^ W293\n172 |         div_term = torch.exp(torch.arange(0, time_dim, 2).float() * \n173 |                            (-math.log(10000.0) / time_dim))\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:172:68: W291 [*] Trailing whitespace\n    |\n170 |         position = torch.arange(0, max_time, dtype=torch.float).unsqueeze(1)\n171 |         \n172 |         div_term = torch.exp(torch.arange(0, time_dim, 2).float() * \n    |                                                                    ^ W291\n173 |                            (-math.log(10000.0) / time_dim))\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/temporal/encoding.py:174:1: W293 [*] Blank line contains whitespace\n    |\n172 |         div_term = torch.exp(torch.arange(0, time_dim, 2).float() * \n173 |                            (-math.log(10000.0) / time_dim))\n174 |         \n    | ^^^^^^^^ W293\n175 |         pe[:, 0::2] = torch.sin(position * div_term)\n176 |         pe[:, 1::2] = torch.cos(position * div_term)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:177:1: W293 [*] Blank line contains whitespace\n    |\n175 |         pe[:, 0::2] = torch.sin(position * div_term)\n176 |         pe[:, 1::2] = torch.cos(position * div_term)\n177 |         \n    | ^^^^^^^^ W293\n178 |         self.register_buffer('pe', pe)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:179:1: W293 [*] Blank line contains whitespace\n    |\n178 |         self.register_buffer('pe', pe)\n179 |     \n    | ^^^^ W293\n180 |     def forward(self, timestamps: torch.Tensor) -> torch.Tensor:\n181 |         \"\"\"Encode timestamps using positional encoding.\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:182:1: W293 Blank line contains whitespace\n    |\n180 |     def forward(self, timestamps: torch.Tensor) -> torch.Tensor:\n181 |         \"\"\"Encode timestamps using positional encoding.\n182 |         \n    | ^^^^^^^^ W293\n183 |         Args:\n184 |             timestamps: Continuous timestamp values\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:185:1: W293 Blank line contains whitespace\n    |\n183 |         Args:\n184 |             timestamps: Continuous timestamp values\n185 |             \n    | ^^^^^^^^^^^^ W293\n186 |         Returns:\n187 |             Positional encodings for the timestamps\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:191:1: W293 [*] Blank line contains whitespace\n    |\n189 |         # Clamp timestamps to valid range\n190 |         timestamps = torch.clamp(timestamps, 0, self.max_time - 1).long()\n191 |         \n    | ^^^^^^^^ W293\n192 |         return self.pe[timestamps]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:197:1: W293 Blank line contains whitespace\n    |\n195 | class MultiScaleTimeEncoder(nn.Module):\n196 |     \"\"\"Multi-scale temporal encoder that combines encodings at different time scales.\n197 |     \n    | ^^^^ W293\n198 |     Useful for capturing both short-term and long-term temporal patterns.\n199 |     \"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:200:1: W293 [*] Blank line contains whitespace\n    |\n198 |     Useful for capturing both short-term and long-term temporal patterns.\n199 |     \"\"\"\n200 |     \n    | ^^^^ W293\n201 |     def __init__(\n202 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:208:1: W293 [*] Blank line contains whitespace\n    |\n206 |     ):\n207 |         super().__init__()\n208 |         \n    | ^^^^^^^^ W293\n209 |         if scales is None:\n210 |             scales = [1.0, 10.0, 100.0, 1000.0]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:211:1: W293 [*] Blank line contains whitespace\n    |\n209 |         if scales is None:\n210 |             scales = [1.0, 10.0, 100.0, 1000.0]\n211 |         \n    | ^^^^^^^^ W293\n212 |         self.scales = scales\n213 |         self.aggregation = aggregation\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:214:1: W293 [*] Blank line contains whitespace\n    |\n212 |         self.scales = scales\n213 |         self.aggregation = aggregation\n214 |         \n    | ^^^^^^^^ W293\n215 |         # Create encoders for different scales\n216 |         if aggregation == \"concat\":\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:219:59: W291 [*] Trailing whitespace\n    |\n217 |             scale_dim = time_dim // len(scales)\n218 |             self.encoders = nn.ModuleList([\n219 |                 EdgeTimeEncoder(scale_dim, max_time=scale) \n    |                                                           ^ W291\n220 |                 for scale in scales\n221 |             ])\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/temporal/encoding.py:224:58: W291 [*] Trailing whitespace\n    |\n222 |         elif aggregation == \"sum\":\n223 |             self.encoders = nn.ModuleList([\n224 |                 EdgeTimeEncoder(time_dim, max_time=scale) \n    |                                                          ^ W291\n225 |                 for scale in scales\n226 |             ])\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/temporal/encoding.py:229:1: W293 [*] Blank line contains whitespace\n    |\n227 |         else:\n228 |             raise ValueError(f\"Unknown aggregation: {aggregation}\")\n229 |     \n    | ^^^^ W293\n230 |     def forward(self, timestamps: torch.Tensor) -> torch.Tensor:\n231 |         \"\"\"Encode timestamps at multiple scales.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:233:1: W293 [*] Blank line contains whitespace\n    |\n231 |         \"\"\"Encode timestamps at multiple scales.\"\"\"\n232 |         encodings = [encoder(timestamps) for encoder in self.encoders]\n233 |         \n    | ^^^^^^^^ W293\n234 |         if self.aggregation == \"concat\":\n235 |             return torch.cat(encodings, dim=-1)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/temporal/encoding.py:239:73: W292 [*] No newline at end of file\n    |\n237 |             return torch.stack(encodings, dim=0).sum(dim=0)\n238 |         else:\n239 |             raise ValueError(f\"Unknown aggregation: {self.aggregation}\")\n    |                                                                         ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/training/__init__.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n  |\n1 |   \"\"\"Training infrastructure for DGDN.\"\"\"\n2 |\n3 | / from .trainer import DGDNTrainer\n4 | | from .losses import DGDNLoss, VariationalLoss, TemporalRegularizationLoss\n5 | | from .metrics import DGDNMetrics, EdgePredictionMetrics, NodeClassificationMetrics\n  | |__________________________________________________________________________________^ I001\n6 |\n7 |   __all__ = [\n  |\n  = help: Organize imports\n\nsrc/dgdn/training/__init__.py:9:16: W291 [*] Trailing whitespace\n   |\n 7 | __all__ = [\n 8 |     \"DGDNTrainer\",\n 9 |     \"DGDNLoss\", \n   |                ^ W291\n10 |     \"VariationalLoss\",\n11 |     \"TemporalRegularizationLoss\",\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/training/__init__.py:13:29: W291 [*] Trailing whitespace\n   |\n11 |     \"TemporalRegularizationLoss\",\n12 |     \"DGDNMetrics\",\n13 |     \"EdgePredictionMetrics\", \n   |                             ^ W291\n14 |     \"NodeClassificationMetrics\"\n15 | ]\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/training/__init__.py:15:2: W292 [*] No newline at end of file\n   |\n13 |     \"EdgePredictionMetrics\", \n14 |     \"NodeClassificationMetrics\"\n15 | ]\n   |  ^ W292\n   |\n   = help: Add trailing newline\n\nsrc/dgdn/training/losses.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n  |\n1 |   \"\"\"Loss functions for DGDN training.\"\"\"\n2 |\n3 | / import torch\n4 | | import torch.nn as nn\n5 | | import torch.nn.functional as F\n6 | | from typing import Dict, Optional, Any\n7 | | import math\n  | |___________^ I001\n  |\n  = help: Organize imports\n\nsrc/dgdn/training/losses.py:6:36: F401 [*] `typing.Any` imported but unused\n  |\n4 | import torch.nn as nn\n5 | import torch.nn.functional as F\n6 | from typing import Dict, Optional, Any\n  |                                    ^^^ F401\n7 | import math\n  |\n  = help: Remove unused import: `typing.Any`\n\nsrc/dgdn/training/losses.py:7:8: F401 [*] `math` imported but unused\n  |\n5 | import torch.nn.functional as F\n6 | from typing import Dict, Optional, Any\n7 | import math\n  |        ^^^^ F401\n  |\n  = help: Remove unused import: `math`\n\nsrc/dgdn/training/losses.py:12:1: W293 Blank line contains whitespace\n   |\n10 | class DGDNLoss(nn.Module):\n11 |     \"\"\"Comprehensive loss function for DGDN training.\n12 |     \n   | ^^^^ W293\n13 |     Combines multiple loss components:\n14 |     - Reconstruction loss (task-specific)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:19:1: W293 [*] Blank line contains whitespace\n   |\n17 |     - Diffusion loss (for proper denoising)\n18 |     \"\"\"\n19 |     \n   | ^^^^ W293\n20 |     def __init__(\n21 |         self,\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:29:1: W293 [*] Blank line contains whitespace\n   |\n27 |     ):\n28 |         super().__init__()\n29 |         \n   | ^^^^^^^^ W293\n30 |         self.reconstruction_weight = reconstruction_weight\n31 |         self.kl_weight = kl_weight\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:35:1: W293 [*] Blank line contains whitespace\n   |\n33 |         self.diffusion_weight = diffusion_weight\n34 |         self.task = task\n35 |         \n   | ^^^^^^^^ W293\n36 |         # Initialize component losses\n37 |         self.variational_loss = VariationalLoss()\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:40:1: W293 [*] Blank line contains whitespace\n   |\n38 |         self.temporal_loss = TemporalRegularizationLoss()\n39 |         self.diffusion_loss = DiffusionLoss()\n40 |         \n   | ^^^^^^^^ W293\n41 |     def forward(\n42 |         self,\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:49:1: W293 Blank line contains whitespace\n   |\n47 |     ) -> Dict[str, torch.Tensor]:\n48 |         \"\"\"Compute total loss and components.\n49 |         \n   | ^^^^^^^^ W293\n50 |         Args:\n51 |             model_output: Dictionary from DGDN forward pass\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:54:1: W293 Blank line contains whitespace\n   |\n52 |             targets: Ground truth targets\n53 |             edge_index: Edge connectivity for edge prediction tasks\n54 |             \n   | ^^^^^^^^^^^^ W293\n55 |         Returns:\n56 |             Dictionary of loss components\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:59:1: W293 [*] Blank line contains whitespace\n   |\n57 |         \"\"\"\n58 |         losses = {}\n59 |         \n   | ^^^^^^^^ W293\n60 |         # 1. Reconstruction loss (task-specific)\n61 |         recon_loss = self._compute_reconstruction_loss(\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:65:1: W293 [*] Blank line contains whitespace\n   |\n63 |         )\n64 |         losses[\"reconstruction\"] = recon_loss\n65 |         \n   | ^^^^^^^^ W293\n66 |         # 2. Variational loss (KL divergence)\n67 |         if \"mean\" in model_output and \"logvar\" in model_output:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:69:38: W291 [*] Trailing whitespace\n   |\n67 |         if \"mean\" in model_output and \"logvar\" in model_output:\n68 |             var_loss = self.variational_loss(\n69 |                 model_output[\"mean\"], \n   |                                      ^ W291\n70 |                 model_output[\"logvar\"]\n71 |             )\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/training/losses.py:75:1: W293 [*] Blank line contains whitespace\n   |\n73 |         else:\n74 |             losses[\"variational\"] = torch.tensor(0.0, device=recon_loss.device)\n75 |         \n   | ^^^^^^^^ W293\n76 |         # 3. Temporal regularization\n77 |         if \"temporal_encoding\" in model_output:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:82:1: W293 [*] Blank line contains whitespace\n   |\n80 |         else:\n81 |             losses[\"temporal\"] = torch.tensor(0.0, device=recon_loss.device)\n82 |         \n   | ^^^^^^^^ W293\n83 |         # 4. Diffusion loss (if diffusion steps available)\n84 |         if \"diffusion_steps\" in model_output:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:89:1: W293 [*] Blank line contains whitespace\n   |\n87 |         else:\n88 |             losses[\"diffusion\"] = torch.tensor(0.0, device=recon_loss.device)\n89 |         \n   | ^^^^^^^^ W293\n90 |         # 5. Total weighted loss\n91 |         total_loss = (\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:97:1: W293 [*] Blank line contains whitespace\n   |\n95 |             self.diffusion_weight * losses[\"diffusion\"]\n96 |         )\n97 |         \n   | ^^^^^^^^ W293\n98 |         losses[\"total\"] = total_loss\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:99:1: W293 [*] Blank line contains whitespace\n    |\n 98 |         losses[\"total\"] = total_loss\n 99 |         \n    | ^^^^^^^^ W293\n100 |         return losses\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:101:1: W293 [*] Blank line contains whitespace\n    |\n100 |         return losses\n101 |     \n    | ^^^^ W293\n102 |     def _compute_reconstruction_loss(\n103 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:109:1: W293 [*] Blank line contains whitespace\n    |\n107 |     ) -> torch.Tensor:\n108 |         \"\"\"Compute task-specific reconstruction loss.\"\"\"\n109 |         \n    | ^^^^^^^^ W293\n110 |         if self.task == \"edge_prediction\":\n111 |             return self._edge_prediction_loss(model_output, targets, edge_index)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:118:1: W293 [*] Blank line contains whitespace\n    |\n116 |         else:\n117 |             raise ValueError(f\"Unknown task: {self.task}\")\n118 |     \n    | ^^^^ W293\n119 |     def _edge_prediction_loss(\n120 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:127:1: W293 [*] Blank line contains whitespace\n    |\n125 |         \"\"\"Binary cross-entropy loss for edge prediction.\"\"\"\n126 |         node_embeddings = model_output[\"node_embeddings\"]\n127 |         \n    | ^^^^^^^^ W293\n128 |         # Get source and target node embeddings\n129 |         src_embeddings = node_embeddings[edge_index[0]]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:131:1: W293 [*] Blank line contains whitespace\n    |\n129 |         src_embeddings = node_embeddings[edge_index[0]]\n130 |         tgt_embeddings = node_embeddings[edge_index[1]]\n131 |         \n    | ^^^^^^^^ W293\n132 |         # Compute edge scores (dot product)\n133 |         edge_scores = torch.sum(src_embeddings * tgt_embeddings, dim=-1)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:135:1: W293 [*] Blank line contains whitespace\n    |\n133 |         edge_scores = torch.sum(src_embeddings * tgt_embeddings, dim=-1)\n134 |         edge_probs = torch.sigmoid(edge_scores)\n135 |         \n    | ^^^^^^^^ W293\n136 |         # Binary cross-entropy loss\n137 |         return F.binary_cross_entropy(edge_probs, targets.float())\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:138:1: W293 [*] Blank line contains whitespace\n    |\n136 |         # Binary cross-entropy loss\n137 |         return F.binary_cross_entropy(edge_probs, targets.float())\n138 |     \n    | ^^^^ W293\n139 |     def _node_classification_loss(\n140 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:144:58: W291 [*] Trailing whitespace\n    |\n142 |         targets: torch.Tensor\n143 |     ) -> torch.Tensor:\n144 |         \"\"\"Cross-entropy loss for node classification.\"\"\" \n    |                                                          ^ W291\n145 |         node_embeddings = model_output[\"node_embeddings\"]\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/training/losses.py:146:1: W293 [*] Blank line contains whitespace\n    |\n144 |         \"\"\"Cross-entropy loss for node classification.\"\"\" \n145 |         node_embeddings = model_output[\"node_embeddings\"]\n146 |         \n    | ^^^^^^^^ W293\n147 |         # Simple linear classifier for demonstration\n148 |         # In practice, this would use the model's node classifier\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:151:39: W291 [*] Trailing whitespace\n    |\n149 |         num_classes = targets.max().item() + 1\n150 |         classifier = nn.Linear(\n151 |             node_embeddings.shape[-1], \n    |                                       ^ W291\n152 |             num_classes,\n153 |             device=node_embeddings.device\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/training/losses.py:155:1: W293 [*] Blank line contains whitespace\n    |\n153 |             device=node_embeddings.device\n154 |         )\n155 |         \n    | ^^^^^^^^ W293\n156 |         logits = classifier(node_embeddings)\n157 |         return F.cross_entropy(logits, targets.long())\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:158:1: W293 [*] Blank line contains whitespace\n    |\n156 |         logits = classifier(node_embeddings)\n157 |         return F.cross_entropy(logits, targets.long())\n158 |     \n    | ^^^^ W293\n159 |     def _link_prediction_loss(\n160 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:167:1: W293 [*] Blank line contains whitespace\n    |\n165 |         \"\"\"Loss for link prediction with positive and negative samples.\"\"\"\n166 |         node_embeddings = model_output[\"node_embeddings\"]\n167 |         \n    | ^^^^^^^^ W293\n168 |         # Positive edges\n169 |         pos_src = node_embeddings[edge_index[0]]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:172:1: W293 [*] Blank line contains whitespace\n    |\n170 |         pos_tgt = node_embeddings[edge_index[1]]\n171 |         pos_scores = torch.sum(pos_src * pos_tgt, dim=-1)\n172 |         \n    | ^^^^^^^^ W293\n173 |         # Negative sampling (simplified)\n174 |         num_neg = edge_index.shape[1]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:177:1: W293 [*] Blank line contains whitespace\n    |\n175 |         neg_src_idx = torch.randint(0, node_embeddings.shape[0], (num_neg,))\n176 |         neg_tgt_idx = torch.randint(0, node_embeddings.shape[0], (num_neg,))\n177 |         \n    | ^^^^^^^^ W293\n178 |         neg_src = node_embeddings[neg_src_idx]\n179 |         neg_tgt = node_embeddings[neg_tgt_idx]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:181:1: W293 [*] Blank line contains whitespace\n    |\n179 |         neg_tgt = node_embeddings[neg_tgt_idx]\n180 |         neg_scores = torch.sum(neg_src * neg_tgt, dim=-1)\n181 |         \n    | ^^^^^^^^ W293\n182 |         # BPR loss (Bayesian Personalized Ranking)\n183 |         loss = -torch.log(torch.sigmoid(pos_scores - neg_scores)).mean()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:184:1: W293 [*] Blank line contains whitespace\n    |\n182 |         # BPR loss (Bayesian Personalized Ranking)\n183 |         loss = -torch.log(torch.sigmoid(pos_scores - neg_scores)).mean()\n184 |         \n    | ^^^^^^^^ W293\n185 |         return loss\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:190:1: W293 [*] Blank line contains whitespace\n    |\n188 | class VariationalLoss(nn.Module):\n189 |     \"\"\"KL divergence loss for variational inference.\"\"\"\n190 |     \n    | ^^^^ W293\n191 |     def __init__(self, beta: float = 1.0):\n192 |         super().__init__()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:194:1: W293 [*] Blank line contains whitespace\n    |\n192 |         super().__init__()\n193 |         self.beta = beta\n194 |     \n    | ^^^^ W293\n195 |     def forward(\n196 |         self, \n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:196:14: W291 [*] Trailing whitespace\n    |\n195 |     def forward(\n196 |         self, \n    |              ^ W291\n197 |         mean: torch.Tensor, \n198 |         logvar: torch.Tensor,\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/training/losses.py:197:28: W291 [*] Trailing whitespace\n    |\n195 |     def forward(\n196 |         self, \n197 |         mean: torch.Tensor, \n    |                            ^ W291\n198 |         logvar: torch.Tensor,\n199 |         prior_mean: Optional[torch.Tensor] = None,\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/training/losses.py:203:1: W293 Blank line contains whitespace\n    |\n201 |     ) -> torch.Tensor:\n202 |         \"\"\"Compute KL divergence loss.\n203 |         \n    | ^^^^^^^^ W293\n204 |         Args:\n205 |             mean: Posterior mean [batch_size, hidden_dim]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:209:1: W293 Blank line contains whitespace\n    |\n207 |             prior_mean: Prior mean (defaults to zero)\n208 |             prior_logvar: Prior log variance (defaults to zero)\n209 |             \n    | ^^^^^^^^^^^^ W293\n210 |         Returns:\n211 |             KL divergence loss\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:217:1: W293 [*] Blank line contains whitespace\n    |\n215 |         if prior_logvar is None:\n216 |             prior_logvar = torch.zeros_like(logvar)\n217 |         \n    | ^^^^^^^^ W293\n218 |         # KL(q||p) = 0.5 * [log(\u03c3_p\u00b2/\u03c3_q\u00b2) + (\u03c3_q\u00b2 + (\u03bc_q - \u03bc_p)\u00b2)/\u03c3_p\u00b2 - 1]\n219 |         var = torch.exp(logvar)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:221:1: W293 [*] Blank line contains whitespace\n    |\n219 |         var = torch.exp(logvar)\n220 |         prior_var = torch.exp(prior_logvar)\n221 |         \n    | ^^^^^^^^ W293\n222 |         kl_div = 0.5 * (\n223 |             prior_logvar - logvar +\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:226:1: W293 [*] Blank line contains whitespace\n    |\n224 |             (var + (mean - prior_mean) ** 2) / prior_var - 1\n225 |         )\n226 |         \n    | ^^^^^^^^ W293\n227 |         return self.beta * kl_div.sum(dim=-1).mean()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:232:1: W293 [*] Blank line contains whitespace\n    |\n230 | class TemporalRegularizationLoss(nn.Module):\n231 |     \"\"\"Temporal smoothness regularization loss.\"\"\"\n232 |     \n    | ^^^^ W293\n233 |     def __init__(self, alpha: float = 1.0):\n234 |         super().__init__()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:236:1: W293 [*] Blank line contains whitespace\n    |\n234 |         super().__init__()\n235 |         self.alpha = alpha\n236 |     \n    | ^^^^ W293\n237 |     def forward(self, temporal_encoding: torch.Tensor) -> torch.Tensor:\n238 |         \"\"\"Encourage smooth temporal transitions.\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:239:1: W293 Blank line contains whitespace\n    |\n237 |     def forward(self, temporal_encoding: torch.Tensor) -> torch.Tensor:\n238 |         \"\"\"Encourage smooth temporal transitions.\n239 |         \n    | ^^^^^^^^ W293\n240 |         Args:\n241 |             temporal_encoding: Temporal encodings [num_edges, time_dim]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:242:1: W293 Blank line contains whitespace\n    |\n240 |         Args:\n241 |             temporal_encoding: Temporal encodings [num_edges, time_dim]\n242 |             \n    | ^^^^^^^^^^^^ W293\n243 |         Returns:\n244 |             Temporal regularization loss\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:248:1: W293 [*] Blank line contains whitespace\n    |\n246 |         if temporal_encoding.shape[0] <= 1:\n247 |             return torch.tensor(0.0, device=temporal_encoding.device)\n248 |         \n    | ^^^^^^^^ W293\n249 |         # Compute differences between consecutive time encodings\n250 |         temporal_diff = temporal_encoding[1:] - temporal_encoding[:-1]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:251:1: W293 [*] Blank line contains whitespace\n    |\n249 |         # Compute differences between consecutive time encodings\n250 |         temporal_diff = temporal_encoding[1:] - temporal_encoding[:-1]\n251 |         \n    | ^^^^^^^^ W293\n252 |         # L2 regularization on differences\n253 |         smooth_loss = torch.mean(torch.sum(temporal_diff ** 2, dim=-1))\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:254:1: W293 [*] Blank line contains whitespace\n    |\n252 |         # L2 regularization on differences\n253 |         smooth_loss = torch.mean(torch.sum(temporal_diff ** 2, dim=-1))\n254 |         \n    | ^^^^^^^^ W293\n255 |         return self.alpha * smooth_loss\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:260:1: W293 [*] Blank line contains whitespace\n    |\n258 | class DiffusionLoss(nn.Module):\n259 |     \"\"\"Loss for proper diffusion process training.\"\"\"\n260 |     \n    | ^^^^ W293\n261 |     def __init__(self, noise_schedule: str = \"linear\"):\n262 |         super().__init__()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:264:1: W293 [*] Blank line contains whitespace\n    |\n262 |         super().__init__()\n263 |         self.noise_schedule = noise_schedule\n264 |     \n    | ^^^^ W293\n265 |     def forward(self, diffusion_steps: list) -> torch.Tensor:\n266 |         \"\"\"Compute diffusion denoising loss.\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:267:1: W293 Blank line contains whitespace\n    |\n265 |     def forward(self, diffusion_steps: list) -> torch.Tensor:\n266 |         \"\"\"Compute diffusion denoising loss.\n267 |         \n    | ^^^^^^^^ W293\n268 |         Args:\n269 |             diffusion_steps: List of diffusion step outputs\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:270:1: W293 Blank line contains whitespace\n    |\n268 |         Args:\n269 |             diffusion_steps: List of diffusion step outputs\n270 |             \n    | ^^^^^^^^^^^^ W293\n271 |         Returns:\n272 |             Diffusion loss\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:276:1: W293 [*] Blank line contains whitespace\n    |\n274 |         if not diffusion_steps:\n275 |             return torch.tensor(0.0)\n276 |         \n    | ^^^^^^^^ W293\n277 |         total_loss = 0.0\n278 |         num_steps = len(diffusion_steps)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:279:1: W293 [*] Blank line contains whitespace\n    |\n277 |         total_loss = 0.0\n278 |         num_steps = len(diffusion_steps)\n279 |         \n    | ^^^^^^^^ W293\n280 |         for i, step_output in enumerate(diffusion_steps):\n281 |             # Loss for each diffusion step\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:285:1: W293 [*] Blank line contains whitespace\n    |\n283 |             z = step_output[\"z\"]\n284 |             mean = step_output[\"mean\"]\n285 |             \n    | ^^^^^^^^^^^^ W293\n286 |             # MSE between sampled z and mean (encourage low variance when appropriate)\n287 |             step_loss = F.mse_loss(z, mean)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:288:1: W293 [*] Blank line contains whitespace\n    |\n286 |             # MSE between sampled z and mean (encourage low variance when appropriate)\n287 |             step_loss = F.mse_loss(z, mean)\n288 |             \n    | ^^^^^^^^^^^^ W293\n289 |             # Weight by step position (later steps should be more accurate)\n290 |             weight = (i + 1) / num_steps\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:292:1: W293 [*] Blank line contains whitespace\n    |\n290 |             weight = (i + 1) / num_steps\n291 |             total_loss += weight * step_loss\n292 |         \n    | ^^^^^^^^ W293\n293 |         return total_loss / num_steps\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:298:1: W293 [*] Blank line contains whitespace\n    |\n296 | class ContrastiveLoss(nn.Module):\n297 |     \"\"\"Contrastive loss for temporal graph representation learning.\"\"\"\n298 |     \n    | ^^^^ W293\n299 |     def __init__(self, temperature: float = 0.1):\n300 |         super().__init__()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:302:1: W293 [*] Blank line contains whitespace\n    |\n300 |         super().__init__()\n301 |         self.temperature = temperature\n302 |     \n    | ^^^^ W293\n303 |     def forward(\n304 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:310:1: W293 Blank line contains whitespace\n    |\n308 |     ) -> torch.Tensor:\n309 |         \"\"\"Compute contrastive loss between embedding pairs.\n310 |         \n    | ^^^^^^^^ W293\n311 |         Args:\n312 |             embeddings1: First set of embeddings\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:313:50: W291 Trailing whitespace\n    |\n311 |         Args:\n312 |             embeddings1: First set of embeddings\n313 |             embeddings2: Second set of embeddings  \n    |                                                  ^^ W291\n314 |             labels: Binary labels (1 for positive pairs, 0 for negative)\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/training/losses.py:315:1: W293 Blank line contains whitespace\n    |\n313 |             embeddings2: Second set of embeddings  \n314 |             labels: Binary labels (1 for positive pairs, 0 for negative)\n315 |             \n    | ^^^^^^^^^^^^ W293\n316 |         Returns:\n317 |             Contrastive loss\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:322:1: W293 [*] Blank line contains whitespace\n    |\n320 |         embeddings1 = F.normalize(embeddings1, dim=-1)\n321 |         embeddings2 = F.normalize(embeddings2, dim=-1)\n322 |         \n    | ^^^^^^^^ W293\n323 |         # Compute similarities\n324 |         similarities = torch.sum(embeddings1 * embeddings2, dim=-1) / self.temperature\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:325:1: W293 [*] Blank line contains whitespace\n    |\n323 |         # Compute similarities\n324 |         similarities = torch.sum(embeddings1 * embeddings2, dim=-1) / self.temperature\n325 |         \n    | ^^^^^^^^ W293\n326 |         # Contrastive loss\n327 |         pos_loss = labels * torch.exp(similarities)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:329:1: W293 [*] Blank line contains whitespace\n    |\n327 |         pos_loss = labels * torch.exp(similarities)\n328 |         neg_loss = (1 - labels) * torch.exp(-similarities)\n329 |         \n    | ^^^^^^^^ W293\n330 |         loss = -torch.log(pos_loss / (pos_loss + neg_loss + 1e-8))\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:331:1: W293 [*] Blank line contains whitespace\n    |\n330 |         loss = -torch.log(pos_loss / (pos_loss + neg_loss + 1e-8))\n331 |         \n    | ^^^^^^^^ W293\n332 |         return loss.mean()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:337:1: W293 [*] Blank line contains whitespace\n    |\n335 | class AdversarialLoss(nn.Module):\n336 |     \"\"\"Adversarial loss for robustness training.\"\"\"\n337 |     \n    | ^^^^ W293\n338 |     def __init__(self, epsilon: float = 0.1):\n339 |         super().__init__()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:341:1: W293 [*] Blank line contains whitespace\n    |\n339 |         super().__init__()\n340 |         self.epsilon = epsilon\n341 |     \n    | ^^^^ W293\n342 |     def forward(\n343 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:350:1: W293 Blank line contains whitespace\n    |\n348 |     ) -> torch.Tensor:\n349 |         \"\"\"Compute adversarial loss using FGSM attack.\n350 |         \n    | ^^^^^^^^ W293\n351 |         Args:\n352 |             model: DGDN model\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:356:1: W293 Blank line contains whitespace\n    |\n354 |             targets: Ground truth targets\n355 |             base_loss_fn: Base loss function\n356 |             \n    | ^^^^^^^^^^^^ W293\n357 |         Returns:\n358 |             Adversarial loss\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:363:1: W293 [*] Blank line contains whitespace\n    |\n361 |         if hasattr(data, 'node_features') and data.node_features is not None:\n362 |             data.node_features.requires_grad_(True)\n363 |         \n    | ^^^^^^^^ W293\n364 |         # Forward pass\n365 |         output = model(data)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:366:1: W293 [*] Blank line contains whitespace\n    |\n364 |         # Forward pass\n365 |         output = model(data)\n366 |         \n    | ^^^^^^^^ W293\n367 |         # Compute loss\n368 |         loss = base_loss_fn(output, targets)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:369:1: W293 [*] Blank line contains whitespace\n    |\n367 |         # Compute loss\n368 |         loss = base_loss_fn(output, targets)\n369 |         \n    | ^^^^^^^^ W293\n370 |         # Compute gradients\n371 |         loss.backward(retain_graph=True)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:372:1: W293 [*] Blank line contains whitespace\n    |\n370 |         # Compute gradients\n371 |         loss.backward(retain_graph=True)\n372 |         \n    | ^^^^^^^^ W293\n373 |         # Generate adversarial perturbation\n374 |         if data.node_features.grad is not None:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:376:1: W293 [*] Blank line contains whitespace\n    |\n374 |         if data.node_features.grad is not None:\n375 |             perturbation = self.epsilon * torch.sign(data.node_features.grad)\n376 |             \n    | ^^^^^^^^^^^^ W293\n377 |             # Apply perturbation\n378 |             perturbed_features = data.node_features + perturbation\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:379:1: W293 [*] Blank line contains whitespace\n    |\n377 |             # Apply perturbation\n378 |             perturbed_features = data.node_features + perturbation\n379 |             \n    | ^^^^^^^^^^^^ W293\n380 |             # Create perturbed data\n381 |             perturbed_data = type(data)(\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:388:1: W293 [*] Blank line contains whitespace\n    |\n386 |                 num_nodes=data.num_nodes\n387 |             )\n388 |             \n    | ^^^^^^^^^^^^ W293\n389 |             # Forward pass with perturbed data\n390 |             adv_output = model(perturbed_data)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:391:1: W293 [*] Blank line contains whitespace\n    |\n389 |             # Forward pass with perturbed data\n390 |             adv_output = model(perturbed_data)\n391 |             \n    | ^^^^^^^^^^^^ W293\n392 |             # Adversarial loss\n393 |             adv_loss = base_loss_fn(adv_output, targets)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:394:1: W293 [*] Blank line contains whitespace\n    |\n392 |             # Adversarial loss\n393 |             adv_loss = base_loss_fn(adv_output, targets)\n394 |             \n    | ^^^^^^^^^^^^ W293\n395 |             return adv_loss\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:396:1: W293 [*] Blank line contains whitespace\n    |\n395 |             return adv_loss\n396 |         \n    | ^^^^^^^^ W293\n397 |         return loss\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/losses.py:397:20: W292 [*] No newline at end of file\n    |\n395 |             return adv_loss\n396 |         \n397 |         return loss\n    |                    ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/training/metrics.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n  |\n1 |   \"\"\"Evaluation metrics for DGDN training.\"\"\"\n2 |\n3 | / import torch\n4 | | import numpy as np\n5 | | from typing import Dict, List, Optional, Tuple\n6 | | from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, f1_score\n7 | | import torch.nn.functional as F\n  | |_______________________________^ I001\n  |\n  = help: Organize imports\n\nsrc/dgdn/training/metrics.py:5:42: F401 [*] `typing.Tuple` imported but unused\n  |\n3 | import torch\n4 | import numpy as np\n5 | from typing import Dict, List, Optional, Tuple\n  |                                          ^^^^^ F401\n6 | from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, f1_score\n7 | import torch.nn.functional as F\n  |\n  = help: Remove unused import: `typing.Tuple`\n\nsrc/dgdn/training/metrics.py:12:1: W293 [*] Blank line contains whitespace\n   |\n10 | class DGDNMetrics:\n11 |     \"\"\"Comprehensive metrics for DGDN evaluation.\"\"\"\n12 |     \n   | ^^^^ W293\n13 |     def __init__(self, task: str = \"edge_prediction\"):\n14 |         self.task = task\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:16:1: W293 [*] Blank line contains whitespace\n   |\n14 |         self.task = task\n15 |         self.reset()\n16 |     \n   | ^^^^ W293\n17 |     def reset(self):\n18 |         \"\"\"Reset all metrics.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:23:1: W293 [*] Blank line contains whitespace\n   |\n21 |         self.uncertainties = []\n22 |         self.losses = []\n23 |     \n   | ^^^^ W293\n24 |     def update(\n25 |         self,\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:34:1: W293 [*] Blank line contains whitespace\n   |\n32 |         self.predictions.append(predictions.detach().cpu())\n33 |         self.targets.append(targets.detach().cpu())\n34 |         \n   | ^^^^^^^^ W293\n35 |         if uncertainties is not None:\n36 |             self.uncertainties.append(uncertainties.detach().cpu())\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:37:1: W293 [*] Blank line contains whitespace\n   |\n35 |         if uncertainties is not None:\n36 |             self.uncertainties.append(uncertainties.detach().cpu())\n37 |         \n   | ^^^^^^^^ W293\n38 |         if loss is not None:\n39 |             self.losses.append(loss)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:40:1: W293 [*] Blank line contains whitespace\n   |\n38 |         if loss is not None:\n39 |             self.losses.append(loss)\n40 |     \n   | ^^^^ W293\n41 |     def compute(self) -> Dict[str, float]:\n42 |         \"\"\"Compute all metrics.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:45:1: W293 [*] Blank line contains whitespace\n   |\n43 |         if not self.predictions:\n44 |             return {}\n45 |         \n   | ^^^^^^^^ W293\n46 |         # Concatenate all batches\n47 |         predictions = torch.cat(self.predictions, dim=0)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:49:1: W293 [*] Blank line contains whitespace\n   |\n47 |         predictions = torch.cat(self.predictions, dim=0)\n48 |         targets = torch.cat(self.targets, dim=0)\n49 |         \n   | ^^^^^^^^ W293\n50 |         metrics = {}\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:51:1: W293 [*] Blank line contains whitespace\n   |\n50 |         metrics = {}\n51 |         \n   | ^^^^^^^^ W293\n52 |         # Loss metrics\n53 |         if self.losses:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:55:1: W293 [*] Blank line contains whitespace\n   |\n53 |         if self.losses:\n54 |             metrics[\"loss\"] = np.mean(self.losses)\n55 |         \n   | ^^^^^^^^ W293\n56 |         # Task-specific metrics\n57 |         if self.task == \"edge_prediction\":\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:61:1: W293 [*] Blank line contains whitespace\n   |\n59 |         elif self.task == \"node_classification\":\n60 |             metrics.update(self._compute_node_classification_metrics(predictions, targets))\n61 |         \n   | ^^^^^^^^ W293\n62 |         # Uncertainty metrics\n63 |         if self.uncertainties:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:66:1: W293 [*] Blank line contains whitespace\n   |\n64 |             uncertainties = torch.cat(self.uncertainties, dim=0)\n65 |             metrics.update(self._compute_uncertainty_metrics(predictions, targets, uncertainties))\n66 |         \n   | ^^^^^^^^ W293\n67 |         return metrics\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:68:1: W293 [*] Blank line contains whitespace\n   |\n67 |         return metrics\n68 |     \n   | ^^^^ W293\n69 |     def _compute_edge_prediction_metrics(\n70 |         self, \n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:70:14: W291 [*] Trailing whitespace\n   |\n69 |     def _compute_edge_prediction_metrics(\n70 |         self, \n   |              ^ W291\n71 |         predictions: torch.Tensor, \n72 |         targets: torch.Tensor\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/training/metrics.py:71:35: W291 [*] Trailing whitespace\n   |\n69 |     def _compute_edge_prediction_metrics(\n70 |         self, \n71 |         predictions: torch.Tensor, \n   |                                   ^ W291\n72 |         targets: torch.Tensor\n73 |     ) -> Dict[str, float]:\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/training/metrics.py:84:1: W293 [*] Blank line contains whitespace\n   |\n82 |             pred_probs = torch.sigmoid(predictions).numpy()\n83 |             pred_labels = (pred_probs > 0.5).astype(int)\n84 |         \n   | ^^^^^^^^ W293\n85 |         targets_np = targets.numpy()\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:86:1: W293 [*] Blank line contains whitespace\n   |\n85 |         targets_np = targets.numpy()\n86 |         \n   | ^^^^^^^^ W293\n87 |         metrics = {}\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:88:1: W293 [*] Blank line contains whitespace\n   |\n87 |         metrics = {}\n88 |         \n   | ^^^^^^^^ W293\n89 |         # AUC-ROC\n90 |         if len(np.unique(targets_np)) > 1:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:93:1: W293 [*] Blank line contains whitespace\n   |\n91 |             metrics[\"auc\"] = roc_auc_score(targets_np, pred_probs)\n92 |             metrics[\"ap\"] = average_precision_score(targets_np, pred_probs)\n93 |         \n   | ^^^^^^^^ W293\n94 |         # Accuracy\n95 |         metrics[\"accuracy\"] = accuracy_score(targets_np, pred_labels)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:96:1: W293 [*] Blank line contains whitespace\n   |\n94 |         # Accuracy\n95 |         metrics[\"accuracy\"] = accuracy_score(targets_np, pred_labels)\n96 |         \n   | ^^^^^^^^ W293\n97 |         # F1 Score\n98 |         metrics[\"f1\"] = f1_score(targets_np, pred_labels, average='binary')\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:99:1: W293 [*] Blank line contains whitespace\n    |\n 97 |         # F1 Score\n 98 |         metrics[\"f1\"] = f1_score(targets_np, pred_labels, average='binary')\n 99 |         \n    | ^^^^^^^^ W293\n100 |         # Mean Reciprocal Rank (MRR)\n101 |         if len(pred_probs) > 1:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:107:1: W293 [*] Blank line contains whitespace\n    |\n105 |                 mrr = np.mean(1.0 / (ranks + 1))\n106 |                 metrics[\"mrr\"] = mrr\n107 |         \n    | ^^^^^^^^ W293\n108 |         return metrics\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:109:1: W293 [*] Blank line contains whitespace\n    |\n108 |         return metrics\n109 |     \n    | ^^^^ W293\n110 |     def _compute_node_classification_metrics(\n111 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:118:1: W293 [*] Blank line contains whitespace\n    |\n116 |         pred_labels = torch.argmax(predictions, dim=-1).numpy()\n117 |         targets_np = targets.numpy()\n118 |         \n    | ^^^^^^^^ W293\n119 |         metrics = {\n120 |             \"accuracy\": accuracy_score(targets_np, pred_labels),\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:124:1: W293 [*] Blank line contains whitespace\n    |\n122 |             \"f1_macro\": f1_score(targets_np, pred_labels, average='macro'),\n123 |         }\n124 |         \n    | ^^^^^^^^ W293\n125 |         # Multi-class AUC if applicable\n126 |         if predictions.shape[-1] > 2:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:134:1: W293 [*] Blank line contains whitespace\n    |\n132 |             except ValueError:\n133 |                 pass  # Skip if not enough classes\n134 |         \n    | ^^^^^^^^ W293\n135 |         return metrics\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:136:1: W293 [*] Blank line contains whitespace\n    |\n135 |         return metrics\n136 |     \n    | ^^^^ W293\n137 |     def _compute_uncertainty_metrics(\n138 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:145:1: W293 [*] Blank line contains whitespace\n    |\n143 |         \"\"\"Compute uncertainty calibration metrics.\"\"\"\n144 |         uncertainties_np = uncertainties.numpy()\n145 |         \n    | ^^^^^^^^ W293\n146 |         metrics = {\n147 |             \"mean_uncertainty\": np.mean(uncertainties_np),\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:150:1: W293 [*] Blank line contains whitespace\n    |\n148 |             \"std_uncertainty\": np.std(uncertainties_np)\n149 |         }\n150 |         \n    | ^^^^^^^^ W293\n151 |         # Calibration metrics\n152 |         if self.task == \"edge_prediction\":\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:155:1: W293 [*] Blank line contains whitespace\n    |\n153 |             pred_probs = torch.sigmoid(predictions).numpy()\n154 |             targets_np = targets.numpy()\n155 |             \n    | ^^^^^^^^^^^^ W293\n156 |             # Expected Calibration Error (ECE)\n157 |             ece = self._compute_ece(pred_probs, targets_np, uncertainties_np)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:159:1: W293 [*] Blank line contains whitespace\n    |\n157 |             ece = self._compute_ece(pred_probs, targets_np, uncertainties_np)\n158 |             metrics[\"ece\"] = ece\n159 |             \n    | ^^^^^^^^^^^^ W293\n160 |             # Reliability metrics\n161 |             reliability = self._compute_reliability(pred_probs, targets_np, uncertainties_np)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:163:1: W293 [*] Blank line contains whitespace\n    |\n161 |             reliability = self._compute_reliability(pred_probs, targets_np, uncertainties_np)\n162 |             metrics.update(reliability)\n163 |         \n    | ^^^^^^^^ W293\n164 |         return metrics\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:165:1: W293 [*] Blank line contains whitespace\n    |\n164 |         return metrics\n165 |     \n    | ^^^^ W293\n166 |     def _compute_ece(\n167 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:177:1: W293 [*] Blank line contains whitespace\n    |\n175 |         bin_lowers = bin_boundaries[:-1]\n176 |         bin_uppers = bin_boundaries[1:]\n177 |         \n    | ^^^^^^^^ W293\n178 |         ece = 0\n179 |         for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:183:1: W293 [*] Blank line contains whitespace\n    |\n181 |             in_bin = (confidences > bin_lower) & (confidences <= bin_upper)\n182 |             prop_in_bin = in_bin.mean()\n183 |             \n    | ^^^^^^^^^^^^ W293\n184 |             if prop_in_bin > 0:\n185 |                 accuracy_in_bin = accuracies[in_bin].mean()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:188:1: W293 [*] Blank line contains whitespace\n    |\n186 |                 avg_confidence_in_bin = confidences[in_bin].mean()\n187 |                 ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n188 |         \n    | ^^^^^^^^ W293\n189 |         return ece\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:190:1: W293 [*] Blank line contains whitespace\n    |\n189 |         return ece\n190 |     \n    | ^^^^ W293\n191 |     def _compute_reliability(\n192 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:200:1: W293 [*] Blank line contains whitespace\n    |\n198 |         # Prediction accuracy vs uncertainty correlation\n199 |         errors = np.abs(predictions - targets)\n200 |         \n    | ^^^^^^^^ W293\n201 |         # Handle shape mismatch\n202 |         if errors.shape != uncertainties.shape:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:209:1: W293 [*] Blank line contains whitespace\n    |\n207 |             errors = errors[:min_len]\n208 |             uncertainties = uncertainties[:min_len]\n209 |         \n    | ^^^^^^^^ W293\n210 |         try:\n211 |             if len(errors) > 1 and len(uncertainties) > 1:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:217:1: W293 [*] Blank line contains whitespace\n    |\n215 |         except Exception:\n216 |             correlation = 0.0\n217 |         \n    | ^^^^^^^^ W293\n218 |         return {\n219 |             \"uncertainty_error_correlation\": correlation if not np.isnan(correlation) else 0.0,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:227:1: W293 [*] Blank line contains whitespace\n    |\n225 | class EdgePredictionMetrics(DGDNMetrics):\n226 |     \"\"\"Specialized metrics for edge prediction tasks.\"\"\"\n227 |     \n    | ^^^^ W293\n228 |     def __init__(self):\n229 |         super().__init__(task=\"edge_prediction\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:230:1: W293 [*] Blank line contains whitespace\n    |\n228 |     def __init__(self):\n229 |         super().__init__(task=\"edge_prediction\")\n230 |     \n    | ^^^^ W293\n231 |     def compute_ranking_metrics(\n232 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:235:31: B006 Do not use mutable data structures for argument defaults\n    |\n233 |         predictions: torch.Tensor,\n234 |         targets: torch.Tensor,\n235 |         k_values: List[int] = [1, 5, 10, 20]\n    |                               ^^^^^^^^^^^^^^ B006\n236 |     ) -> Dict[str, float]:\n237 |         \"\"\"Compute ranking-based metrics.\"\"\"\n    |\n    = help: Replace with `None`; initialize within function\n\nsrc/dgdn/training/metrics.py:240:1: W293 [*] Blank line contains whitespace\n    |\n238 |         pred_probs = torch.sigmoid(predictions).numpy()\n239 |         targets_np = targets.numpy()\n240 |         \n    | ^^^^^^^^ W293\n241 |         # Sort by prediction scores\n242 |         sorted_indices = np.argsort(-pred_probs)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:244:1: W293 [*] Blank line contains whitespace\n    |\n242 |         sorted_indices = np.argsort(-pred_probs)\n243 |         sorted_targets = targets_np[sorted_indices]\n244 |         \n    | ^^^^^^^^ W293\n245 |         metrics = {}\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:246:1: W293 [*] Blank line contains whitespace\n    |\n245 |         metrics = {}\n246 |         \n    | ^^^^^^^^ W293\n247 |         # Hits@K\n248 |         for k in k_values:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:252:1: W293 [*] Blank line contains whitespace\n    |\n250 |                 hits_at_k = np.sum(sorted_targets[:k]) / min(k, np.sum(targets_np))\n251 |                 metrics[f\"hits@{k}\"] = hits_at_k\n252 |         \n    | ^^^^^^^^ W293\n253 |         # NDCG@K\n254 |         for k in k_values:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:258:1: W293 [*] Blank line contains whitespace\n    |\n256 |                 ndcg_at_k = self._compute_ndcg(sorted_targets[:k])\n257 |                 metrics[f\"ndcg@{k}\"] = ndcg_at_k\n258 |         \n    | ^^^^^^^^ W293\n259 |         return metrics\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:260:1: W293 [*] Blank line contains whitespace\n    |\n259 |         return metrics\n260 |     \n    | ^^^^ W293\n261 |     def _compute_ndcg(self, relevance_scores: np.ndarray) -> float:\n262 |         \"\"\"Compute Normalized Discounted Cumulative Gain.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:265:1: W293 [*] Blank line contains whitespace\n    |\n263 |         if len(relevance_scores) == 0:\n264 |             return 0.0\n265 |         \n    | ^^^^^^^^ W293\n266 |         # DCG\n267 |         dcg = relevance_scores[0]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:270:1: W293 [*] Blank line contains whitespace\n    |\n268 |         for i in range(1, len(relevance_scores)):\n269 |             dcg += relevance_scores[i] / np.log2(i + 1)\n270 |         \n    | ^^^^^^^^ W293\n271 |         # IDCG (perfect ranking)\n272 |         ideal_relevance = np.sort(relevance_scores)[::-1]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:276:1: W293 [*] Blank line contains whitespace\n    |\n274 |         for i in range(1, len(ideal_relevance)):\n275 |             idcg += ideal_relevance[i] / np.log2(i + 1)\n276 |         \n    | ^^^^^^^^ W293\n277 |         return dcg / idcg if idcg > 0 else 0.0\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:282:1: W293 [*] Blank line contains whitespace\n    |\n280 | class NodeClassificationMetrics(DGDNMetrics):\n281 |     \"\"\"Specialized metrics for node classification tasks.\"\"\"\n282 |     \n    | ^^^^ W293\n283 |     def __init__(self, num_classes: int = 2):\n284 |         super().__init__(task=\"node_classification\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:286:1: W293 [*] Blank line contains whitespace\n    |\n284 |         super().__init__(task=\"node_classification\")\n285 |         self.num_classes = num_classes\n286 |     \n    | ^^^^ W293\n287 |     def compute_per_class_metrics(\n288 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:295:1: W293 [*] Blank line contains whitespace\n    |\n293 |         pred_labels = torch.argmax(predictions, dim=-1).numpy()\n294 |         targets_np = targets.numpy()\n295 |         \n    | ^^^^^^^^ W293\n296 |         metrics = {}\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:297:1: W293 [*] Blank line contains whitespace\n    |\n296 |         metrics = {}\n297 |         \n    | ^^^^^^^^ W293\n298 |         for class_id in range(self.num_classes):\n299 |             class_mask = targets_np == class_id\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:303:1: W293 [*] Blank line contains whitespace\n    |\n301 |                 class_pred = pred_labels[class_mask]\n302 |                 class_target = targets_np[class_mask]\n303 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n304 |                 accuracy = accuracy_score(class_target, class_pred)\n305 |                 metrics[f\"class_{class_id}_accuracy\"] = accuracy\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:306:1: W293 [*] Blank line contains whitespace\n    |\n304 |                 accuracy = accuracy_score(class_target, class_pred)\n305 |                 metrics[f\"class_{class_id}_accuracy\"] = accuracy\n306 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n307 |                 # Precision and Recall\n308 |                 if len(np.unique(class_pred)) > 1:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:311:1: W293 [*] Blank line contains whitespace\n    |\n309 |                     f1 = f1_score(class_target, class_pred, average='binary', pos_label=class_id)\n310 |                     metrics[f\"class_{class_id}_f1\"] = f1\n311 |         \n    | ^^^^^^^^ W293\n312 |         return metrics\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:317:1: W293 [*] Blank line contains whitespace\n    |\n315 | class TemporalMetrics:\n316 |     \"\"\"Metrics for evaluating temporal aspects of predictions.\"\"\"\n317 |     \n    | ^^^^ W293\n318 |     def __init__(self):\n319 |         self.temporal_predictions = []\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:322:1: W293 [*] Blank line contains whitespace\n    |\n320 |         self.temporal_targets = []\n321 |         self.timestamps = []\n322 |     \n    | ^^^^ W293\n323 |     def update(\n324 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:333:1: W293 [*] Blank line contains whitespace\n    |\n331 |         self.temporal_targets.append(targets.detach().cpu())\n332 |         self.timestamps.append(timestamps.detach().cpu())\n333 |     \n    | ^^^^ W293\n334 |     def compute_temporal_stability(self) -> Dict[str, float]:\n335 |         \"\"\"Compute temporal stability metrics.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:338:1: W293 [*] Blank line contains whitespace\n    |\n336 |         if not self.temporal_predictions:\n337 |             return {}\n338 |         \n    | ^^^^^^^^ W293\n339 |         predictions = torch.cat(self.temporal_predictions, dim=0)\n340 |         timestamps = torch.cat(self.timestamps, dim=0)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:341:1: W293 [*] Blank line contains whitespace\n    |\n339 |         predictions = torch.cat(self.temporal_predictions, dim=0)\n340 |         timestamps = torch.cat(self.timestamps, dim=0)\n341 |         \n    | ^^^^^^^^ W293\n342 |         # Sort by timestamp\n343 |         sorted_indices = torch.argsort(timestamps)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:345:1: W293 [*] Blank line contains whitespace\n    |\n343 |         sorted_indices = torch.argsort(timestamps)\n344 |         sorted_predictions = predictions[sorted_indices]\n345 |         \n    | ^^^^^^^^ W293\n346 |         # Compute prediction variance over time\n347 |         if len(sorted_predictions) > 1:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:351:1: W293 [*] Blank line contains whitespace\n    |\n349 |             temporal_variance = torch.var(pred_diffs).item()\n350 |             temporal_smoothness = torch.mean(torch.abs(pred_diffs)).item()\n351 |             \n    | ^^^^^^^^^^^^ W293\n352 |             return {\n353 |                 \"temporal_variance\": temporal_variance,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:356:1: W293 [*] Blank line contains whitespace\n    |\n354 |                 \"temporal_smoothness\": temporal_smoothness\n355 |             }\n356 |         \n    | ^^^^^^^^ W293\n357 |         return {}\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:358:1: W293 [*] Blank line contains whitespace\n    |\n357 |         return {}\n358 |     \n    | ^^^^ W293\n359 |     def compute_prediction_drift(self, window_size: int = 100) -> Dict[str, float]:\n360 |         \"\"\"Compute prediction drift over time windows.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:363:1: W293 [*] Blank line contains whitespace\n    |\n361 |         if not self.temporal_predictions:\n362 |             return {}\n363 |         \n    | ^^^^^^^^ W293\n364 |         predictions = torch.cat(self.temporal_predictions, dim=0)\n365 |         timestamps = torch.cat(self.timestamps, dim=0)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:366:1: W293 [*] Blank line contains whitespace\n    |\n364 |         predictions = torch.cat(self.temporal_predictions, dim=0)\n365 |         timestamps = torch.cat(self.timestamps, dim=0)\n366 |         \n    | ^^^^^^^^ W293\n367 |         # Sort by timestamp\n368 |         sorted_indices = torch.argsort(timestamps)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:370:1: W293 [*] Blank line contains whitespace\n    |\n368 |         sorted_indices = torch.argsort(timestamps)\n369 |         sorted_predictions = predictions[sorted_indices]\n370 |         \n    | ^^^^^^^^ W293\n371 |         if len(sorted_predictions) < window_size * 2:\n372 |             return {}\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:373:1: W293 [*] Blank line contains whitespace\n    |\n371 |         if len(sorted_predictions) < window_size * 2:\n372 |             return {}\n373 |         \n    | ^^^^^^^^ W293\n374 |         # Compare early and late windows\n375 |         early_window = sorted_predictions[:window_size]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:377:1: W293 [*] Blank line contains whitespace\n    |\n375 |         early_window = sorted_predictions[:window_size]\n376 |         late_window = sorted_predictions[-window_size:]\n377 |         \n    | ^^^^^^^^ W293\n378 |         # Compute drift metrics\n379 |         mean_drift = torch.abs(torch.mean(late_window) - torch.mean(early_window)).item()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:381:1: W293 [*] Blank line contains whitespace\n    |\n379 |         mean_drift = torch.abs(torch.mean(late_window) - torch.mean(early_window)).item()\n380 |         std_drift = torch.abs(torch.std(late_window) - torch.std(early_window)).item()\n381 |         \n    | ^^^^^^^^ W293\n382 |         return {\n383 |             \"mean_drift\": mean_drift,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:390:1: W293 [*] Blank line contains whitespace\n    |\n388 | class UncertaintyMetrics:\n389 |     \"\"\"Specialized metrics for uncertainty quantification.\"\"\"\n390 |     \n    | ^^^^ W293\n391 |     def __init__(self):\n392 |         self.predictions = []\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:395:1: W293 [*] Blank line contains whitespace\n    |\n393 |         self.uncertainties = []\n394 |         self.targets = []\n395 |     \n    | ^^^^ W293\n396 |     def update(\n397 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:406:1: W293 [*] Blank line contains whitespace\n    |\n404 |         self.uncertainties.append(uncertainties.detach().cpu())\n405 |         self.targets.append(targets.detach().cpu())\n406 |     \n    | ^^^^ W293\n407 |     def compute_calibration_metrics(self) -> Dict[str, float]:\n408 |         \"\"\"Compute uncertainty calibration metrics.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:411:1: W293 [*] Blank line contains whitespace\n    |\n409 |         if not self.predictions:\n410 |             return {}\n411 |         \n    | ^^^^^^^^ W293\n412 |         predictions = torch.cat(self.predictions, dim=0)\n413 |         uncertainties = torch.cat(self.uncertainties, dim=0)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:415:1: W293 [*] Blank line contains whitespace\n    |\n413 |         uncertainties = torch.cat(self.uncertainties, dim=0)\n414 |         targets = torch.cat(self.targets, dim=0)\n415 |         \n    | ^^^^^^^^ W293\n416 |         # Convert to numpy\n417 |         pred_np = predictions.numpy()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:420:1: W293 [*] Blank line contains whitespace\n    |\n418 |         unc_np = uncertainties.numpy()\n419 |         targets_np = targets.numpy()\n420 |         \n    | ^^^^^^^^ W293\n421 |         # Compute errors\n422 |         errors = np.abs(pred_np - targets_np)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:423:1: W293 [*] Blank line contains whitespace\n    |\n421 |         # Compute errors\n422 |         errors = np.abs(pred_np - targets_np)\n423 |         \n    | ^^^^^^^^ W293\n424 |         # Uncertainty-error correlation\n425 |         correlation = np.corrcoef(errors, unc_np)[0, 1]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:426:1: W293 [*] Blank line contains whitespace\n    |\n424 |         # Uncertainty-error correlation\n425 |         correlation = np.corrcoef(errors, unc_np)[0, 1]\n426 |         \n    | ^^^^^^^^ W293\n427 |         # Calibration curve\n428 |         n_bins = 10\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:430:1: W293 [*] Blank line contains whitespace\n    |\n428 |         n_bins = 10\n429 |         bin_edges = np.percentile(unc_np, np.linspace(0, 100, n_bins + 1))\n430 |         \n    | ^^^^^^^^ W293\n431 |         calibration_error = 0.0\n432 |         for i in range(n_bins):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:438:1: W293 [*] Blank line contains whitespace\n    |\n436 |                 bin_error = np.mean(errors[mask])\n437 |                 calibration_error += np.abs(bin_uncertainty - bin_error)\n438 |         \n    | ^^^^^^^^ W293\n439 |         calibration_error /= n_bins\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:440:1: W293 [*] Blank line contains whitespace\n    |\n439 |         calibration_error /= n_bins\n440 |         \n    | ^^^^^^^^ W293\n441 |         return {\n442 |             \"uncertainty_error_correlation\": correlation if not np.isnan(correlation) else 0.0,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/metrics.py:446:10: W292 [*] No newline at end of file\n    |\n444 |             \"mean_uncertainty\": np.mean(unc_np),\n445 |             \"mean_error\": np.mean(errors)\n446 |         }\n    |          ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/training/trainer.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n   |\n 1 |   \"\"\"DGDN training pipeline implementation.\"\"\"\n 2 |\n 3 | / import torch\n 4 | | import torch.nn as nn\n 5 | | import torch.optim as optim\n 6 | | # from torch.utils.tensorboard import SummaryWriter  # Optional dependency\n 7 | | import numpy as np\n 8 | | import time\n 9 | | import os\n10 | | from typing import Dict, Optional, List, Tuple, Any, Callable\n11 | | from tqdm import tqdm\n12 | | import warnings\n13 | | import logging\n14 | | from pathlib import Path\n15 | |\n16 | | from ..models import DynamicGraphDiffusionNet\n17 | | from ..data import TemporalDataset, create_data_loaders\n18 | | from .losses import DGDNLoss\n19 | | from .metrics import DGDNMetrics, EdgePredictionMetrics, NodeClassificationMetrics\n20 | | from ..optimization import MixedPrecisionTrainer, MemoryOptimizer, ParallelismManager, CacheManager\n   | |___________________________________________________________________________________________________^ I001\n   |\n   = help: Organize imports\n\nsrc/dgdn/training/trainer.py:4:20: F401 [*] `torch.nn` imported but unused\n  |\n3 | import torch\n4 | import torch.nn as nn\n  |                    ^^ F401\n5 | import torch.optim as optim\n6 | # from torch.utils.tensorboard import SummaryWriter  # Optional dependency\n  |\n  = help: Remove unused import: `torch.nn`\n\nsrc/dgdn/training/trainer.py:7:17: F401 [*] `numpy` imported but unused\n  |\n5 | import torch.optim as optim\n6 | # from torch.utils.tensorboard import SummaryWriter  # Optional dependency\n7 | import numpy as np\n  |                 ^^ F401\n8 | import time\n9 | import os\n  |\n  = help: Remove unused import: `numpy`\n\nsrc/dgdn/training/trainer.py:8:8: F401 [*] `time` imported but unused\n   |\n 6 | # from torch.utils.tensorboard import SummaryWriter  # Optional dependency\n 7 | import numpy as np\n 8 | import time\n   |        ^^^^ F401\n 9 | import os\n10 | from typing import Dict, Optional, List, Tuple, Any, Callable\n   |\n   = help: Remove unused import: `time`\n\nsrc/dgdn/training/trainer.py:10:42: F401 [*] `typing.Tuple` imported but unused\n   |\n 8 | import time\n 9 | import os\n10 | from typing import Dict, Optional, List, Tuple, Any, Callable\n   |                                          ^^^^^ F401\n11 | from tqdm import tqdm\n12 | import warnings\n   |\n   = help: Remove unused import\n\nsrc/dgdn/training/trainer.py:10:49: F401 [*] `typing.Any` imported but unused\n   |\n 8 | import time\n 9 | import os\n10 | from typing import Dict, Optional, List, Tuple, Any, Callable\n   |                                                 ^^^ F401\n11 | from tqdm import tqdm\n12 | import warnings\n   |\n   = help: Remove unused import\n\nsrc/dgdn/training/trainer.py:10:54: F401 [*] `typing.Callable` imported but unused\n   |\n 8 | import time\n 9 | import os\n10 | from typing import Dict, Optional, List, Tuple, Any, Callable\n   |                                                      ^^^^^^^^ F401\n11 | from tqdm import tqdm\n12 | import warnings\n   |\n   = help: Remove unused import\n\nsrc/dgdn/training/trainer.py:25:1: W293 Blank line contains whitespace\n   |\n23 | class DGDNTrainer:\n24 |     \"\"\"Comprehensive trainer for DGDN models.\n25 |     \n   | ^^^^ W293\n26 |     Handles training, validation, testing, and model management with\n27 |     support for various tasks and advanced training techniques.\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:28:1: W293 Blank line contains whitespace\n   |\n26 |     Handles training, validation, testing, and model management with\n27 |     support for various tasks and advanced training techniques.\n28 |     \n   | ^^^^ W293\n29 |     Args:\n30 |         model: DGDN model to train\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:42:1: W293 [*] Blank line contains whitespace\n   |\n40 |         checkpoint_dir: Directory for model checkpoints\n41 |     \"\"\"\n42 |     \n   | ^^^^ W293\n43 |     def __init__(\n44 |         self,\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:62:1: W293 [*] Blank line contains whitespace\n   |\n60 |         self.weight_decay = weight_decay\n61 |         self.task = task\n62 |         \n   | ^^^^^^^^ W293\n63 |         # Device setup\n64 |         if device is None:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:68:1: W293 [*] Blank line contains whitespace\n   |\n66 |         else:\n67 |             self.device = device\n68 |         \n   | ^^^^^^^^ W293\n69 |         self.model.to(self.device)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:70:1: W293 [*] Blank line contains whitespace\n   |\n69 |         self.model.to(self.device)\n70 |         \n   | ^^^^^^^^ W293\n71 |         # Setup optimizer\n72 |         self.optimizer = self._setup_optimizer(optimizer_type)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:73:1: W293 [*] Blank line contains whitespace\n   |\n71 |         # Setup optimizer\n72 |         self.optimizer = self._setup_optimizer(optimizer_type)\n73 |         \n   | ^^^^^^^^ W293\n74 |         # Setup scheduler\n75 |         self.scheduler = self._setup_scheduler(scheduler_type) if scheduler_type else None\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:76:1: W293 [*] Blank line contains whitespace\n   |\n74 |         # Setup scheduler\n75 |         self.scheduler = self._setup_scheduler(scheduler_type) if scheduler_type else None\n76 |         \n   | ^^^^^^^^ W293\n77 |         # Setup loss function\n78 |         self.loss_fn = DGDNLoss(\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:83:1: W293 [*] Blank line contains whitespace\n   |\n81 |             task=task\n82 |         )\n83 |         \n   | ^^^^^^^^ W293\n84 |         # Setup metrics\n85 |         if task == \"edge_prediction\":\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:91:1: W293 [*] Blank line contains whitespace\n   |\n89 |         else:\n90 |             self.metrics = DGDNMetrics(task=task)\n91 |         \n   | ^^^^^^^^ W293\n92 |         # Logging and checkpointing\n93 |         self.log_dir = log_dir\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:97:1: W293 [*] Blank line contains whitespace\n   |\n95 |         os.makedirs(log_dir, exist_ok=True)\n96 |         os.makedirs(checkpoint_dir, exist_ok=True)\n97 |         \n   | ^^^^^^^^ W293\n98 |         self.writer = SummaryWriter(log_dir)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:98:23: F821 Undefined name `SummaryWriter`\n    |\n 96 |         os.makedirs(checkpoint_dir, exist_ok=True)\n 97 |         \n 98 |         self.writer = SummaryWriter(log_dir)\n    |                       ^^^^^^^^^^^^^ F821\n 99 |         \n100 |         # Training state\n    |\n\nsrc/dgdn/training/trainer.py:99:1: W293 [*] Blank line contains whitespace\n    |\n 98 |         self.writer = SummaryWriter(log_dir)\n 99 |         \n    | ^^^^^^^^ W293\n100 |         # Training state\n101 |         self.current_epoch = 0\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:106:1: W293 [*] Blank line contains whitespace\n    |\n104 |         self.early_stopping_patience = None\n105 |         self.early_stopping_counter = 0\n106 |         \n    | ^^^^^^^^ W293\n107 |         # Setup logging\n108 |         self.logger = self._setup_logger()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:109:1: W293 [*] Blank line contains whitespace\n    |\n107 |         # Setup logging\n108 |         self.logger = self._setup_logger()\n109 |         \n    | ^^^^^^^^ W293\n110 |         # Security and validation\n111 |         self._validate_init_parameters(learning_rate, weight_decay, diffusion_loss_weight, temporal_reg_weight)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:112:1: W293 [*] Blank line contains whitespace\n    |\n110 |         # Security and validation\n111 |         self._validate_init_parameters(learning_rate, weight_decay, diffusion_loss_weight, temporal_reg_weight)\n112 |         \n    | ^^^^^^^^ W293\n113 |         # Performance optimization setup\n114 |         optimization_config = kwargs.get('optimization', {})\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:118:1: W293 [*] Blank line contains whitespace\n    |\n116 |         self.enable_caching = optimization_config.get('caching', True)\n117 |         self.enable_memory_optimization = optimization_config.get('memory_optimization', True)\n118 |         \n    | ^^^^^^^^ W293\n119 |         # Initialize optimization components\n120 |         self.mixed_precision = MixedPrecisionTrainer(self.enable_mixed_precision)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:124:1: W293 [*] Blank line contains whitespace\n    |\n122 |         self.parallelism_manager = ParallelismManager(self.model)\n123 |         self.cache_manager = CacheManager() if self.enable_caching else None\n124 |         \n    | ^^^^^^^^ W293\n125 |         self.logger.info(f\"Initialized DGDN trainer for {task} task\")\n126 |         self.logger.info(f\"Device: {self.device}, Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:129:1: W293 [*] Blank line contains whitespace\n    |\n127 |         self.logger.info(f\"Optimizations: Mixed Precision={self.enable_mixed_precision}, \"\n128 |                         f\"Caching={self.enable_caching}, Memory Opt={self.enable_memory_optimization}\")\n129 |         \n    | ^^^^^^^^ W293\n130 |     def _setup_optimizer(self, optimizer_type: str) -> optim.Optimizer:\n131 |         \"\"\"Setup optimizer.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:153:1: W293 [*] Blank line contains whitespace\n    |\n151 |         else:\n152 |             raise ValueError(f\"Unknown optimizer type: {optimizer_type}\")\n153 |     \n    | ^^^^ W293\n154 |     def _setup_scheduler(self, scheduler_type: str) -> Optional[optim.lr_scheduler._LRScheduler]:\n155 |         \"\"\"Setup learning rate scheduler.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:170:13: B028 No explicit `stacklevel` keyword argument found\n    |\n168 |             )\n169 |         else:\n170 |             warnings.warn(f\"Unknown scheduler type: {scheduler_type}\")\n    |             ^^^^^^^^^^^^^ B028\n171 |             return None\n    |\n    = help: Set `stacklevel=2`\n\nsrc/dgdn/training/trainer.py:172:1: W293 [*] Blank line contains whitespace\n    |\n170 |             warnings.warn(f\"Unknown scheduler type: {scheduler_type}\")\n171 |             return None\n172 |     \n    | ^^^^ W293\n173 |     def fit(\n174 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:184:1: W293 Blank line contains whitespace\n    |\n182 |     ) -> Dict[str, List[float]]:\n183 |         \"\"\"Train the DGDN model.\n184 |         \n    | ^^^^^^^^ W293\n185 |         Args:\n186 |             train_data: Training dataset\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:193:1: W293 Blank line contains whitespace\n    |\n191 |             save_best: Whether to save best model\n192 |             verbose: Whether to print progress\n193 |             \n    | ^^^^^^^^^^^^ W293\n194 |         Returns:\n195 |             Training history dictionary\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:198:1: W293 [*] Blank line contains whitespace\n    |\n196 |         \"\"\"\n197 |         self.early_stopping_patience = early_stopping_patience\n198 |         \n    | ^^^^^^^^ W293\n199 |         # Validate training data\n200 |         self._validate_training_data(train_data, val_data)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:201:1: W293 [*] Blank line contains whitespace\n    |\n199 |         # Validate training data\n200 |         self._validate_training_data(train_data, val_data)\n201 |         \n    | ^^^^^^^^ W293\n202 |         # Create data loaders\n203 |         if hasattr(train_data, '_train_data') and train_data._train_data is not None:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:231:1: W293 [*] Blank line contains whitespace\n    |\n229 |             else:\n230 |                 val_loader = None\n231 |         \n    | ^^^^^^^^ W293\n232 |         # Training loop\n233 |         for epoch in range(epochs):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:235:1: W293 [*] Blank line contains whitespace\n    |\n233 |         for epoch in range(epochs):\n234 |             self.current_epoch = epoch\n235 |             \n    | ^^^^^^^^^^^^ W293\n236 |             # Training phase\n237 |             train_metrics = self._train_epoch(train_loader, verbose)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:239:1: W293 [*] Blank line contains whitespace\n    |\n237 |             train_metrics = self._train_epoch(train_loader, verbose)\n238 |             self.training_history[\"train\"].append(train_metrics)\n239 |             \n    | ^^^^^^^^^^^^ W293\n240 |             # Validation phase\n241 |             if val_data is not None:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:244:1: W293 [*] Blank line contains whitespace\n    |\n242 |                 val_metrics = self._validate_epoch(val_loader, verbose)\n243 |                 self.training_history[\"val\"].append(val_metrics)\n244 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n245 |                 # Early stopping and best model saving\n246 |                 if self._should_stop_early(val_metrics, save_best):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:250:1: W293 [*] Blank line contains whitespace\n    |\n248 |                         print(f\"Early stopping at epoch {epoch}\")\n249 |                     break\n250 |             \n    | ^^^^^^^^^^^^ W293\n251 |             # Update learning rate scheduler\n252 |             if self.scheduler is not None:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:259:1: W293 [*] Blank line contains whitespace\n    |\n257 |                 else:\n258 |                     self.scheduler.step()\n259 |             \n    | ^^^^^^^^^^^^ W293\n260 |             # Log metrics\n261 |             self._log_metrics(train_metrics, val_metrics if val_data else None, epoch)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:262:1: W293 [*] Blank line contains whitespace\n    |\n260 |             # Log metrics\n261 |             self._log_metrics(train_metrics, val_metrics if val_data else None, epoch)\n262 |             \n    | ^^^^^^^^^^^^ W293\n263 |             if verbose and epoch % 10 == 0:\n264 |                 self._print_progress(epoch, train_metrics, val_metrics if val_data else None)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:265:1: W293 [*] Blank line contains whitespace\n    |\n263 |             if verbose and epoch % 10 == 0:\n264 |                 self._print_progress(epoch, train_metrics, val_metrics if val_data else None)\n265 |         \n    | ^^^^^^^^ W293\n266 |         self.writer.close()\n267 |         return self.training_history\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:268:1: W293 [*] Blank line contains whitespace\n    |\n266 |         self.writer.close()\n267 |         return self.training_history\n268 |     \n    | ^^^^ W293\n269 |     def _train_epoch(self, train_loader, verbose: bool = True) -> Dict[str, float]:\n270 |         \"\"\"Train for one epoch.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:273:1: W293 [*] Blank line contains whitespace\n    |\n271 |         self.model.train()\n272 |         self.metrics.reset()\n273 |         \n    | ^^^^^^^^ W293\n274 |         epoch_losses = []\n275 |         progress_bar = tqdm(train_loader, desc=f\"Epoch {self.current_epoch}\") if verbose else train_loader\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:276:1: W293 [*] Blank line contains whitespace\n    |\n274 |         epoch_losses = []\n275 |         progress_bar = tqdm(train_loader, desc=f\"Epoch {self.current_epoch}\") if verbose else train_loader\n276 |         \n    | ^^^^^^^^ W293\n277 |         for batch_idx, batch_data in enumerate(progress_bar):\n278 |             # Move data to device\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:280:1: W293 [*] Blank line contains whitespace\n    |\n278 |             # Move data to device\n279 |             batch_data = batch_data.to(self.device)\n280 |             \n    | ^^^^^^^^^^^^ W293\n281 |             # Zero gradients\n282 |             self.optimizer.zero_grad()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:283:1: W293 [*] Blank line contains whitespace\n    |\n281 |             # Zero gradients\n282 |             self.optimizer.zero_grad()\n283 |             \n    | ^^^^^^^^^^^^ W293\n284 |             # Forward pass with mixed precision\n285 |             try:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:288:1: W293 [*] Blank line contains whitespace\n    |\n286 |                 with self.mixed_precision.autocast_context():\n287 |                     output = self.model(batch_data, return_uncertainty=True)\n288 |                     \n    | ^^^^^^^^^^^^^^^^^^^^ W293\n289 |                     # Compute loss\n290 |                     if self.task == \"edge_prediction\":\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:296:1: W293 [*] Blank line contains whitespace\n    |\n294 |                         targets = getattr(batch_data, 'y', torch.zeros(batch_data.num_nodes, dtype=torch.long))\n295 |                         loss_dict = self.loss_fn(output, targets)\n296 |                     \n    | ^^^^^^^^^^^^^^^^^^^^ W293\n297 |                     loss = loss_dict[\"total\"]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:298:1: W293 [*] Blank line contains whitespace\n    |\n297 |                     loss = loss_dict[\"total\"]\n298 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n299 |                 # Backward pass with gradient scaling\n300 |                 scaled_loss = self.mixed_precision.scale_loss(loss)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:302:1: W293 [*] Blank line contains whitespace\n    |\n300 |                 scaled_loss = self.mixed_precision.scale_loss(loss)\n301 |                 scaled_loss.backward()\n302 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n303 |                 # Gradient clipping\n304 |                 torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:305:1: W293 [*] Blank line contains whitespace\n    |\n303 |                 # Gradient clipping\n304 |                 torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n305 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n306 |                 # Optimizer step with mixed precision\n307 |                 self.mixed_precision.step_optimizer(self.optimizer)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:308:1: W293 [*] Blank line contains whitespace\n    |\n306 |                 # Optimizer step with mixed precision\n307 |                 self.mixed_precision.step_optimizer(self.optimizer)\n308 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n309 |                 # Update metrics\n310 |                 predictions = self._extract_predictions(output, batch_data)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:318:1: W293 [*] Blank line contains whitespace\n    |\n316 |                     loss=loss.item()\n317 |                 )\n318 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n319 |                 epoch_losses.append(loss.item())\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:320:1: W293 [*] Blank line contains whitespace\n    |\n319 |                 epoch_losses.append(loss.item())\n320 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n321 |                 # Memory cleanup if needed\n322 |                 if self.memory_optimizer and batch_idx % 10 == 0:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:326:1: W293 [*] Blank line contains whitespace\n    |\n324 |                     if memory_stats.get('ram_percent', 0) > 90:\n325 |                         self.memory_optimizer.cleanup_memory()\n326 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n327 |                 # Update progress bar\n328 |                 if verbose:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:336:1: W293 [*] Blank line contains whitespace\n    |\n334 |                         postfix[\"scale\"] = f\"{self.mixed_precision.get_scale():.0f}\"\n335 |                     progress_bar.set_postfix(postfix)\n336 |                     \n    | ^^^^^^^^^^^^^^^^^^^^ W293\n337 |             except Exception as e:\n338 |                 self.logger.error(f\"Error in batch {batch_idx}: {e}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:342:1: W293 [*] Blank line contains whitespace\n    |\n340 |                     torch.cuda.empty_cache()\n341 |                 continue\n342 |         \n    | ^^^^^^^^ W293\n343 |         return self.metrics.compute()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:344:1: W293 [*] Blank line contains whitespace\n    |\n343 |         return self.metrics.compute()\n344 |     \n    | ^^^^ W293\n345 |     def _validate_epoch(self, val_loader, verbose: bool = True) -> Dict[str, float]:\n346 |         \"\"\"Validate for one epoch.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:349:1: W293 [*] Blank line contains whitespace\n    |\n347 |         self.model.eval()\n348 |         val_metrics = DGDNMetrics(task=self.task)\n349 |         \n    | ^^^^^^^^ W293\n350 |         with torch.no_grad():\n351 |             for batch_data in val_loader:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:353:1: W293 [*] Blank line contains whitespace\n    |\n351 |             for batch_data in val_loader:\n352 |                 batch_data = batch_data.to(self.device)\n353 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n354 |                 try:\n355 |                     # Forward pass\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:357:1: W293 [*] Blank line contains whitespace\n    |\n355 |                     # Forward pass\n356 |                     output = self.model(batch_data, return_uncertainty=True)\n357 |                     \n    | ^^^^^^^^^^^^^^^^^^^^ W293\n358 |                     # Compute loss\n359 |                     if self.task == \"edge_prediction\":\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:365:1: W293 [*] Blank line contains whitespace\n    |\n363 |                         targets = getattr(batch_data, 'y', torch.zeros(batch_data.num_nodes, dtype=torch.long))\n364 |                         loss_dict = self.loss_fn(output, targets)\n365 |                     \n    | ^^^^^^^^^^^^^^^^^^^^ W293\n366 |                     # Update metrics\n367 |                     predictions = self._extract_predictions(output, batch_data)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:375:1: W293 [*] Blank line contains whitespace\n    |\n373 |                         loss=loss_dict[\"total\"].item()\n374 |                     )\n375 |                     \n    | ^^^^^^^^^^^^^^^^^^^^ W293\n376 |                 except Exception as e:\n377 |                     print(f\"Validation error: {e}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:379:1: W293 [*] Blank line contains whitespace\n    |\n377 |                     print(f\"Validation error: {e}\")\n378 |                     continue\n379 |         \n    | ^^^^^^^^ W293\n380 |         return val_metrics.compute()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:381:1: W293 [*] Blank line contains whitespace\n    |\n380 |         return val_metrics.compute()\n381 |     \n    | ^^^^ W293\n382 |     def _extract_predictions(self, model_output: Dict, batch_data) -> torch.Tensor:\n383 |         \"\"\"Extract predictions from model output based on task.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:388:1: W293 [*] Blank line contains whitespace\n    |\n386 |             node_embeddings = model_output[\"node_embeddings\"]\n387 |             edge_index = batch_data.edge_index\n388 |             \n    | ^^^^^^^^^^^^ W293\n389 |             src_embeddings = node_embeddings[edge_index[0]]\n390 |             tgt_embeddings = node_embeddings[edge_index[1]]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:391:1: W293 [*] Blank line contains whitespace\n    |\n389 |             src_embeddings = node_embeddings[edge_index[0]]\n390 |             tgt_embeddings = node_embeddings[edge_index[1]]\n391 |             \n    | ^^^^^^^^^^^^ W293\n392 |             # Simple dot product for edge prediction\n393 |             predictions = torch.sum(src_embeddings * tgt_embeddings, dim=-1)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:395:1: W293 [*] Blank line contains whitespace\n    |\n393 |             predictions = torch.sum(src_embeddings * tgt_embeddings, dim=-1)\n394 |             return predictions\n395 |         \n    | ^^^^^^^^ W293\n396 |         elif self.task == \"node_classification\":\n397 |             # Use model's node classifier\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:400:1: W293 [*] Blank line contains whitespace\n    |\n398 |             node_embeddings = model_output[\"node_embeddings\"]\n399 |             return self.model.node_classifier(node_embeddings)\n400 |         \n    | ^^^^^^^^ W293\n401 |         else:\n402 |             return model_output[\"node_embeddings\"]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:403:1: W293 [*] Blank line contains whitespace\n    |\n401 |         else:\n402 |             return model_output[\"node_embeddings\"]\n403 |     \n    | ^^^^ W293\n404 |     def _extract_uncertainties(self, model_output: Dict, batch_data, target_shape: torch.Size) -> Optional[torch.Tensor]:\n405 |         \"\"\"Extract uncertainties matching the prediction shape.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:409:1: W293 [*] Blank line contains whitespace\n    |\n407 |         if uncertainty is None:\n408 |             return None\n409 |         \n    | ^^^^^^^^ W293\n410 |         if self.task == \"edge_prediction\":\n411 |             # Extract uncertainties for edges\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:415:1: W293 [*] Blank line contains whitespace\n    |\n413 |             src_uncertainty = uncertainty[edge_index[0]]\n414 |             tgt_uncertainty = uncertainty[edge_index[1]]\n415 |             \n    | ^^^^^^^^^^^^ W293\n416 |             # Combine uncertainties (mean or sum) and flatten to 1D\n417 |             edge_uncertainty = (src_uncertainty + tgt_uncertainty) / 2\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:421:1: W293 [*] Blank line contains whitespace\n    |\n419 |                 edge_uncertainty = edge_uncertainty.mean(dim=-1)  # Average across feature dimension\n420 |             return edge_uncertainty\n421 |         \n    | ^^^^^^^^ W293\n422 |         elif self.task == \"node_classification\":\n423 |             # Return node uncertainties as is\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:425:1: W293 [*] Blank line contains whitespace\n    |\n423 |             # Return node uncertainties as is\n424 |             return uncertainty\n425 |         \n    | ^^^^^^^^ W293\n426 |         else:\n427 |             # Reshape to match target shape if needed\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:431:1: W293 [*] Blank line contains whitespace\n    |\n429 |                 return uncertainty.view(-1)[:target_shape.numel()].view(target_shape)\n430 |             return uncertainty\n431 |     \n    | ^^^^ W293\n432 |     def _should_stop_early(self, val_metrics: Dict[str, float], save_best: bool) -> bool:\n433 |         \"\"\"Check if training should stop early.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:436:1: W293 [*] Blank line contains whitespace\n    |\n434 |         if self.early_stopping_patience is None:\n435 |             return False\n436 |         \n    | ^^^^^^^^ W293\n437 |         # Get validation metric for comparison\n438 |         if self.task == \"edge_prediction\":\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:444:1: W293 [*] Blank line contains whitespace\n    |\n442 |             current_metric = val_metrics.get(\"accuracy\", 0)\n443 |             is_better = current_metric > self.best_val_metric\n444 |         \n    | ^^^^^^^^ W293\n445 |         if is_better:\n446 |             self.best_val_metric = current_metric\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:448:1: W293 [*] Blank line contains whitespace\n    |\n446 |             self.best_val_metric = current_metric\n447 |             self.early_stopping_counter = 0\n448 |             \n    | ^^^^^^^^^^^^ W293\n449 |             if save_best:\n450 |                 self._save_checkpoint(\"best_model.pt\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:453:1: W293 [*] Blank line contains whitespace\n    |\n451 |         else:\n452 |             self.early_stopping_counter += 1\n453 |         \n    | ^^^^^^^^ W293\n454 |         return self.early_stopping_counter >= self.early_stopping_patience\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:455:1: W293 [*] Blank line contains whitespace\n    |\n454 |         return self.early_stopping_counter >= self.early_stopping_patience\n455 |     \n    | ^^^^ W293\n456 |     def _log_metrics(\n457 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:466:1: W293 [*] Blank line contains whitespace\n    |\n464 |         for key, value in train_metrics.items():\n465 |             self.writer.add_scalar(f\"train/{key}\", value, epoch)\n466 |         \n    | ^^^^^^^^ W293\n467 |         # Log validation metrics\n468 |         if val_metrics:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:471:1: W293 [*] Blank line contains whitespace\n    |\n469 |             for key, value in val_metrics.items():\n470 |                 self.writer.add_scalar(f\"val/{key}\", value, epoch)\n471 |         \n    | ^^^^^^^^ W293\n472 |         # Log learning rate\n473 |         current_lr = self.optimizer.param_groups[0]['lr']\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:475:1: W293 [*] Blank line contains whitespace\n    |\n473 |         current_lr = self.optimizer.param_groups[0]['lr']\n474 |         self.writer.add_scalar(\"learning_rate\", current_lr, epoch)\n475 |     \n    | ^^^^ W293\n476 |     def _print_progress(\n477 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:485:1: W293 [*] Blank line contains whitespace\n    |\n483 |         train_loss = train_metrics.get(\"loss\", 0)\n484 |         train_metric = train_metrics.get(\"auc\" if self.task == \"edge_prediction\" else \"accuracy\", 0)\n485 |         \n    | ^^^^^^^^ W293\n486 |         print_str = f\"Epoch {epoch:3d} | Train Loss: {train_loss:.4f} | Train Metric: {train_metric:.4f}\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:487:1: W293 [*] Blank line contains whitespace\n    |\n486 |         print_str = f\"Epoch {epoch:3d} | Train Loss: {train_loss:.4f} | Train Metric: {train_metric:.4f}\"\n487 |         \n    | ^^^^^^^^ W293\n488 |         if val_metrics:\n489 |             val_loss = val_metrics.get(\"loss\", 0)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:492:1: W293 [*] Blank line contains whitespace\n    |\n490 |             val_metric = val_metrics.get(\"auc\" if self.task == \"edge_prediction\" else \"accuracy\", 0)\n491 |             print_str += f\" | Val Loss: {val_loss:.4f} | Val Metric: {val_metric:.4f}\"\n492 |         \n    | ^^^^^^^^ W293\n493 |         print(print_str)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:494:1: W293 [*] Blank line contains whitespace\n    |\n493 |         print(print_str)\n494 |     \n    | ^^^^ W293\n495 |     def evaluate(self, test_data: TemporalDataset, batch_size: int = 64) -> Dict[str, float]:\n496 |         \"\"\"Evaluate model on test data.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:499:1: W293 [*] Blank line contains whitespace\n    |\n497 |         self.model.eval()\n498 |         test_metrics = DGDNMetrics(task=self.task)\n499 |         \n    | ^^^^^^^^ W293\n500 |         # Create test loader\n501 |         from ..data import TemporalDataLoader\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:509:1: W293 [*] Blank line contains whitespace\n    |\n507 |             dynamic_batching=False\n508 |         )\n509 |         \n    | ^^^^^^^^ W293\n510 |         with torch.no_grad():\n511 |             for batch_data in tqdm(test_loader, desc=\"Testing\"):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:513:1: W293 [*] Blank line contains whitespace\n    |\n511 |             for batch_data in tqdm(test_loader, desc=\"Testing\"):\n512 |                 batch_data = batch_data.to(self.device)\n513 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n514 |                 # Forward pass\n515 |                 output = self.model(batch_data, return_uncertainty=True)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:516:1: W293 [*] Blank line contains whitespace\n    |\n514 |                 # Forward pass\n515 |                 output = self.model(batch_data, return_uncertainty=True)\n516 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n517 |                 # Compute predictions\n518 |                 predictions = self._extract_predictions(output, batch_data)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:519:1: W293 [*] Blank line contains whitespace\n    |\n517 |                 # Compute predictions\n518 |                 predictions = self._extract_predictions(output, batch_data)\n519 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n520 |                 if self.task == \"edge_prediction\":\n521 |                     targets = getattr(batch_data, 'y', torch.ones(batch_data.edge_index.shape[1]))\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:524:1: W293 [*] Blank line contains whitespace\n    |\n522 |                 else:\n523 |                     targets = getattr(batch_data, 'y', torch.zeros(batch_data.num_nodes, dtype=torch.long))\n524 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n525 |                 # Update metrics\n526 |                 uncertainties = self._extract_uncertainties(output, batch_data, predictions.shape)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:532:1: W293 [*] Blank line contains whitespace\n    |\n530 |                     uncertainties=uncertainties\n531 |                 )\n532 |         \n    | ^^^^^^^^ W293\n533 |         return test_metrics.compute()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:534:1: W293 [*] Blank line contains whitespace\n    |\n533 |         return test_metrics.compute()\n534 |     \n    | ^^^^ W293\n535 |     def _save_checkpoint(self, filename: str):\n536 |         \"\"\"Save model checkpoint.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:544:1: W293 [*] Blank line contains whitespace\n    |\n542 |             'training_history': self.training_history\n543 |         }\n544 |         \n    | ^^^^^^^^ W293\n545 |         if self.scheduler:\n546 |             checkpoint['scheduler_state_dict'] = self.scheduler.state_dict()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:547:1: W293 [*] Blank line contains whitespace\n    |\n545 |         if self.scheduler:\n546 |             checkpoint['scheduler_state_dict'] = self.scheduler.state_dict()\n547 |         \n    | ^^^^^^^^ W293\n548 |         torch.save(checkpoint, os.path.join(self.checkpoint_dir, filename))\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:549:1: W293 [*] Blank line contains whitespace\n    |\n548 |         torch.save(checkpoint, os.path.join(self.checkpoint_dir, filename))\n549 |     \n    | ^^^^ W293\n550 |     def load_checkpoint(self, filename: str):\n551 |         \"\"\"Load model checkpoint.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:554:1: W293 [*] Blank line contains whitespace\n    |\n552 |         checkpoint_path = os.path.join(self.checkpoint_dir, filename)\n553 |         checkpoint = torch.load(checkpoint_path, map_location=self.device)\n554 |         \n    | ^^^^^^^^ W293\n555 |         self.model.load_state_dict(checkpoint['model_state_dict'])\n556 |         self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:560:1: W293 [*] Blank line contains whitespace\n    |\n558 |         self.best_val_metric = checkpoint['best_val_metric']\n559 |         self.training_history = checkpoint['training_history']\n560 |         \n    | ^^^^^^^^ W293\n561 |         if self.scheduler and 'scheduler_state_dict' in checkpoint:\n562 |             self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:563:1: W293 [*] Blank line contains whitespace\n    |\n561 |         if self.scheduler and 'scheduler_state_dict' in checkpoint:\n562 |             self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n563 |     \n    | ^^^^ W293\n564 |     def predict(self, data, return_uncertainty: bool = False) -> Dict[str, torch.Tensor]:\n565 |         \"\"\"Make predictions on new data.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:567:1: W293 [*] Blank line contains whitespace\n    |\n565 |         \"\"\"Make predictions on new data.\"\"\"\n566 |         self.model.eval()\n567 |         \n    | ^^^^^^^^ W293\n568 |         with torch.no_grad():\n569 |             data = data.to(self.device)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:571:1: W293 [*] Blank line contains whitespace\n    |\n569 |             data = data.to(self.device)\n570 |             output = self.model(data, return_uncertainty=return_uncertainty)\n571 |             \n    | ^^^^^^^^^^^^ W293\n572 |             predictions = self._extract_predictions(output, data)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:573:1: W293 [*] Blank line contains whitespace\n    |\n572 |             predictions = self._extract_predictions(output, data)\n573 |             \n    | ^^^^^^^^^^^^ W293\n574 |             result = {\"predictions\": predictions}\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:575:1: W293 [*] Blank line contains whitespace\n    |\n574 |             result = {\"predictions\": predictions}\n575 |             \n    | ^^^^^^^^^^^^ W293\n576 |             if return_uncertainty:\n577 |                 result[\"uncertainty\"] = output.get(\"uncertainty\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:580:1: W293 [*] Blank line contains whitespace\n    |\n578 |                 result[\"mean\"] = output.get(\"mean\")\n579 |                 result[\"logvar\"] = output.get(\"logvar\")\n580 |             \n    | ^^^^^^^^^^^^ W293\n581 |             return result\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:582:1: W293 [*] Blank line contains whitespace\n    |\n581 |             return result\n582 |     \n    | ^^^^ W293\n583 |     def _setup_logger(self) -> logging.Logger:\n584 |         \"\"\"Setup structured logging.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:587:1: W293 [*] Blank line contains whitespace\n    |\n585 |         logger = logging.getLogger(f\"DGDN.{self.__class__.__name__}\")\n586 |         logger.setLevel(logging.INFO)\n587 |         \n    | ^^^^^^^^ W293\n588 |         # Prevent duplicate handlers\n589 |         if not logger.handlers:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:593:1: W293 [*] Blank line contains whitespace\n    |\n591 |             console_handler = logging.StreamHandler()\n592 |             console_handler.setLevel(logging.INFO)\n593 |             \n    | ^^^^^^^^^^^^ W293\n594 |             # File handler\n595 |             log_file = Path(self.log_dir) / \"training.log\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:598:1: W293 [*] Blank line contains whitespace\n    |\n596 |             file_handler = logging.FileHandler(log_file)\n597 |             file_handler.setLevel(logging.DEBUG)\n598 |             \n    | ^^^^^^^^^^^^ W293\n599 |             # Formatter\n600 |             formatter = logging.Formatter(\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:605:1: W293 [*] Blank line contains whitespace\n    |\n603 |             console_handler.setFormatter(formatter)\n604 |             file_handler.setFormatter(formatter)\n605 |             \n    | ^^^^^^^^^^^^ W293\n606 |             logger.addHandler(console_handler)\n607 |             logger.addHandler(file_handler)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:608:1: W293 [*] Blank line contains whitespace\n    |\n606 |             logger.addHandler(console_handler)\n607 |             logger.addHandler(file_handler)\n608 |         \n    | ^^^^^^^^ W293\n609 |         return logger\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:610:1: W293 [*] Blank line contains whitespace\n    |\n609 |         return logger\n610 |     \n    | ^^^^ W293\n611 |     def _validate_init_parameters(self, learning_rate, weight_decay, \n612 |                                  diffusion_loss_weight, temporal_reg_weight):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:611:69: W291 [*] Trailing whitespace\n    |\n609 |         return logger\n610 |     \n611 |     def _validate_init_parameters(self, learning_rate, weight_decay, \n    |                                                                     ^ W291\n612 |                                  diffusion_loss_weight, temporal_reg_weight):\n613 |         \"\"\"Validate trainer initialization parameters.\"\"\"\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/training/trainer.py:618:1: W293 [*] Blank line contains whitespace\n    |\n616 |         if learning_rate > 1.0:\n617 |             self.logger.warning(f\"Very high learning rate: {learning_rate}\")\n618 |         \n    | ^^^^^^^^ W293\n619 |         if not isinstance(weight_decay, (int, float)) or weight_decay < 0:\n620 |             raise ValueError(f\"weight_decay must be non-negative, got {weight_decay}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:623:1: W293 [*] Blank line contains whitespace\n    |\n621 |         if weight_decay > 0.1:\n622 |             self.logger.warning(f\"High weight decay: {weight_decay}\")\n623 |         \n    | ^^^^^^^^ W293\n624 |         if not isinstance(diffusion_loss_weight, (int, float)) or diffusion_loss_weight < 0:\n625 |             raise ValueError(f\"diffusion_loss_weight must be non-negative, got {diffusion_loss_weight}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:626:1: W293 [*] Blank line contains whitespace\n    |\n624 |         if not isinstance(diffusion_loss_weight, (int, float)) or diffusion_loss_weight < 0:\n625 |             raise ValueError(f\"diffusion_loss_weight must be non-negative, got {diffusion_loss_weight}\")\n626 |         \n    | ^^^^^^^^ W293\n627 |         if not isinstance(temporal_reg_weight, (int, float)) or temporal_reg_weight < 0:\n628 |             raise ValueError(f\"temporal_reg_weight must be non-negative, got {temporal_reg_weight}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:629:1: W293 [*] Blank line contains whitespace\n    |\n627 |         if not isinstance(temporal_reg_weight, (int, float)) or temporal_reg_weight < 0:\n628 |             raise ValueError(f\"temporal_reg_weight must be non-negative, got {temporal_reg_weight}\")\n629 |     \n    | ^^^^ W293\n630 |     def _validate_training_data(self, train_data, val_data=None):\n631 |         \"\"\"Validate training and validation data.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:634:1: W293 [*] Blank line contains whitespace\n    |\n632 |         if not hasattr(train_data, 'data'):\n633 |             raise ValueError(\"train_data must have a 'data' attribute\")\n634 |         \n    | ^^^^^^^^ W293\n635 |         # Check for minimum data size\n636 |         if hasattr(train_data.data, 'timestamps'):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:641:1: W293 [*] Blank line contains whitespace\n    |\n639 |                 raise ValueError(f\"Insufficient training data: only {num_edges} edges\")\n640 |             self.logger.info(f\"Training data: {num_edges} edges\")\n641 |         \n    | ^^^^^^^^ W293\n642 |         if val_data is not None:\n643 |             if not hasattr(val_data, 'data'):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:648:1: W293 [*] Blank line contains whitespace\n    |\n646 |                 num_val_edges = len(val_data.data.timestamps)\n647 |                 self.logger.info(f\"Validation data: {num_val_edges} edges\")\n648 |     \n    | ^^^^ W293\n649 |     def _secure_checkpoint_path(self, filename: str) -> str:\n650 |         \"\"\"Secure checkpoint path validation.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:654:1: W293 [*] Blank line contains whitespace\n    |\n652 |         import re\n653 |         filename = re.sub(r'[^\\w\\-_\\.]', '_', filename)\n654 |         \n    | ^^^^^^^^ W293\n655 |         # Ensure .pth extension\n656 |         if not filename.endswith('.pth'):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:658:1: W293 [*] Blank line contains whitespace\n    |\n656 |         if not filename.endswith('.pth'):\n657 |             filename += '.pth'\n658 |         \n    | ^^^^^^^^ W293\n659 |         # Check path traversal attacks\n660 |         filepath = Path(self.checkpoint_dir) / filename\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:663:1: W293 [*] Blank line contains whitespace\n    |\n661 |         if not str(filepath.resolve()).startswith(str(Path(self.checkpoint_dir).resolve())):\n662 |             raise ValueError(f\"Insecure checkpoint path: {filename}\")\n663 |         \n    | ^^^^^^^^ W293\n664 |         return str(filepath)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:665:1: W293 [*] Blank line contains whitespace\n    |\n664 |         return str(filepath)\n665 |     \n    | ^^^^ W293\n666 |     def _log_training_progress(self, epoch, train_metrics, val_metrics=None):\n667 |         \"\"\"Log training progress with security considerations.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:671:1: W293 [*] Blank line contains whitespace\n    |\n669 |         train_loss = train_metrics.get('loss', 0.0)\n670 |         train_metric = train_metrics.get(self._get_primary_metric(), 0.0)\n671 |         \n    | ^^^^^^^^ W293\n672 |         log_msg = f\"Epoch {epoch:3d} | Train Loss: {train_loss:.4f} | Train Metric: {train_metric:.4f}\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:673:1: W293 [*] Blank line contains whitespace\n    |\n672 |         log_msg = f\"Epoch {epoch:3d} | Train Loss: {train_loss:.4f} | Train Metric: {train_metric:.4f}\"\n673 |         \n    | ^^^^^^^^ W293\n674 |         if val_metrics:\n675 |             val_loss = val_metrics.get('loss', 0.0)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:678:1: W293 [*] Blank line contains whitespace\n    |\n676 |             val_metric = val_metrics.get(self._get_primary_metric(), 0.0)\n677 |             log_msg += f\" | Val Loss: {val_loss:.4f} | Val Metric: {val_metric:.4f}\"\n678 |         \n    | ^^^^^^^^ W293\n679 |         self.logger.info(log_msg)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:680:1: W293 [*] Blank line contains whitespace\n    |\n679 |         self.logger.info(log_msg)\n680 |         \n    | ^^^^^^^^ W293\n681 |         # Log to tensorboard (with rate limiting)\n682 |         if hasattr(self, 'writer') and epoch % 5 == 0:  # Log every 5 epochs\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:686:1: W293 [*] Blank line contains whitespace\n    |\n684 |                 if isinstance(value, (int, float)) and not (key.startswith('_') or key == 'loss'):\n685 |                     self.writer.add_scalar(f\"train/{key}\", value, epoch)\n686 |             \n    | ^^^^^^^^^^^^ W293\n687 |             if val_metrics:\n688 |                 for key, value in val_metrics.items():\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:691:1: W293 [*] Blank line contains whitespace\n    |\n689 |                     if isinstance(value, (int, float)) and not (key.startswith('_') or key == 'loss'):\n690 |                         self.writer.add_scalar(f\"val/{key}\", value, epoch)\n691 |     \n    | ^^^^ W293\n692 |     def _get_primary_metric(self) -> str:\n693 |         \"\"\"Get primary metric for the task.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/training/trainer.py:699:26: W292 [*] No newline at end of file\n    |\n697 |             return \"accuracy\"\n698 |         else:\n699 |             return \"loss\"\n    |                          ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/utils/__init__.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n  |\n1 |   \"\"\"Utility modules for DGDN.\"\"\"\n2 |\n3 | / from .config import DGDNConfig, ModelConfig, TrainingConfig\n4 | | from .logging import setup_logging, get_logger, log_model_info\n5 | | from .validation import validate_model_config, validate_data, validate_tensors\n6 | | from .monitoring import ModelMonitor, TrainingMonitor, PerformanceProfiler\n7 | | from .security import SecurityValidator, sanitize_input, check_model_integrity\n  | |______________________________________________________________________________^ I001\n8 |\n9 |   __all__ = [\n  |\n  = help: Organize imports\n\nsrc/dgdn/utils/__init__.py:11:19: W291 [*] Trailing whitespace\n   |\n 9 | __all__ = [\n10 |     \"DGDNConfig\",\n11 |     \"ModelConfig\", \n   |                   ^ W291\n12 |     \"TrainingConfig\",\n13 |     \"setup_logging\",\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/utils/__init__.py:25:2: W292 [*] No newline at end of file\n   |\n23 |     \"sanitize_input\",\n24 |     \"check_model_integrity\",\n25 | ]\n   |  ^ W292\n   |\n   = help: Add trailing newline\n\nsrc/dgdn/utils/config.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n  |\n1 |   \"\"\"Configuration management for DGDN.\"\"\"\n2 |\n3 | / import os\n4 | | import json\n5 | | # import yaml  # Optional dependency - imported when needed\n6 | | from dataclasses import dataclass, asdict\n7 | | from typing import Dict, Any, Optional, Union\n8 | | from pathlib import Path\n  | |________________________^ I001\n  |\n  = help: Organize imports\n\nsrc/dgdn/utils/config.py:58:1: W293 [*] Blank line contains whitespace\n   |\n56 |     max_input_size: int = 1000000\n57 |     allowed_file_types: list = None\n58 |     \n   | ^^^^ W293\n59 |     def __post_init__(self):\n60 |         if self.allowed_file_types is None:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:64:11: W291 [*] Trailing whitespace\n   |\n64 | @dataclass \n   |           ^ W291\n65 | class MonitoringConfig:\n66 |     \"\"\"Monitoring and logging configuration.\"\"\"\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/utils/config.py:86:1: W293 [*] Blank line contains whitespace\n   |\n84 |     security: SecurityConfig\n85 |     monitoring: MonitoringConfig\n86 |     \n   | ^^^^ W293\n87 |     def __init__(\n88 |         self,\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:98:1: W293 [*] Blank line contains whitespace\n    |\n 96 |         self.security = security or SecurityConfig()\n 97 |         self.monitoring = monitoring or MonitoringConfig()\n 98 |     \n    | ^^^^ W293\n 99 |     @classmethod\n100 |     def from_file(cls, config_path: Union[str, Path]) -> 'DGDNConfig':\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:103:1: W293 [*] Blank line contains whitespace\n    |\n101 |         \"\"\"Load configuration from file.\"\"\"\n102 |         config_path = Path(config_path)\n103 |         \n    | ^^^^^^^^ W293\n104 |         if not config_path.exists():\n105 |             raise FileNotFoundError(f\"Configuration file not found: {config_path}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:106:1: W293 [*] Blank line contains whitespace\n    |\n104 |         if not config_path.exists():\n105 |             raise FileNotFoundError(f\"Configuration file not found: {config_path}\")\n106 |         \n    | ^^^^^^^^ W293\n107 |         with open(config_path, 'r') as f:\n108 |             if config_path.suffix.lower() in ['.yaml', '.yml']:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:107:32: UP015 [*] Unnecessary mode argument\n    |\n105 |             raise FileNotFoundError(f\"Configuration file not found: {config_path}\")\n106 |         \n107 |         with open(config_path, 'r') as f:\n    |                                ^^^ UP015\n108 |             if config_path.suffix.lower() in ['.yaml', '.yml']:\n109 |                 try:\n    |\n    = help: Remove mode argument\n\nsrc/dgdn/utils/config.py:111:35: F821 Undefined name `yaml`\n    |\n109 |                 try:\n110 |                     # import yaml  # Optional dependency - imported when needed\n111 |                     config_dict = yaml.safe_load(f)\n    |                                   ^^^^ F821\n112 |                 except ImportError:\n113 |                     raise ImportError(\"PyYAML is required for YAML configuration files\")\n    |\n\nsrc/dgdn/utils/config.py:113:21: B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling\n    |\n111 |                     config_dict = yaml.safe_load(f)\n112 |                 except ImportError:\n113 |                     raise ImportError(\"PyYAML is required for YAML configuration files\")\n    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ B904\n114 |             elif config_path.suffix.lower() == '.json':\n115 |                 config_dict = json.load(f)\n    |\n\nsrc/dgdn/utils/config.py:118:1: W293 [*] Blank line contains whitespace\n    |\n116 |             else:\n117 |                 raise ValueError(f\"Unsupported configuration file format: {config_path.suffix}\")\n118 |         \n    | ^^^^^^^^ W293\n119 |         return cls.from_dict(config_dict)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:120:1: W293 [*] Blank line contains whitespace\n    |\n119 |         return cls.from_dict(config_dict)\n120 |     \n    | ^^^^ W293\n121 |     @classmethod\n122 |     def from_dict(cls, config_dict: Dict[str, Any]) -> 'DGDNConfig':\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:128:1: W293 [*] Blank line contains whitespace\n    |\n126 |         security_config = SecurityConfig(**config_dict.get('security', {}))\n127 |         monitoring_config = MonitoringConfig(**config_dict.get('monitoring', {}))\n128 |         \n    | ^^^^^^^^ W293\n129 |         return cls(\n130 |             model=model_config,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:135:1: W293 [*] Blank line contains whitespace\n    |\n133 |             monitoring=monitoring_config\n134 |         )\n135 |     \n    | ^^^^ W293\n136 |     def to_dict(self) -> Dict[str, Any]:\n137 |         \"\"\"Convert configuration to dictionary.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:144:1: W293 [*] Blank line contains whitespace\n    |\n142 |             'monitoring': asdict(self.monitoring)\n143 |         }\n144 |     \n    | ^^^^ W293\n145 |     def save(self, config_path: Union[str, Path]) -> None:\n146 |         \"\"\"Save configuration to file.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:149:1: W293 [*] Blank line contains whitespace\n    |\n147 |         config_path = Path(config_path)\n148 |         config_path.parent.mkdir(parents=True, exist_ok=True)\n149 |         \n    | ^^^^^^^^ W293\n150 |         config_dict = self.to_dict()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:151:1: W293 [*] Blank line contains whitespace\n    |\n150 |         config_dict = self.to_dict()\n151 |         \n    | ^^^^^^^^ W293\n152 |         with open(config_path, 'w') as f:\n153 |             if config_path.suffix.lower() in ['.yaml', '.yml']:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:156:21: F821 Undefined name `yaml`\n    |\n154 |                 try:\n155 |                     # import yaml  # Optional dependency - imported when needed\n156 |                     yaml.dump(config_dict, f, default_flow_style=False, indent=2)\n    |                     ^^^^ F821\n157 |                 except ImportError:\n158 |                     raise ImportError(\"PyYAML is required for YAML configuration files\")\n    |\n\nsrc/dgdn/utils/config.py:158:21: B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling\n    |\n156 |                     yaml.dump(config_dict, f, default_flow_style=False, indent=2)\n157 |                 except ImportError:\n158 |                     raise ImportError(\"PyYAML is required for YAML configuration files\")\n    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ B904\n159 |             elif config_path.suffix.lower() == '.json':\n160 |                 json.dump(config_dict, f, indent=2)\n    |\n\nsrc/dgdn/utils/config.py:163:1: W293 [*] Blank line contains whitespace\n    |\n161 |             else:\n162 |                 raise ValueError(f\"Unsupported configuration file format: {config_path.suffix}\")\n163 |     \n    | ^^^^ W293\n164 |     def validate(self) -> bool:\n165 |         \"\"\"Validate configuration values.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:167:1: W293 [*] Blank line contains whitespace\n    |\n165 |         \"\"\"Validate configuration values.\"\"\"\n166 |         errors = []\n167 |         \n    | ^^^^^^^^ W293\n168 |         # Model validation\n169 |         if self.model.node_dim <= 0:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:177:1: W293 [*] Blank line contains whitespace\n    |\n175 |         if not 0 <= self.model.dropout < 1:\n176 |             errors.append(\"dropout must be in [0, 1)\")\n177 |         \n    | ^^^^^^^^ W293\n178 |         # Training validation\n179 |         if self.training.learning_rate <= 0:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:185:1: W293 [*] Blank line contains whitespace\n    |\n183 |         if self.training.epochs <= 0:\n184 |             errors.append(\"epochs must be positive\")\n185 |         \n    | ^^^^^^^^ W293\n186 |         # Security validation\n187 |         if self.security.max_input_size <= 0:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:189:1: W293 [*] Blank line contains whitespace\n    |\n187 |         if self.security.max_input_size <= 0:\n188 |             errors.append(\"max_input_size must be positive\")\n189 |         \n    | ^^^^^^^^ W293\n190 |         if errors:\n191 |             raise ValueError(f\"Configuration validation failed: {'; '.join(errors)}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:192:1: W293 [*] Blank line contains whitespace\n    |\n190 |         if errors:\n191 |             raise ValueError(f\"Configuration validation failed: {'; '.join(errors)}\")\n192 |         \n    | ^^^^^^^^ W293\n193 |         return True\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:204:1: W293 [*] Blank line contains whitespace\n    |\n202 |         'monitoring': {}\n203 |     }\n204 |     \n    | ^^^^ W293\n205 |     # Model config from env\n206 |     if os.getenv('DGDN_NODE_DIM'):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:212:1: W293 [*] Blank line contains whitespace\n    |\n210 |     if os.getenv('DGDN_NUM_LAYERS'):\n211 |         config_dict['model']['num_layers'] = int(os.getenv('DGDN_NUM_LAYERS'))\n212 |     \n    | ^^^^ W293\n213 |     # Training config from env\n214 |     if os.getenv('DGDN_LEARNING_RATE'):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:220:1: W293 [*] Blank line contains whitespace\n    |\n218 |     if os.getenv('DGDN_EPOCHS'):\n219 |         config_dict['training']['epochs'] = int(os.getenv('DGDN_EPOCHS'))\n220 |     \n    | ^^^^ W293\n221 |     # Security config from env\n222 |     if os.getenv('DGDN_ENABLE_VALIDATION'):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:224:1: W293 [*] Blank line contains whitespace\n    |\n222 |     if os.getenv('DGDN_ENABLE_VALIDATION'):\n223 |         config_dict['security']['enable_input_validation'] = os.getenv('DGDN_ENABLE_VALIDATION').lower() == 'true'\n224 |     \n    | ^^^^ W293\n225 |     # Monitoring config from env\n226 |     if os.getenv('DGDN_LOG_LEVEL'):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:228:1: W293 [*] Blank line contains whitespace\n    |\n226 |     if os.getenv('DGDN_LOG_LEVEL'):\n227 |         config_dict['monitoring']['log_level'] = os.getenv('DGDN_LOG_LEVEL')\n228 |     \n    | ^^^^ W293\n229 |     return DGDNConfig.from_dict(config_dict)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:241:1: W293 [*] Blank line contains whitespace\n    |\n239 |     base_dict = base_config.to_dict()\n240 |     override_dict = override_config.to_dict()\n241 |     \n    | ^^^^ W293\n242 |     def deep_merge(base: dict, override: dict) -> dict:\n243 |         result = base.copy()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:250:1: W293 [*] Blank line contains whitespace\n    |\n248 |                 result[key] = value\n249 |         return result\n250 |     \n    | ^^^^ W293\n251 |     merged_dict = deep_merge(base_dict, override_dict)\n252 |     return DGDNConfig.from_dict(merged_dict)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/config.py:252:45: W292 [*] No newline at end of file\n    |\n251 |     merged_dict = deep_merge(base_dict, override_dict)\n252 |     return DGDNConfig.from_dict(merged_dict)\n    |                                             ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/utils/logging.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n  |\n1 |   \"\"\"Logging utilities for DGDN.\"\"\"\n2 |\n3 | / import logging\n4 | | import sys\n5 | | from typing import Optional, Dict, Any\n6 | | from pathlib import Path\n7 | | import json\n8 | | import time\n9 | | from datetime import datetime\n  | |_____________________________^ I001\n  |\n  = help: Organize imports\n\nsrc/dgdn/utils/logging.py:19:1: W293 Blank line contains whitespace\n   |\n17 | ) -> logging.Logger:\n18 |     \"\"\"Setup logging configuration for DGDN.\n19 |     \n   | ^^^^ W293\n20 |     Args:\n21 |         log_level: Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:25:1: W293 Blank line contains whitespace\n   |\n23 |         format_string: Custom format string for log messages\n24 |         include_timestamp: Whether to include timestamp in logs\n25 |         \n   | ^^^^^^^^ W293\n26 |     Returns:\n27 |         Configured logger instance\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:32:1: W293 [*] Blank line contains whitespace\n   |\n30 |     logger = logging.getLogger(\"dgdn\")\n31 |     logger.handlers.clear()\n32 |     \n   | ^^^^ W293\n33 |     # Set log level\n34 |     numeric_level = getattr(logging, log_level.upper(), None)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:38:1: W293 [*] Blank line contains whitespace\n   |\n36 |         raise ValueError(f'Invalid log level: {log_level}')\n37 |     logger.setLevel(numeric_level)\n38 |     \n   | ^^^^ W293\n39 |     # Create formatter\n40 |     if format_string is None:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:45:1: W293 [*] Blank line contains whitespace\n   |\n43 |         else:\n44 |             format_string = '%(name)s - %(levelname)s - %(message)s'\n45 |     \n   | ^^^^ W293\n46 |     formatter = logging.Formatter(format_string)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:47:1: W293 [*] Blank line contains whitespace\n   |\n46 |     formatter = logging.Formatter(format_string)\n47 |     \n   | ^^^^ W293\n48 |     # Console handler\n49 |     console_handler = logging.StreamHandler(sys.stdout)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:52:1: W293 [*] Blank line contains whitespace\n   |\n50 |     console_handler.setFormatter(formatter)\n51 |     logger.addHandler(console_handler)\n52 |     \n   | ^^^^ W293\n53 |     # File handler (if specified)\n54 |     if log_file:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:57:1: W293 [*] Blank line contains whitespace\n   |\n55 |         log_path = Path(log_file)\n56 |         log_path.parent.mkdir(parents=True, exist_ok=True)\n57 |         \n   | ^^^^^^^^ W293\n58 |         file_handler = logging.FileHandler(log_file)\n59 |         file_handler.setFormatter(formatter)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:61:1: W293 [*] Blank line contains whitespace\n   |\n59 |         file_handler.setFormatter(formatter)\n60 |         logger.addHandler(file_handler)\n61 |     \n   | ^^^^ W293\n62 |     return logger\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:67:1: W293 Blank line contains whitespace\n   |\n65 | def get_logger(name: str = \"dgdn\") -> logging.Logger:\n66 |     \"\"\"Get a logger instance.\n67 |     \n   | ^^^^ W293\n68 |     Args:\n69 |         name: Logger name\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:70:1: W293 Blank line contains whitespace\n   |\n68 |     Args:\n69 |         name: Logger name\n70 |         \n   | ^^^^^^^^ W293\n71 |     Returns:\n72 |         Logger instance\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:79:1: W293 [*] Blank line contains whitespace\n   |\n77 | class StructuredLogger:\n78 |     \"\"\"Structured logging for machine-readable logs.\"\"\"\n79 |     \n   | ^^^^ W293\n80 |     def __init__(self, logger_name: str = \"dgdn\", log_file: Optional[str] = None):\n81 |         self.logger = get_logger(logger_name)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:83:1: W293 [*] Blank line contains whitespace\n   |\n81 |         self.logger = get_logger(logger_name)\n82 |         self.log_file = log_file\n83 |         \n   | ^^^^^^^^ W293\n84 |         if log_file:\n85 |             log_path = Path(log_file)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:87:1: W293 [*] Blank line contains whitespace\n   |\n85 |             log_path = Path(log_file)\n86 |             log_path.parent.mkdir(parents=True, exist_ok=True)\n87 |     \n   | ^^^^ W293\n88 |     def log_event(\n89 |         self, \n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:89:14: W291 [*] Trailing whitespace\n   |\n88 |     def log_event(\n89 |         self, \n   |              ^ W291\n90 |         event_type: str, \n91 |         data: Dict[str, Any], \n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/utils/logging.py:90:25: W291 [*] Trailing whitespace\n   |\n88 |     def log_event(\n89 |         self, \n90 |         event_type: str, \n   |                         ^ W291\n91 |         data: Dict[str, Any], \n92 |         level: str = \"INFO\"\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/utils/logging.py:91:30: W291 [*] Trailing whitespace\n   |\n89 |         self, \n90 |         event_type: str, \n91 |         data: Dict[str, Any], \n   |                              ^ W291\n92 |         level: str = \"INFO\"\n93 |     ) -> None:\n   |\n   = help: Remove trailing whitespace\n\nsrc/dgdn/utils/logging.py:95:1: W293 Blank line contains whitespace\n   |\n93 |     ) -> None:\n94 |         \"\"\"Log a structured event.\n95 |         \n   | ^^^^^^^^ W293\n96 |         Args:\n97 |             event_type: Type of event (e.g., 'training_start', 'model_forward')\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:106:1: W293 [*] Blank line contains whitespace\n    |\n104 |             \"data\": data\n105 |         }\n106 |         \n    | ^^^^^^^^ W293\n107 |         # Log to standard logger\n108 |         log_func = getattr(self.logger, level.lower())\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:110:1: W293 [*] Blank line contains whitespace\n    |\n108 |         log_func = getattr(self.logger, level.lower())\n109 |         log_func(f\"{event_type}: {json.dumps(data)}\")\n110 |         \n    | ^^^^^^^^ W293\n111 |         # Write to structured log file\n112 |         if self.log_file:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:119:1: W293 Blank line contains whitespace\n    |\n117 | def log_model_info(model, logger: Optional[logging.Logger] = None) -> None:\n118 |     \"\"\"Log model information.\n119 |     \n    | ^^^^ W293\n120 |     Args:\n121 |         model: PyTorch model to log information about\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:126:1: W293 [*] Blank line contains whitespace\n    |\n124 |     if logger is None:\n125 |         logger = get_logger()\n126 |     \n    | ^^^^ W293\n127 |     # Count parameters\n128 |     total_params = sum(p.numel() for p in model.parameters())\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:130:1: W293 [*] Blank line contains whitespace\n    |\n128 |     total_params = sum(p.numel() for p in model.parameters())\n129 |     trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n130 |     \n    | ^^^^ W293\n131 |     logger.info(f\"Model: {model.__class__.__name__}\")\n132 |     logger.info(f\"Total parameters: {total_params:,}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:135:1: W293 [*] Blank line contains whitespace\n    |\n133 |     logger.info(f\"Trainable parameters: {trainable_params:,}\")\n134 |     logger.info(f\"Model size (MB): {total_params * 4 / 1024 / 1024:.2f}\")  # Assuming float32\n135 |     \n    | ^^^^ W293\n136 |     # Log model configuration if available\n137 |     if hasattr(model, 'node_dim'):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:147:1: W293 [*] Blank line contains whitespace\n    |\n145 | class TrainingLogger:\n146 |     \"\"\"Specialized logger for training progress.\"\"\"\n147 |     \n    | ^^^^ W293\n148 |     def __init__(self, logger_name: str = \"dgdn.training\"):\n149 |         self.logger = get_logger(logger_name)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:152:1: W293 [*] Blank line contains whitespace\n    |\n150 |         self.start_time = None\n151 |         self.epoch_start_time = None\n152 |         \n    | ^^^^^^^^ W293\n153 |     def log_training_start(self, config: Dict[str, Any]) -> None:\n154 |         \"\"\"Log training start.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:159:1: W293 [*] Blank line contains whitespace\n    |\n157 |         self.logger.info(\"TRAINING STARTED\")\n158 |         self.logger.info(\"=\" * 50)\n159 |         \n    | ^^^^^^^^ W293\n160 |         for key, value in config.items():\n161 |             self.logger.info(f\"{key}: {value}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:162:1: W293 [*] Blank line contains whitespace\n    |\n160 |         for key, value in config.items():\n161 |             self.logger.info(f\"{key}: {value}\")\n162 |     \n    | ^^^^ W293\n163 |     def log_epoch_start(self, epoch: int, total_epochs: int) -> None:\n164 |         \"\"\"Log epoch start.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:167:1: W293 [*] Blank line contains whitespace\n    |\n165 |         self.epoch_start_time = time.time()\n166 |         self.logger.info(f\"Epoch {epoch + 1}/{total_epochs}\")\n167 |     \n    | ^^^^ W293\n168 |     def log_epoch_end(\n169 |         self, \n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:169:14: W291 [*] Trailing whitespace\n    |\n168 |     def log_epoch_end(\n169 |         self, \n    |              ^ W291\n170 |         epoch: int, \n171 |         train_loss: float, \n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/utils/logging.py:170:20: W291 [*] Trailing whitespace\n    |\n168 |     def log_epoch_end(\n169 |         self, \n170 |         epoch: int, \n    |                    ^ W291\n171 |         train_loss: float, \n172 |         val_loss: Optional[float] = None,\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/utils/logging.py:171:27: W291 [*] Trailing whitespace\n    |\n169 |         self, \n170 |         epoch: int, \n171 |         train_loss: float, \n    |                           ^ W291\n172 |         val_loss: Optional[float] = None,\n173 |         metrics: Optional[Dict[str, float]] = None\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/utils/logging.py:177:1: W293 [*] Blank line contains whitespace\n    |\n175 |         \"\"\"Log epoch end with metrics.\"\"\"\n176 |         epoch_time = time.time() - self.epoch_start_time if self.epoch_start_time else 0\n177 |         \n    | ^^^^^^^^ W293\n178 |         log_msg = f\"Epoch {epoch + 1} completed in {epoch_time:.2f}s - \"\n179 |         log_msg += f\"Train Loss: {train_loss:.4f}\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:180:1: W293 [*] Blank line contains whitespace\n    |\n178 |         log_msg = f\"Epoch {epoch + 1} completed in {epoch_time:.2f}s - \"\n179 |         log_msg += f\"Train Loss: {train_loss:.4f}\"\n180 |         \n    | ^^^^^^^^ W293\n181 |         if val_loss is not None:\n182 |             log_msg += f\", Val Loss: {val_loss:.4f}\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:183:1: W293 [*] Blank line contains whitespace\n    |\n181 |         if val_loss is not None:\n182 |             log_msg += f\", Val Loss: {val_loss:.4f}\"\n183 |         \n    | ^^^^^^^^ W293\n184 |         if metrics:\n185 |             metric_strs = [f\"{k}: {v:.4f}\" for k, v in metrics.items()]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:187:1: W293 [*] Blank line contains whitespace\n    |\n185 |             metric_strs = [f\"{k}: {v:.4f}\" for k, v in metrics.items()]\n186 |             log_msg += f\", {', '.join(metric_strs)}\"\n187 |         \n    | ^^^^^^^^ W293\n188 |         self.logger.info(log_msg)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:189:1: W293 [*] Blank line contains whitespace\n    |\n188 |         self.logger.info(log_msg)\n189 |     \n    | ^^^^ W293\n190 |     def log_training_end(self, best_metrics: Optional[Dict[str, float]] = None) -> None:\n191 |         \"\"\"Log training completion.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:193:1: W293 [*] Blank line contains whitespace\n    |\n191 |         \"\"\"Log training completion.\"\"\"\n192 |         total_time = time.time() - self.start_time if self.start_time else 0\n193 |         \n    | ^^^^^^^^ W293\n194 |         self.logger.info(\"=\" * 50)\n195 |         self.logger.info(\"TRAINING COMPLETED\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:197:1: W293 [*] Blank line contains whitespace\n    |\n195 |         self.logger.info(\"TRAINING COMPLETED\")\n196 |         self.logger.info(f\"Total training time: {total_time:.2f}s\")\n197 |         \n    | ^^^^^^^^ W293\n198 |         if best_metrics:\n199 |             self.logger.info(\"Best metrics:\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:202:1: W293 [*] Blank line contains whitespace\n    |\n200 |             for key, value in best_metrics.items():\n201 |                 self.logger.info(f\"  {key}: {value:.4f}\")\n202 |         \n    | ^^^^^^^^ W293\n203 |         self.logger.info(\"=\" * 50)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:208:1: W293 [*] Blank line contains whitespace\n    |\n206 | class PerformanceLogger:\n207 |     \"\"\"Logger for performance metrics.\"\"\"\n208 |     \n    | ^^^^ W293\n209 |     def __init__(self, logger_name: str = \"dgdn.performance\"):\n210 |         self.logger = get_logger(logger_name)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:212:1: W293 [*] Blank line contains whitespace\n    |\n210 |         self.logger = get_logger(logger_name)\n211 |         self.timers = {}\n212 |     \n    | ^^^^ W293\n213 |     def start_timer(self, name: str) -> None:\n214 |         \"\"\"Start a named timer.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:216:1: W293 [*] Blank line contains whitespace\n    |\n214 |         \"\"\"Start a named timer.\"\"\"\n215 |         self.timers[name] = time.time()\n216 |     \n    | ^^^^ W293\n217 |     def end_timer(self, name: str, log_result: bool = True) -> float:\n218 |         \"\"\"End a named timer and optionally log the result.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:222:1: W293 [*] Blank line contains whitespace\n    |\n220 |             self.logger.warning(f\"Timer '{name}' was not started\")\n221 |             return 0.0\n222 |         \n    | ^^^^^^^^ W293\n223 |         elapsed = time.time() - self.timers[name]\n224 |         del self.timers[name]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:225:1: W293 [*] Blank line contains whitespace\n    |\n223 |         elapsed = time.time() - self.timers[name]\n224 |         del self.timers[name]\n225 |         \n    | ^^^^^^^^ W293\n226 |         if log_result:\n227 |             self.logger.info(f\"Timer '{name}': {elapsed:.4f}s\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:228:1: W293 [*] Blank line contains whitespace\n    |\n226 |         if log_result:\n227 |             self.logger.info(f\"Timer '{name}': {elapsed:.4f}s\")\n228 |         \n    | ^^^^^^^^ W293\n229 |         return elapsed\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:230:1: W293 [*] Blank line contains whitespace\n    |\n229 |         return elapsed\n230 |     \n    | ^^^^ W293\n231 |     def log_memory_usage(self) -> None:\n232 |         \"\"\"Log current memory usage.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:237:1: W293 [*] Blank line contains whitespace\n    |\n235 |             process = psutil.Process()\n236 |             memory_info = process.memory_info()\n237 |             \n    | ^^^^^^^^^^^^ W293\n238 |             self.logger.info(f\"Memory - RSS: {memory_info.rss / 1024 / 1024:.2f} MB, \"\n239 |                            f\"VMS: {memory_info.vms / 1024 / 1024:.2f} MB\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:242:1: W293 [*] Blank line contains whitespace\n    |\n240 |         except ImportError:\n241 |             self.logger.warning(\"psutil not available for memory monitoring\")\n242 |     \n    | ^^^^ W293\n243 |     def log_gpu_usage(self) -> None:\n244 |         \"\"\"Log GPU usage if available.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:252:1: W293 [*] Blank line contains whitespace\n    |\n250 |                     memory_total = torch.cuda.get_device_properties(i).total_memory / 1024 / 1024\n251 |                     utilization = memory_used / memory_total * 100\n252 |                     \n    | ^^^^^^^^^^^^^^^^^^^^ W293\n253 |                     self.logger.info(f\"GPU {i} - Memory: {memory_used:.2f}/{memory_total:.2f} MB \"\n254 |                                    f\"({utilization:.1f}%)\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/logging.py:268:26: W292 [*] No newline at end of file\n    |\n266 |     if _global_logger is None:\n267 |         _global_logger = setup_logging()\n268 |     return _global_logger\n    |                          ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/utils/monitoring.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n   |\n 1 |   \"\"\"Monitoring and performance profiling for DGDN.\"\"\"\n 2 |\n 3 | / import time\n 4 | | import torch\n 5 | | import psutil\n 6 | | import threading\n 7 | | from typing import Dict, Any, Optional, List, Callable\n 8 | | from collections import defaultdict, deque\n 9 | | import json\n10 | | from pathlib import Path\n11 | | from dataclasses import dataclass, asdict\n12 | | from datetime import datetime\n13 | |\n14 | | from .logging import get_logger\n   | |_______________________________^ I001\n   |\n   = help: Organize imports\n\nsrc/dgdn/utils/monitoring.py:7:47: F401 [*] `typing.Callable` imported but unused\n  |\n5 | import psutil\n6 | import threading\n7 | from typing import Dict, Any, Optional, List, Callable\n  |                                               ^^^^^^^^ F401\n8 | from collections import defaultdict, deque\n9 | import json\n  |\n  = help: Remove unused import: `typing.Callable`\n\nsrc/dgdn/utils/monitoring.py:34:1: W293 [*] Blank line contains whitespace\n   |\n32 | class PerformanceProfiler:\n33 |     \"\"\"Performance profiler for DGDN operations.\"\"\"\n34 |     \n   | ^^^^ W293\n35 |     def __init__(self, enable_gpu_monitoring: bool = True):\n36 |         self.enable_gpu_monitoring = enable_gpu_monitoring and torch.cuda.is_available()\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:41:1: W293 [*] Blank line contains whitespace\n   |\n39 |         self.active_timers: Dict[str, float] = {}\n40 |         self.operation_stats = defaultdict(list)\n41 |         \n   | ^^^^^^^^ W293\n42 |     def start_timer(self, operation_name: str) -> None:\n43 |         \"\"\"Start timing an operation.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:45:1: W293 [*] Blank line contains whitespace\n   |\n43 |         \"\"\"Start timing an operation.\"\"\"\n44 |         self.active_timers[operation_name] = time.time()\n45 |     \n   | ^^^^ W293\n46 |     def end_timer(self, operation_name: str) -> float:\n47 |         \"\"\"End timing an operation and return elapsed time in ms.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:51:1: W293 [*] Blank line contains whitespace\n   |\n49 |             self.logger.warning(f\"Timer '{operation_name}' was not started\")\n50 |             return 0.0\n51 |         \n   | ^^^^^^^^ W293\n52 |         elapsed_ms = (time.time() - self.active_timers[operation_name]) * 1000\n53 |         del self.active_timers[operation_name]\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:54:1: W293 [*] Blank line contains whitespace\n   |\n52 |         elapsed_ms = (time.time() - self.active_timers[operation_name]) * 1000\n53 |         del self.active_timers[operation_name]\n54 |         \n   | ^^^^^^^^ W293\n55 |         self.operation_stats[operation_name].append(elapsed_ms)\n56 |         return elapsed_ms\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:57:1: W293 [*] Blank line contains whitespace\n   |\n55 |         self.operation_stats[operation_name].append(elapsed_ms)\n56 |         return elapsed_ms\n57 |     \n   | ^^^^ W293\n58 |     def profile_memory(self) -> Dict[str, float]:\n59 |         \"\"\"Profile current memory usage.\"\"\"\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:61:1: W293 [*] Blank line contains whitespace\n   |\n59 |         \"\"\"Profile current memory usage.\"\"\"\n60 |         metrics = {}\n61 |         \n   | ^^^^^^^^ W293\n62 |         # CPU memory\n63 |         process = psutil.Process()\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:67:1: W293 [*] Blank line contains whitespace\n   |\n65 |         metrics['cpu_memory_mb'] = memory_info.rss / 1024 / 1024\n66 |         metrics['cpu_percent'] = process.cpu_percent()\n67 |         \n   | ^^^^^^^^ W293\n68 |         # GPU memory\n69 |         if self.enable_gpu_monitoring:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:76:1: W293 [*] Blank line contains whitespace\n   |\n74 |         else:\n75 |             metrics['gpu_memory_mb'] = None\n76 |         \n   | ^^^^^^^^ W293\n77 |         return metrics\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:78:1: W293 [*] Blank line contains whitespace\n   |\n77 |         return metrics\n78 |     \n   | ^^^^ W293\n79 |     def capture_metrics(\n80 |         self,\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:90:1: W293 [*] Blank line contains whitespace\n   |\n88 |         \"\"\"Capture current performance metrics.\"\"\"\n89 |         memory_metrics = self.profile_memory()\n90 |         \n   | ^^^^^^^^ W293\n91 |         metrics = PerformanceMetrics(\n92 |             timestamp=time.time(),\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:103:1: W293 [*] Blank line contains whitespace\n    |\n101 |             num_edges=num_edges\n102 |         )\n103 |         \n    | ^^^^^^^^ W293\n104 |         self.metrics_history.append(metrics)\n105 |         return metrics\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:106:1: W293 [*] Blank line contains whitespace\n    |\n104 |         self.metrics_history.append(metrics)\n105 |         return metrics\n106 |     \n    | ^^^^ W293\n107 |     def get_operation_stats(self, operation_name: str) -> Dict[str, float]:\n108 |         \"\"\"Get statistics for a specific operation.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:111:1: W293 [*] Blank line contains whitespace\n    |\n109 |         if operation_name not in self.operation_stats:\n110 |             return {}\n111 |         \n    | ^^^^^^^^ W293\n112 |         times = self.operation_stats[operation_name]\n113 |         return {\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:120:1: W293 [*] Blank line contains whitespace\n    |\n118 |             'total_ms': sum(times)\n119 |         }\n120 |     \n    | ^^^^ W293\n121 |     def get_summary(self) -> Dict[str, Any]:\n122 |         \"\"\"Get profiling summary.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:128:1: W293 [*] Blank line contains whitespace\n    |\n126 |             'memory_stats': {}\n127 |         }\n128 |         \n    | ^^^^^^^^ W293\n129 |         # Operation statistics\n130 |         for op_name in self.operation_stats:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:132:1: W293 [*] Blank line contains whitespace\n    |\n130 |         for op_name in self.operation_stats:\n131 |             summary['operations'][op_name] = self.get_operation_stats(op_name)\n132 |         \n    | ^^^^^^^^ W293\n133 |         # Memory statistics\n134 |         if self.metrics_history:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:141:1: W293 [*] Blank line contains whitespace\n    |\n139 |                 'max': max(cpu_memory)\n140 |             }\n141 |             \n    | ^^^^^^^^^^^^ W293\n142 |             if self.enable_gpu_monitoring:\n143 |                 gpu_memory = [m.gpu_memory_mb for m in self.metrics_history if m.gpu_memory_mb is not None]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:150:1: W293 [*] Blank line contains whitespace\n    |\n148 |                         'max': max(gpu_memory)\n149 |                     }\n150 |         \n    | ^^^^^^^^ W293\n151 |         return summary\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:152:1: W293 [*] Blank line contains whitespace\n    |\n151 |         return summary\n152 |     \n    | ^^^^ W293\n153 |     def save_metrics(self, file_path: str) -> None:\n154 |         \"\"\"Save metrics to file.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:157:1: W293 [*] Blank line contains whitespace\n    |\n155 |         path = Path(file_path)\n156 |         path.parent.mkdir(parents=True, exist_ok=True)\n157 |         \n    | ^^^^^^^^ W293\n158 |         data = {\n159 |             'summary': self.get_summary(),\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:163:1: W293 [*] Blank line contains whitespace\n    |\n161 |             'operation_stats': dict(self.operation_stats)\n162 |         }\n163 |         \n    | ^^^^^^^^ W293\n164 |         with open(path, 'w') as f:\n165 |             json.dump(data, f, indent=2)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:166:1: W293 [*] Blank line contains whitespace\n    |\n164 |         with open(path, 'w') as f:\n165 |             json.dump(data, f, indent=2)\n166 |         \n    | ^^^^^^^^ W293\n167 |         self.logger.info(f\"Performance metrics saved to {file_path}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:172:1: W293 [*] Blank line contains whitespace\n    |\n170 | class ModelMonitor:\n171 |     \"\"\"Monitor model behavior during training and inference.\"\"\"\n172 |     \n    | ^^^^ W293\n173 |     def __init__(self, model, monitor_gradients: bool = True):\n174 |         self.model = model\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:177:1: W293 [*] Blank line contains whitespace\n    |\n175 |         self.monitor_gradients = monitor_gradients\n176 |         self.logger = get_logger(\"dgdn.model_monitor\")\n177 |         \n    | ^^^^^^^^ W293\n178 |         self.parameter_stats = {}\n179 |         self.gradient_stats = {}\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:182:1: W293 [*] Blank line contains whitespace\n    |\n180 |         self.activation_stats = {}\n181 |         self.hooks = []\n182 |         \n    | ^^^^^^^^ W293\n183 |         if monitor_gradients:\n184 |             self._register_gradient_hooks()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:185:1: W293 [*] Blank line contains whitespace\n    |\n183 |         if monitor_gradients:\n184 |             self._register_gradient_hooks()\n185 |     \n    | ^^^^ W293\n186 |     def _register_gradient_hooks(self) -> None:\n187 |         \"\"\"Register hooks to monitor gradients.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:199:1: W293 [*] Blank line contains whitespace\n    |\n197 |                     }\n198 |             return hook\n199 |         \n    | ^^^^^^^^ W293\n200 |         for name, param in self.model.named_parameters():\n201 |             if param.requires_grad:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:204:1: W293 [*] Blank line contains whitespace\n    |\n202 |                 handle = param.register_hook(gradient_hook(name))\n203 |                 self.hooks.append(handle)\n204 |     \n    | ^^^^ W293\n205 |     def monitor_parameters(self) -> None:\n206 |         \"\"\"Monitor parameter statistics.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:215:1: W293 [*] Blank line contains whitespace\n    |\n213 |                 'norm': param.data.norm().item()\n214 |             }\n215 |     \n    | ^^^^ W293\n216 |     def check_parameter_health(self) -> Dict[str, List[str]]:\n217 |         \"\"\"Check for parameter health issues.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:219:1: W293 [*] Blank line contains whitespace\n    |\n217 |         \"\"\"Check for parameter health issues.\"\"\"\n218 |         issues = defaultdict(list)\n219 |         \n    | ^^^^^^^^ W293\n220 |         for name, stats in self.parameter_stats.items():\n221 |             # Check for NaN or infinite values\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:224:1: W293 [*] Blank line contains whitespace\n    |\n222 |             if not all(torch.isfinite(torch.tensor(v)) for v in stats.values()):\n223 |                 issues['nan_or_inf'].append(name)\n224 |             \n    | ^^^^^^^^^^^^ W293\n225 |             # Check for very large or small values\n226 |             if abs(stats['max']) > 1e6 or abs(stats['min']) > 1e6:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:228:1: W293 [*] Blank line contains whitespace\n    |\n226 |             if abs(stats['max']) > 1e6 or abs(stats['min']) > 1e6:\n227 |                 issues['large_values'].append(name)\n228 |             \n    | ^^^^^^^^^^^^ W293\n229 |             if abs(stats['mean']) < 1e-8 and stats['std'] < 1e-8:\n230 |                 issues['very_small_values'].append(name)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:231:1: W293 [*] Blank line contains whitespace\n    |\n229 |             if abs(stats['mean']) < 1e-8 and stats['std'] < 1e-8:\n230 |                 issues['very_small_values'].append(name)\n231 |         \n    | ^^^^^^^^ W293\n232 |         return dict(issues)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:233:1: W293 [*] Blank line contains whitespace\n    |\n232 |         return dict(issues)\n233 |     \n    | ^^^^ W293\n234 |     def check_gradient_health(self) -> Dict[str, List[str]]:\n235 |         \"\"\"Check for gradient health issues.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:237:1: W293 [*] Blank line contains whitespace\n    |\n235 |         \"\"\"Check for gradient health issues.\"\"\"\n236 |         issues = defaultdict(list)\n237 |         \n    | ^^^^^^^^ W293\n238 |         for name, stats in self.gradient_stats.items():\n239 |             # Check for vanishing gradients\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:242:1: W293 [*] Blank line contains whitespace\n    |\n240 |             if stats['norm'] < 1e-8:\n241 |                 issues['vanishing_gradients'].append(name)\n242 |             \n    | ^^^^^^^^^^^^ W293\n243 |             # Check for exploding gradients\n244 |             if stats['norm'] > 100:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:246:1: W293 [*] Blank line contains whitespace\n    |\n244 |             if stats['norm'] > 100:\n245 |                 issues['exploding_gradients'].append(name)\n246 |             \n    | ^^^^^^^^^^^^ W293\n247 |             # Check for NaN or infinite gradients\n248 |             if not all(torch.isfinite(torch.tensor(v)) for v in stats.values()):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:250:1: W293 [*] Blank line contains whitespace\n    |\n248 |             if not all(torch.isfinite(torch.tensor(v)) for v in stats.values()):\n249 |                 issues['nan_or_inf_gradients'].append(name)\n250 |         \n    | ^^^^^^^^ W293\n251 |         return dict(issues)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:252:1: W293 [*] Blank line contains whitespace\n    |\n251 |         return dict(issues)\n252 |     \n    | ^^^^ W293\n253 |     def get_health_report(self) -> Dict[str, Any]:\n254 |         \"\"\"Get comprehensive health report.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:256:1: W293 [*] Blank line contains whitespace\n    |\n254 |         \"\"\"Get comprehensive health report.\"\"\"\n255 |         self.monitor_parameters()\n256 |         \n    | ^^^^^^^^ W293\n257 |         param_issues = self.check_parameter_health()\n258 |         grad_issues = self.check_gradient_health()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:259:1: W293 [*] Blank line contains whitespace\n    |\n257 |         param_issues = self.check_parameter_health()\n258 |         grad_issues = self.check_gradient_health()\n259 |         \n    | ^^^^^^^^ W293\n260 |         return {\n261 |             'parameter_issues': param_issues,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:267:1: W293 [*] Blank line contains whitespace\n    |\n265 |             'timestamp': datetime.utcnow().isoformat()\n266 |         }\n267 |     \n    | ^^^^ W293\n268 |     def cleanup(self) -> None:\n269 |         \"\"\"Remove hooks and cleanup.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:277:1: W293 [*] Blank line contains whitespace\n    |\n275 | class TrainingMonitor:\n276 |     \"\"\"Monitor training progress and detect issues.\"\"\"\n277 |     \n    | ^^^^ W293\n278 |     def __init__(self, patience: int = 10, min_delta: float = 1e-4):\n279 |         self.patience = patience\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:282:1: W293 [*] Blank line contains whitespace\n    |\n280 |         self.min_delta = min_delta\n281 |         self.logger = get_logger(\"dgdn.training_monitor\")\n282 |         \n    | ^^^^^^^^ W293\n283 |         self.train_losses = deque(maxlen=1000)\n284 |         self.val_losses = deque(maxlen=1000)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:286:1: W293 [*] Blank line contains whitespace\n    |\n284 |         self.val_losses = deque(maxlen=1000)\n285 |         self.learning_rates = deque(maxlen=1000)\n286 |         \n    | ^^^^^^^^ W293\n287 |         self.best_val_loss = float('inf')\n288 |         self.epochs_without_improvement = 0\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:290:1: W293 [*] Blank line contains whitespace\n    |\n288 |         self.epochs_without_improvement = 0\n289 |         self.should_stop = False\n290 |         \n    | ^^^^^^^^ W293\n291 |         self.loss_history = []\n292 |         self.metrics_history = []\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:293:1: W293 [*] Blank line contains whitespace\n    |\n291 |         self.loss_history = []\n292 |         self.metrics_history = []\n293 |     \n    | ^^^^ W293\n294 |     def update(\n295 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:304:1: W293 [*] Blank line contains whitespace\n    |\n302 |         \"\"\"Update monitoring with latest training metrics.\"\"\"\n303 |         self.train_losses.append(train_loss)\n304 |         \n    | ^^^^^^^^ W293\n305 |         if val_loss is not None:\n306 |             self.val_losses.append(val_loss)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:307:1: W293 [*] Blank line contains whitespace\n    |\n305 |         if val_loss is not None:\n306 |             self.val_losses.append(val_loss)\n307 |             \n    | ^^^^^^^^^^^^ W293\n308 |             # Early stopping logic\n309 |             if val_loss < self.best_val_loss - self.min_delta:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:314:1: W293 [*] Blank line contains whitespace\n    |\n312 |             else:\n313 |                 self.epochs_without_improvement += 1\n314 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n315 |             if self.epochs_without_improvement >= self.patience:\n316 |                 self.should_stop = True\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:318:1: W293 [*] Blank line contains whitespace\n    |\n316 |                 self.should_stop = True\n317 |                 self.logger.info(f\"Early stopping triggered after {self.patience} epochs without improvement\")\n318 |         \n    | ^^^^^^^^ W293\n319 |         if learning_rate is not None:\n320 |             self.learning_rates.append(learning_rate)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:321:1: W293 [*] Blank line contains whitespace\n    |\n319 |         if learning_rate is not None:\n320 |             self.learning_rates.append(learning_rate)\n321 |         \n    | ^^^^^^^^ W293\n322 |         # Store history\n323 |         self.loss_history.append({\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:329:1: W293 [*] Blank line contains whitespace\n    |\n327 |             'learning_rate': learning_rate\n328 |         })\n329 |         \n    | ^^^^^^^^ W293\n330 |         if metrics:\n331 |             self.metrics_history.append({\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:335:1: W293 [*] Blank line contains whitespace\n    |\n333 |                 **metrics\n334 |             })\n335 |     \n    | ^^^^ W293\n336 |     def detect_training_issues(self) -> List[str]:\n337 |         \"\"\"Detect potential training issues.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:339:1: W293 [*] Blank line contains whitespace\n    |\n337 |         \"\"\"Detect potential training issues.\"\"\"\n338 |         issues = []\n339 |         \n    | ^^^^^^^^ W293\n340 |         if len(self.train_losses) < 5:\n341 |             return issues\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:342:1: W293 [*] Blank line contains whitespace\n    |\n340 |         if len(self.train_losses) < 5:\n341 |             return issues\n342 |         \n    | ^^^^^^^^ W293\n343 |         recent_losses = list(self.train_losses)[-5:]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:344:1: W293 [*] Blank line contains whitespace\n    |\n343 |         recent_losses = list(self.train_losses)[-5:]\n344 |         \n    | ^^^^^^^^ W293\n345 |         # Check for non-decreasing loss\n346 |         if all(recent_losses[i] >= recent_losses[i-1] for i in range(1, len(recent_losses))):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:348:1: W293 [*] Blank line contains whitespace\n    |\n346 |         if all(recent_losses[i] >= recent_losses[i-1] for i in range(1, len(recent_losses))):\n347 |             issues.append(\"Training loss not decreasing\")\n348 |         \n    | ^^^^^^^^ W293\n349 |         # Check for loss explosion\n350 |         if recent_losses[-1] > recent_losses[0] * 10:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:352:1: W293 [*] Blank line contains whitespace\n    |\n350 |         if recent_losses[-1] > recent_losses[0] * 10:\n351 |             issues.append(\"Training loss exploding\")\n352 |         \n    | ^^^^^^^^ W293\n353 |         # Check for loss plateauing\n354 |         if len(recent_losses) >= 5:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:358:1: W293 [*] Blank line contains whitespace\n    |\n356 |             if loss_variance < 1e-8:\n357 |                 issues.append(\"Training loss plateaued\")\n358 |         \n    | ^^^^^^^^ W293\n359 |         # Check for oscillating loss\n360 |         if len(recent_losses) >= 4:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:365:1: W293 [*] Blank line contains whitespace\n    |\n363 |             if sign_changes >= len(diffs) - 1:\n364 |                 issues.append(\"Training loss oscillating\")\n365 |         \n    | ^^^^^^^^ W293\n366 |         return issues\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:367:1: W293 [*] Blank line contains whitespace\n    |\n366 |         return issues\n367 |     \n    | ^^^^ W293\n368 |     def get_training_summary(self) -> Dict[str, Any]:\n369 |         \"\"\"Get training summary.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:377:1: W293 [*] Blank line contains whitespace\n    |\n375 |             'detected_issues': self.detect_training_issues()\n376 |         }\n377 |         \n    | ^^^^^^^^ W293\n378 |         if self.train_losses:\n379 |             recent_train_losses = list(self.train_losses)[-10:]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:385:1: W293 [*] Blank line contains whitespace\n    |\n383 |                 'improvement': recent_train_losses[0] - recent_train_losses[-1] if len(recent_train_losses) > 1 else 0\n384 |             }\n385 |         \n    | ^^^^^^^^ W293\n386 |         if self.val_losses:\n387 |             recent_val_losses = list(self.val_losses)[-10:]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:393:1: W293 [*] Blank line contains whitespace\n    |\n391 |                 'improvement': recent_val_losses[0] - recent_val_losses[-1] if len(recent_val_losses) > 1 else 0\n392 |             }\n393 |         \n    | ^^^^^^^^ W293\n394 |         return summary\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:399:1: W293 [*] Blank line contains whitespace\n    |\n397 | class SystemMonitor:\n398 |     \"\"\"Monitor system resources during training.\"\"\"\n399 |     \n    | ^^^^ W293\n400 |     def __init__(self, monitoring_interval: float = 1.0):\n401 |         self.monitoring_interval = monitoring_interval\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:403:1: W293 [*] Blank line contains whitespace\n    |\n401 |         self.monitoring_interval = monitoring_interval\n402 |         self.logger = get_logger(\"dgdn.system_monitor\")\n403 |         \n    | ^^^^^^^^ W293\n404 |         self.monitoring = False\n405 |         self.monitor_thread = None\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:407:1: W293 [*] Blank line contains whitespace\n    |\n405 |         self.monitor_thread = None\n406 |         self.metrics = []\n407 |         \n    | ^^^^^^^^ W293\n408 |     def start_monitoring(self) -> None:\n409 |         \"\"\"Start system monitoring in background thread.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:413:1: W293 [*] Blank line contains whitespace\n    |\n411 |             self.logger.warning(\"Monitoring already started\")\n412 |             return\n413 |         \n    | ^^^^^^^^ W293\n414 |         self.monitoring = True\n415 |         self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:418:1: W293 [*] Blank line contains whitespace\n    |\n416 |         self.monitor_thread.start()\n417 |         self.logger.info(\"System monitoring started\")\n418 |     \n    | ^^^^ W293\n419 |     def stop_monitoring(self) -> None:\n420 |         \"\"\"Stop system monitoring.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:425:1: W293 [*] Blank line contains whitespace\n    |\n423 |             self.monitor_thread.join(timeout=2.0)\n424 |         self.logger.info(\"System monitoring stopped\")\n425 |     \n    | ^^^^ W293\n426 |     def _monitor_loop(self) -> None:\n427 |         \"\"\"Background monitoring loop.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:436:1: W293 [*] Blank line contains whitespace\n    |\n434 |                     'disk_usage_percent': psutil.disk_usage('/').percent\n435 |                 }\n436 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n437 |                 # GPU metrics if available\n438 |                 if torch.cuda.is_available():\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:444:1: W293 [*] Blank line contains whitespace\n    |\n442 |                         reserved = torch.cuda.memory_reserved(i)\n443 |                         total = torch.cuda.get_device_properties(i).total_memory\n444 |                         \n    | ^^^^^^^^^^^^^^^^^^^^^^^^ W293\n445 |                         gpu_metrics[f'gpu_{i}_memory_allocated_percent'] = (allocated / total) * 100\n446 |                         gpu_metrics[f'gpu_{i}_memory_reserved_percent'] = (reserved / total) * 100\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:447:1: W293 [*] Blank line contains whitespace\n    |\n445 |                         gpu_metrics[f'gpu_{i}_memory_allocated_percent'] = (allocated / total) * 100\n446 |                         gpu_metrics[f'gpu_{i}_memory_reserved_percent'] = (reserved / total) * 100\n447 |                     \n    | ^^^^^^^^^^^^^^^^^^^^ W293\n448 |                     metrics.update(gpu_metrics)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:449:1: W293 [*] Blank line contains whitespace\n    |\n448 |                     metrics.update(gpu_metrics)\n449 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n450 |                 self.metrics.append(metrics)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:451:1: W293 [*] Blank line contains whitespace\n    |\n450 |                 self.metrics.append(metrics)\n451 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n452 |                 # Keep only last 1000 measurements\n453 |                 if len(self.metrics) > 1000:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:455:1: W293 [*] Blank line contains whitespace\n    |\n453 |                 if len(self.metrics) > 1000:\n454 |                     self.metrics = self.metrics[-1000:]\n455 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n456 |                 time.sleep(self.monitoring_interval)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:457:1: W293 [*] Blank line contains whitespace\n    |\n456 |                 time.sleep(self.monitoring_interval)\n457 |                 \n    | ^^^^^^^^^^^^^^^^ W293\n458 |             except Exception as e:\n459 |                 self.logger.error(f\"Error in monitoring loop: {e}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:460:1: W293 [*] Blank line contains whitespace\n    |\n458 |             except Exception as e:\n459 |                 self.logger.error(f\"Error in monitoring loop: {e}\")\n460 |     \n    | ^^^^ W293\n461 |     def get_current_metrics(self) -> Dict[str, Any]:\n462 |         \"\"\"Get current system metrics.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:466:1: W293 [*] Blank line contains whitespace\n    |\n464 |             return {}\n465 |         return self.metrics[-1].copy()\n466 |     \n    | ^^^^ W293\n467 |     def get_metrics_summary(self) -> Dict[str, Any]:\n468 |         \"\"\"Get summary of collected metrics.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:471:1: W293 [*] Blank line contains whitespace\n    |\n469 |         if not self.metrics:\n470 |             return {}\n471 |         \n    | ^^^^^^^^ W293\n472 |         # Calculate statistics for each metric\n473 |         summary = {}\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:475:1: W293 [*] Blank line contains whitespace\n    |\n473 |         summary = {}\n474 |         metric_names = ['cpu_percent', 'memory_percent', 'disk_usage_percent']\n475 |         \n    | ^^^^^^^^ W293\n476 |         for metric_name in metric_names:\n477 |             values = [m[metric_name] for m in self.metrics if metric_name in m]\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:485:1: W293 [*] Blank line contains whitespace\n    |\n483 |                     'current': values[-1]\n484 |                 }\n485 |         \n    | ^^^^^^^^ W293\n486 |         return summary\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/monitoring.py:486:23: W292 [*] No newline at end of file\n    |\n484 |                 }\n485 |         \n486 |         return summary\n    |                       ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/utils/security.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n   |\n 1 |   \"\"\"Security utilities for DGDN.\"\"\"\n 2 |\n 3 | / import torch\n 4 | | import hashlib\n 5 | | import pickle\n 6 | | import tempfile\n 7 | | import os\n 8 | | from typing import Any, Dict, List, Optional, Union\n 9 | | from pathlib import Path\n10 | | import warnings\n11 | |\n12 | | from .logging import get_logger\n13 | | from .validation import validate_tensor_properties\n   | |__________________________________________________^ I001\n   |\n   = help: Organize imports\n\nsrc/dgdn/utils/security.py:5:8: F401 [*] `pickle` imported but unused\n  |\n3 | import torch\n4 | import hashlib\n5 | import pickle\n  |        ^^^^^^ F401\n6 | import tempfile\n7 | import os\n  |\n  = help: Remove unused import: `pickle`\n\nsrc/dgdn/utils/security.py:8:31: F401 [*] `typing.List` imported but unused\n   |\n 6 | import tempfile\n 7 | import os\n 8 | from typing import Any, Dict, List, Optional, Union\n   |                               ^^^^ F401\n 9 | from pathlib import Path\n10 | import warnings\n   |\n   = help: Remove unused import\n\nsrc/dgdn/utils/security.py:8:37: F401 [*] `typing.Optional` imported but unused\n   |\n 6 | import tempfile\n 7 | import os\n 8 | from typing import Any, Dict, List, Optional, Union\n   |                                     ^^^^^^^^ F401\n 9 | from pathlib import Path\n10 | import warnings\n   |\n   = help: Remove unused import\n\nsrc/dgdn/utils/security.py:10:8: F401 [*] `warnings` imported but unused\n   |\n 8 | from typing import Any, Dict, List, Optional, Union\n 9 | from pathlib import Path\n10 | import warnings\n   |        ^^^^^^^^ F401\n11 |\n12 | from .logging import get_logger\n   |\n   = help: Remove unused import: `warnings`\n\nsrc/dgdn/utils/security.py:13:25: F401 [*] `.validation.validate_tensor_properties` imported but unused\n   |\n12 | from .logging import get_logger\n13 | from .validation import validate_tensor_properties\n   |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^ F401\n   |\n   = help: Remove unused import: `.validation.validate_tensor_properties`\n\nsrc/dgdn/utils/security.py:18:1: W293 [*] Blank line contains whitespace\n   |\n16 | class SecurityValidator:\n17 |     \"\"\"Security validator for DGDN inputs and models.\"\"\"\n18 |     \n   | ^^^^ W293\n19 |     def __init__(self, enable_strict_mode: bool = True):\n20 |         self.enable_strict_mode = enable_strict_mode\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:22:1: W293 [*] Blank line contains whitespace\n   |\n20 |         self.enable_strict_mode = enable_strict_mode\n21 |         self.logger = get_logger(\"dgdn.security\")\n22 |         \n   | ^^^^^^^^ W293\n23 |         # Define security limits\n24 |         self.max_tensor_size = 1e9  # 1B elements\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:32:1: W293 [*] Blank line contains whitespace\n   |\n30 |         }\n31 |         self.blocked_operations = set()\n32 |     \n   | ^^^^ W293\n33 |     def validate_tensor_security(self, tensor: torch.Tensor, name: str = \"tensor\") -> bool:\n34 |         \"\"\"Validate tensor for security issues.\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:35:1: W293 Blank line contains whitespace\n   |\n33 |     def validate_tensor_security(self, tensor: torch.Tensor, name: str = \"tensor\") -> bool:\n34 |         \"\"\"Validate tensor for security issues.\n35 |         \n   | ^^^^^^^^ W293\n36 |         Args:\n37 |             tensor: Tensor to validate\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:39:1: W293 Blank line contains whitespace\n   |\n37 |             tensor: Tensor to validate\n38 |             name: Name for logging\n39 |             \n   | ^^^^^^^^^^^^ W293\n40 |         Returns:\n41 |             True if validation passes\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:42:1: W293 Blank line contains whitespace\n   |\n40 |         Returns:\n41 |             True if validation passes\n42 |             \n   | ^^^^^^^^^^^^ W293\n43 |         Raises:\n44 |             SecurityError: If security issues are found\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:49:1: W293 [*] Blank line contains whitespace\n   |\n47 |         if tensor.numel() > self.max_tensor_size:\n48 |             raise SecurityError(f\"Tensor {name} too large: {tensor.numel()} > {self.max_tensor_size}\")\n49 |         \n   | ^^^^^^^^ W293\n50 |         # Check memory usage\n51 |         memory_mb = tensor.element_size() * tensor.numel() / (1024 * 1024)\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:54:1: W293 [*] Blank line contains whitespace\n   |\n52 |         if memory_mb > self.max_memory_mb:\n53 |             raise SecurityError(f\"Tensor {name} requires too much memory: {memory_mb:.2f} MB > {self.max_memory_mb} MB\")\n54 |         \n   | ^^^^^^^^ W293\n55 |         # Check data type\n56 |         if tensor.dtype not in self.allowed_dtypes:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:58:1: W293 [*] Blank line contains whitespace\n   |\n56 |         if tensor.dtype not in self.allowed_dtypes:\n57 |             raise SecurityError(f\"Tensor {name} has disallowed dtype: {tensor.dtype}\")\n58 |         \n   | ^^^^^^^^ W293\n59 |         # Check for suspicious values\n60 |         if torch.isnan(tensor).any():\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:65:1: W293 [*] Blank line contains whitespace\n   |\n63 |             else:\n64 |                 self.logger.warning(f\"Tensor {name} contains NaN values\")\n65 |         \n   | ^^^^^^^^ W293\n66 |         if torch.isinf(tensor).any():\n67 |             if self.enable_strict_mode:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:71:1: W293 [*] Blank line contains whitespace\n   |\n69 |             else:\n70 |                 self.logger.warning(f\"Tensor {name} contains infinite values\")\n71 |         \n   | ^^^^^^^^ W293\n72 |         # Check for extremely large values that could cause overflow\n73 |         max_val = tensor.abs().max().item()\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:76:1: W293 [*] Blank line contains whitespace\n   |\n74 |         if max_val > 1e6:\n75 |             self.logger.warning(f\"Tensor {name} contains very large values: max={max_val}\")\n76 |         \n   | ^^^^^^^^ W293\n77 |         self.logger.debug(f\"Security validation passed for tensor {name}\")\n78 |         return True\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:79:1: W293 [*] Blank line contains whitespace\n   |\n77 |         self.logger.debug(f\"Security validation passed for tensor {name}\")\n78 |         return True\n79 |     \n   | ^^^^ W293\n80 |     def validate_file_security(self, file_path: Union[str, Path]) -> bool:\n81 |         \"\"\"Validate file for security issues.\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:82:1: W293 Blank line contains whitespace\n   |\n80 |     def validate_file_security(self, file_path: Union[str, Path]) -> bool:\n81 |         \"\"\"Validate file for security issues.\n82 |         \n   | ^^^^^^^^ W293\n83 |         Args:\n84 |             file_path: Path to file\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:85:1: W293 Blank line contains whitespace\n   |\n83 |         Args:\n84 |             file_path: Path to file\n85 |             \n   | ^^^^^^^^^^^^ W293\n86 |         Returns:\n87 |             True if validation passes\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:88:1: W293 Blank line contains whitespace\n   |\n86 |         Returns:\n87 |             True if validation passes\n88 |             \n   | ^^^^^^^^^^^^ W293\n89 |         Raises:\n90 |             SecurityError: If security issues are found\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:93:1: W293 [*] Blank line contains whitespace\n   |\n91 |         \"\"\"\n92 |         path = Path(file_path)\n93 |         \n   | ^^^^^^^^ W293\n94 |         # Check file exists and is actually a file\n95 |         if not path.exists():\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:97:1: W293 [*] Blank line contains whitespace\n   |\n95 |         if not path.exists():\n96 |             raise SecurityError(f\"File does not exist: {path}\")\n97 |         \n   | ^^^^^^^^ W293\n98 |         if not path.is_file():\n99 |             raise SecurityError(f\"Path is not a file: {path}\")\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:100:1: W293 [*] Blank line contains whitespace\n    |\n 98 |         if not path.is_file():\n 99 |             raise SecurityError(f\"Path is not a file: {path}\")\n100 |         \n    | ^^^^^^^^ W293\n101 |         # Check file size\n102 |         file_size_mb = path.stat().st_size / (1024 * 1024)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:105:1: W293 [*] Blank line contains whitespace\n    |\n103 |         if file_size_mb > self.max_memory_mb:\n104 |             raise SecurityError(f\"File too large: {file_size_mb:.2f} MB > {self.max_memory_mb} MB\")\n105 |         \n    | ^^^^^^^^ W293\n106 |         # Check file extension\n107 |         allowed_extensions = {'.pt', '.pth', '.pkl', '.json', '.yaml', '.yml'}\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:113:1: W293 [*] Blank line contains whitespace\n    |\n111 |             else:\n112 |                 self.logger.warning(f\"File extension not typically safe: {path.suffix}\")\n113 |         \n    | ^^^^^^^^ W293\n114 |         # Check for suspicious file names\n115 |         suspicious_patterns = ['../', '..\\\\', '~/', '/etc/', '/proc/', 'C:\\\\Windows\\\\']\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:120:1: W293 [*] Blank line contains whitespace\n    |\n118 |             if pattern in path_str:\n119 |                 raise SecurityError(f\"Suspicious file path pattern: {pattern} in {path}\")\n120 |         \n    | ^^^^^^^^ W293\n121 |         self.logger.debug(f\"Security validation passed for file {path}\")\n122 |         return True\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:123:1: W293 [*] Blank line contains whitespace\n    |\n121 |         self.logger.debug(f\"Security validation passed for file {path}\")\n122 |         return True\n123 |     \n    | ^^^^ W293\n124 |     def validate_model_state(self, state_dict: Dict[str, torch.Tensor]) -> bool:\n125 |         \"\"\"Validate model state dictionary for security issues.\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:126:1: W293 Blank line contains whitespace\n    |\n124 |     def validate_model_state(self, state_dict: Dict[str, torch.Tensor]) -> bool:\n125 |         \"\"\"Validate model state dictionary for security issues.\n126 |         \n    | ^^^^^^^^ W293\n127 |         Args:\n128 |             state_dict: Model state dictionary\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:129:1: W293 Blank line contains whitespace\n    |\n127 |         Args:\n128 |             state_dict: Model state dictionary\n129 |             \n    | ^^^^^^^^^^^^ W293\n130 |         Returns:\n131 |             True if validation passes\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:134:1: W293 [*] Blank line contains whitespace\n    |\n132 |         \"\"\"\n133 |         total_params = 0\n134 |         \n    | ^^^^^^^^ W293\n135 |         for name, tensor in state_dict.items():\n136 |             self.validate_tensor_security(tensor, f\"parameter_{name}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:138:1: W293 [*] Blank line contains whitespace\n    |\n136 |             self.validate_tensor_security(tensor, f\"parameter_{name}\")\n137 |             total_params += tensor.numel()\n138 |         \n    | ^^^^^^^^ W293\n139 |         # Check total model size\n140 |         if total_params > 1e9:  # 1B parameters\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:142:1: W293 [*] Blank line contains whitespace\n    |\n140 |         if total_params > 1e9:  # 1B parameters\n141 |             self.logger.warning(f\"Model has very large number of parameters: {total_params:,}\")\n142 |         \n    | ^^^^^^^^ W293\n143 |         self.logger.info(f\"Model state validation passed: {len(state_dict)} parameters, {total_params:,} total elements\")\n144 |         return True\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:154:1: W293 Blank line contains whitespace\n    |\n152 | def sanitize_input(data: Any, max_string_length: int = 1000) -> Any:\n153 |     \"\"\"Sanitize input data for security.\n154 |     \n    | ^^^^ W293\n155 |     Args:\n156 |         data: Data to sanitize\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:158:1: W293 Blank line contains whitespace\n    |\n156 |         data: Data to sanitize\n157 |         max_string_length: Maximum allowed string length\n158 |         \n    | ^^^^^^^^ W293\n159 |     Returns:\n160 |         Sanitized data\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:163:1: W293 [*] Blank line contains whitespace\n    |\n161 |     \"\"\"\n162 |     logger = get_logger(\"dgdn.security\")\n163 |     \n    | ^^^^ W293\n164 |     if isinstance(data, str):\n165 |         # Limit string length\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:169:1: W293 [*] Blank line contains whitespace\n    |\n167 |             logger.warning(f\"String truncated from {len(data)} to {max_string_length} characters\")\n168 |             data = data[:max_string_length]\n169 |         \n    | ^^^^^^^^ W293\n170 |         # Remove potentially dangerous characters\n171 |         dangerous_chars = ['<', '>', '\"', \"'\", '&', '\\x00']\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:176:1: W293 [*] Blank line contains whitespace\n    |\n174 |                 data = data.replace(char, '')\n175 |                 logger.warning(f\"Removed dangerous character: {char}\")\n176 |     \n    | ^^^^ W293\n177 |     elif isinstance(data, (list, tuple)):\n178 |         # Recursively sanitize list/tuple elements\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:183:1: W293 [*] Blank line contains whitespace\n    |\n181 |             sanitized.append(sanitize_input(item, max_string_length))\n182 |         return type(data)(sanitized)\n183 |     \n    | ^^^^ W293\n184 |     elif isinstance(data, dict):\n185 |         # Recursively sanitize dictionary values\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:192:1: W293 [*] Blank line contains whitespace\n    |\n190 |             sanitized[clean_key] = clean_value\n191 |         return sanitized\n192 |     \n    | ^^^^ W293\n193 |     elif isinstance(data, torch.Tensor):\n194 |         # Validate tensor security\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:197:1: W293 [*] Blank line contains whitespace\n    |\n195 |         validator = SecurityValidator()\n196 |         validator.validate_tensor_security(data)\n197 |     \n    | ^^^^ W293\n198 |     return data\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:203:1: W293 Blank line contains whitespace\n    |\n201 | def compute_model_hash(model) -> str:\n202 |     \"\"\"Compute cryptographic hash of model parameters.\n203 |     \n    | ^^^^ W293\n204 |     Args:\n205 |         model: PyTorch model\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:206:1: W293 Blank line contains whitespace\n    |\n204 |     Args:\n205 |         model: PyTorch model\n206 |         \n    | ^^^^^^^^ W293\n207 |     Returns:\n208 |         SHA256 hash of model parameters\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:211:1: W293 [*] Blank line contains whitespace\n    |\n209 |     \"\"\"\n210 |     hasher = hashlib.sha256()\n211 |     \n    | ^^^^ W293\n212 |     for name, param in model.named_parameters():\n213 |         # Convert parameter to bytes and update hash\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:217:1: W293 [*] Blank line contains whitespace\n    |\n215 |         hasher.update(param_bytes)\n216 |         hasher.update(name.encode('utf-8'))  # Include parameter name\n217 |     \n    | ^^^^ W293\n218 |     return hasher.hexdigest()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:223:1: W293 Blank line contains whitespace\n    |\n221 | def check_model_integrity(model, expected_hash: str) -> bool:\n222 |     \"\"\"Check if model parameters match expected hash.\n223 |     \n    | ^^^^ W293\n224 |     Args:\n225 |         model: PyTorch model\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:227:1: W293 Blank line contains whitespace\n    |\n225 |         model: PyTorch model\n226 |         expected_hash: Expected SHA256 hash\n227 |         \n    | ^^^^^^^^ W293\n228 |     Returns:\n229 |         True if integrity check passes\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:230:1: W293 Blank line contains whitespace\n    |\n228 |     Returns:\n229 |         True if integrity check passes\n230 |         \n    | ^^^^^^^^ W293\n231 |     Raises:\n232 |         SecurityError: If integrity check fails\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:235:1: W293 [*] Blank line contains whitespace\n    |\n233 |     \"\"\"\n234 |     logger = get_logger(\"dgdn.security\")\n235 |     \n    | ^^^^ W293\n236 |     current_hash = compute_model_hash(model)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:237:1: W293 [*] Blank line contains whitespace\n    |\n236 |     current_hash = compute_model_hash(model)\n237 |     \n    | ^^^^ W293\n238 |     if current_hash != expected_hash:\n239 |         raise SecurityError(f\"Model integrity check failed: {current_hash} != {expected_hash}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:240:1: W293 [*] Blank line contains whitespace\n    |\n238 |     if current_hash != expected_hash:\n239 |         raise SecurityError(f\"Model integrity check failed: {current_hash} != {expected_hash}\")\n240 |     \n    | ^^^^ W293\n241 |     logger.info(\"Model integrity check passed\")\n242 |     return True\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:247:1: W293 Blank line contains whitespace\n    |\n245 | def secure_model_save(model, file_path: Union[str, Path], include_hash: bool = True) -> str:\n246 |     \"\"\"Securely save model with integrity hash.\n247 |     \n    | ^^^^ W293\n248 |     Args:\n249 |         model: PyTorch model to save\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:252:1: W293 Blank line contains whitespace\n    |\n250 |         file_path: Path to save model\n251 |         include_hash: Whether to include integrity hash\n252 |         \n    | ^^^^^^^^ W293\n253 |     Returns:\n254 |         Model hash if include_hash is True\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:258:1: W293 [*] Blank line contains whitespace\n    |\n256 |     logger = get_logger(\"dgdn.security\")\n257 |     path = Path(file_path)\n258 |     \n    | ^^^^ W293\n259 |     # Validate output path\n260 |     validator = SecurityValidator()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:260:5: F841 Local variable `validator` is assigned to but never used\n    |\n259 |     # Validate output path\n260 |     validator = SecurityValidator()\n    |     ^^^^^^^^^ F841\n261 |     \n262 |     # Create parent directory if needed\n    |\n    = help: Remove assignment to unused variable `validator`\n\nsrc/dgdn/utils/security.py:261:1: W293 [*] Blank line contains whitespace\n    |\n259 |     # Validate output path\n260 |     validator = SecurityValidator()\n261 |     \n    | ^^^^ W293\n262 |     # Create parent directory if needed\n263 |     path.parent.mkdir(parents=True, exist_ok=True)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:264:1: W293 [*] Blank line contains whitespace\n    |\n262 |     # Create parent directory if needed\n263 |     path.parent.mkdir(parents=True, exist_ok=True)\n264 |     \n    | ^^^^ W293\n265 |     # Compute hash before saving\n266 |     model_hash = compute_model_hash(model) if include_hash else None\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:267:1: W293 [*] Blank line contains whitespace\n    |\n265 |     # Compute hash before saving\n266 |     model_hash = compute_model_hash(model) if include_hash else None\n267 |     \n    | ^^^^ W293\n268 |     # Save model\n269 |     torch.save(model.state_dict(), path)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:270:1: W293 [*] Blank line contains whitespace\n    |\n268 |     # Save model\n269 |     torch.save(model.state_dict(), path)\n270 |     \n    | ^^^^ W293\n271 |     # Save hash file if requested\n272 |     if include_hash:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:277:1: W293 [*] Blank line contains whitespace\n    |\n275 |             f.write(model_hash)\n276 |         logger.info(f\"Model saved with integrity hash: {hash_path}\")\n277 |     \n    | ^^^^ W293\n278 |     logger.info(f\"Model securely saved to: {path}\")\n279 |     return model_hash\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:284:1: W293 Blank line contains whitespace\n    |\n282 | def secure_model_load(model, file_path: Union[str, Path], verify_hash: bool = True):\n283 |     \"\"\"Securely load model with integrity verification.\n284 |     \n    | ^^^^ W293\n285 |     Args:\n286 |         model: PyTorch model to load state into\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:289:1: W293 Blank line contains whitespace\n    |\n287 |         file_path: Path to load model from\n288 |         verify_hash: Whether to verify integrity hash\n289 |         \n    | ^^^^^^^^ W293\n290 |     Returns:\n291 |         Loaded model\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:292:1: W293 Blank line contains whitespace\n    |\n290 |     Returns:\n291 |         Loaded model\n292 |         \n    | ^^^^^^^^ W293\n293 |     Raises:\n294 |         SecurityError: If security validation fails\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:298:1: W293 [*] Blank line contains whitespace\n    |\n296 |     logger = get_logger(\"dgdn.security\")\n297 |     path = Path(file_path)\n298 |     \n    | ^^^^ W293\n299 |     # Validate file security\n300 |     validator = SecurityValidator()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:302:1: W293 [*] Blank line contains whitespace\n    |\n300 |     validator = SecurityValidator()\n301 |     validator.validate_file_security(path)\n302 |     \n    | ^^^^ W293\n303 |     # Load model state\n304 |     try:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:307:9: B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling\n    |\n305 |         state_dict = torch.load(path, map_location='cpu')\n306 |     except Exception as e:\n307 |         raise SecurityError(f\"Failed to load model: {e}\")\n    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ B904\n308 |     \n309 |     # Validate state dictionary\n    |\n\nsrc/dgdn/utils/security.py:308:1: W293 [*] Blank line contains whitespace\n    |\n306 |     except Exception as e:\n307 |         raise SecurityError(f\"Failed to load model: {e}\")\n308 |     \n    | ^^^^ W293\n309 |     # Validate state dictionary\n310 |     validator.validate_model_state(state_dict)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:311:1: W293 [*] Blank line contains whitespace\n    |\n309 |     # Validate state dictionary\n310 |     validator.validate_model_state(state_dict)\n311 |     \n    | ^^^^ W293\n312 |     # Load state into model\n313 |     model.load_state_dict(state_dict)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:314:1: W293 [*] Blank line contains whitespace\n    |\n312 |     # Load state into model\n313 |     model.load_state_dict(state_dict)\n314 |     \n    | ^^^^ W293\n315 |     # Verify hash if requested\n316 |     if verify_hash:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:319:34: UP015 [*] Unnecessary mode argument\n    |\n317 |         hash_path = path.with_suffix(path.suffix + '.hash')\n318 |         if hash_path.exists():\n319 |             with open(hash_path, 'r') as f:\n    |                                  ^^^ UP015\n320 |                 expected_hash = f.read().strip()\n321 |             check_model_integrity(model, expected_hash)\n    |\n    = help: Remove mode argument\n\nsrc/dgdn/utils/security.py:324:1: W293 [*] Blank line contains whitespace\n    |\n322 |         else:\n323 |             logger.warning(f\"Hash file not found: {hash_path}\")\n324 |     \n    | ^^^^ W293\n325 |     logger.info(f\"Model securely loaded from: {path}\")\n326 |     return model\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:331:1: W293 [*] Blank line contains whitespace\n    |\n329 | class DifferentialPrivacyManager:\n330 |     \"\"\"Manager for differential privacy during training.\"\"\"\n331 |     \n    | ^^^^ W293\n332 |     def __init__(\n333 |         self,\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:344:1: W293 [*] Blank line contains whitespace\n    |\n342 |         self.enable_privacy = enable_privacy\n343 |         self.logger = get_logger(\"dgdn.privacy\")\n344 |         \n    | ^^^^^^^^ W293\n345 |         if enable_privacy:\n346 |             self.logger.info(f\"Differential privacy enabled: noise={noise_multiplier}, \"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:348:1: W293 [*] Blank line contains whitespace\n    |\n346 |             self.logger.info(f\"Differential privacy enabled: noise={noise_multiplier}, \"\n347 |                            f\"max_grad_norm={max_grad_norm}, sample_rate={sample_rate}\")\n348 |     \n    | ^^^^ W293\n349 |     def add_noise_to_gradients(self, model) -> None:\n350 |         \"\"\"Add calibrated noise to model gradients for differential privacy.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:353:1: W293 [*] Blank line contains whitespace\n    |\n351 |         if not self.enable_privacy:\n352 |             return\n353 |         \n    | ^^^^^^^^ W293\n354 |         # Clip gradients first\n355 |         torch.nn.utils.clip_grad_norm_(model.parameters(), self.max_grad_norm)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:356:1: W293 [*] Blank line contains whitespace\n    |\n354 |         # Clip gradients first\n355 |         torch.nn.utils.clip_grad_norm_(model.parameters(), self.max_grad_norm)\n356 |         \n    | ^^^^^^^^ W293\n357 |         # Add noise to gradients\n358 |         for param in model.parameters():\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:367:1: W293 [*] Blank line contains whitespace\n    |\n365 |                 )\n366 |                 param.grad += noise\n367 |         \n    | ^^^^^^^^ W293\n368 |         self.logger.debug(\"Added differential privacy noise to gradients\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:369:1: W293 [*] Blank line contains whitespace\n    |\n368 |         self.logger.debug(\"Added differential privacy noise to gradients\")\n369 |     \n    | ^^^^ W293\n370 |     def compute_privacy_budget(self, num_epochs: int, num_samples: int) -> float:\n371 |         \"\"\"Compute privacy budget (epsilon) for given training parameters.\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:372:1: W293 Blank line contains whitespace\n    |\n370 |     def compute_privacy_budget(self, num_epochs: int, num_samples: int) -> float:\n371 |         \"\"\"Compute privacy budget (epsilon) for given training parameters.\n372 |         \n    | ^^^^^^^^ W293\n373 |         Args:\n374 |             num_epochs: Number of training epochs\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:376:1: W293 Blank line contains whitespace\n    |\n374 |             num_epochs: Number of training epochs\n375 |             num_samples: Total number of training samples\n376 |             \n    | ^^^^^^^^^^^^ W293\n377 |         Returns:\n378 |             Privacy budget (epsilon)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:382:1: W293 [*] Blank line contains whitespace\n    |\n380 |         if not self.enable_privacy:\n381 |             return float('inf')\n382 |         \n    | ^^^^^^^^ W293\n383 |         # Simplified privacy budget calculation\n384 |         # In practice, use proper accounting methods like RDP\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:387:1: W293 [*] Blank line contains whitespace\n    |\n385 |         q = self.sample_rate\n386 |         steps = num_epochs * (num_samples // int(num_samples * q))\n387 |         \n    | ^^^^^^^^ W293\n388 |         # Rough approximation - use proper privacy accounting in production\n389 |         epsilon = steps * q * q / (2 * self.noise_multiplier * self.noise_multiplier)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:390:1: W293 [*] Blank line contains whitespace\n    |\n388 |         # Rough approximation - use proper privacy accounting in production\n389 |         epsilon = steps * q * q / (2 * self.noise_multiplier * self.noise_multiplier)\n390 |         \n    | ^^^^^^^^ W293\n391 |         self.logger.info(f\"Estimated privacy budget: \u03b5 = {epsilon:.4f}\")\n392 |         return epsilon\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:397:1: W293 Blank line contains whitespace\n    |\n395 | def create_secure_temp_file(suffix: str = \".tmp\") -> str:\n396 |     \"\"\"Create a secure temporary file.\n397 |     \n    | ^^^^ W293\n398 |     Args:\n399 |         suffix: File suffix\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:400:1: W293 Blank line contains whitespace\n    |\n398 |     Args:\n399 |         suffix: File suffix\n400 |         \n    | ^^^^^^^^ W293\n401 |     Returns:\n402 |         Path to secure temporary file\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:406:1: W293 [*] Blank line contains whitespace\n    |\n404 |     # Create temporary file with restricted permissions\n405 |     fd, temp_path = tempfile.mkstemp(suffix=suffix)\n406 |     \n    | ^^^^ W293\n407 |     # Set restrictive permissions (owner read/write only)\n408 |     os.chmod(temp_path, 0o600)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:409:1: W293 [*] Blank line contains whitespace\n    |\n407 |     # Set restrictive permissions (owner read/write only)\n408 |     os.chmod(temp_path, 0o600)\n409 |     \n    | ^^^^ W293\n410 |     # Close file descriptor (caller should open as needed)\n411 |     os.close(fd)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:412:1: W293 [*] Blank line contains whitespace\n    |\n410 |     # Close file descriptor (caller should open as needed)\n411 |     os.close(fd)\n412 |     \n    | ^^^^ W293\n413 |     return temp_path\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:418:1: W293 Blank line contains whitespace\n    |\n416 | def secure_delete_file(file_path: Union[str, Path]) -> None:\n417 |     \"\"\"Securely delete a file by overwriting with random data.\n418 |     \n    | ^^^^ W293\n419 |     Args:\n420 |         file_path: Path to file to delete\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:424:1: W293 [*] Blank line contains whitespace\n    |\n422 |     logger = get_logger(\"dgdn.security\")\n423 |     path = Path(file_path)\n424 |     \n    | ^^^^ W293\n425 |     if not path.exists():\n426 |         return\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:427:1: W293 [*] Blank line contains whitespace\n    |\n425 |     if not path.exists():\n426 |         return\n427 |     \n    | ^^^^ W293\n428 |     try:\n429 |         # Get file size\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:431:1: W293 [*] Blank line contains whitespace\n    |\n429 |         # Get file size\n430 |         file_size = path.stat().st_size\n431 |         \n    | ^^^^^^^^ W293\n432 |         # Overwrite with random data multiple times\n433 |         with open(path, 'r+b') as f:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:439:1: W293 [*] Blank line contains whitespace\n    |\n437 |                 f.flush()\n438 |                 os.fsync(f.fileno())\n439 |         \n    | ^^^^^^^^ W293\n440 |         # Finally delete the file\n441 |         path.unlink()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:443:1: W293 [*] Blank line contains whitespace\n    |\n441 |         path.unlink()\n442 |         logger.debug(f\"Securely deleted file: {path}\")\n443 |         \n    | ^^^^^^^^ W293\n444 |     except Exception as e:\n445 |         logger.error(f\"Failed to securely delete file {path}: {e}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/security.py:450:17: W292 [*] No newline at end of file\n    |\n448 |             path.unlink()\n449 |         except Exception:\n450 |             pass\n    |                 ^ W292\n    |\n    = help: Add trailing newline\n\nsrc/dgdn/utils/validation.py:3:1: I001 [*] Import block is un-sorted or un-formatted\n   |\n 1 |   \"\"\"Input validation and data integrity checks for DGDN.\"\"\"\n 2 |\n 3 | / import torch\n 4 | | import numpy as np\n 5 | | from typing import Optional, Dict, Any, List, Union, Tuple\n 6 | | import warnings\n 7 | | from pathlib import Path\n 8 | |\n 9 | | from .config import ModelConfig, DGDNConfig\n10 | | from .logging import get_logger\n   | |_______________________________^ I001\n   |\n   = help: Organize imports\n\nsrc/dgdn/utils/validation.py:4:17: F401 [*] `numpy` imported but unused\n  |\n3 | import torch\n4 | import numpy as np\n  |                 ^^ F401\n5 | from typing import Optional, Dict, Any, List, Union, Tuple\n6 | import warnings\n  |\n  = help: Remove unused import: `numpy`\n\nsrc/dgdn/utils/validation.py:5:41: F401 [*] `typing.List` imported but unused\n  |\n3 | import torch\n4 | import numpy as np\n5 | from typing import Optional, Dict, Any, List, Union, Tuple\n  |                                         ^^^^ F401\n6 | import warnings\n7 | from pathlib import Path\n  |\n  = help: Remove unused import: `typing.List`\n\nsrc/dgdn/utils/validation.py:9:34: F401 [*] `.config.DGDNConfig` imported but unused\n   |\n 7 | from pathlib import Path\n 8 |\n 9 | from .config import ModelConfig, DGDNConfig\n   |                                  ^^^^^^^^^^ F401\n10 | from .logging import get_logger\n   |\n   = help: Remove unused import: `.config.DGDNConfig`\n\nsrc/dgdn/utils/validation.py:24:1: W293 Blank line contains whitespace\n   |\n22 | ) -> bool:\n23 |     \"\"\"Validate tensor properties.\n24 |     \n   | ^^^^ W293\n25 |     Args:\n26 |         tensor: Tensor to validate\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:34:1: W293 Blank line contains whitespace\n   |\n32 |         allow_nan: Whether to allow NaN values\n33 |         allow_inf: Whether to allow infinite values\n34 |         \n   | ^^^^^^^^ W293\n35 |     Returns:\n36 |         True if validation passes\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:37:1: W293 Blank line contains whitespace\n   |\n35 |     Returns:\n36 |         True if validation passes\n37 |         \n   | ^^^^^^^^ W293\n38 |     Raises:\n39 |         ValueError: If validation fails\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:42:1: W293 [*] Blank line contains whitespace\n   |\n40 |     \"\"\"\n41 |     logger = get_logger(\"dgdn.validation\")\n42 |     \n   | ^^^^ W293\n43 |     # Check if it's actually a tensor\n44 |     if not isinstance(tensor, torch.Tensor):\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:46:1: W293 [*] Blank line contains whitespace\n   |\n44 |     if not isinstance(tensor, torch.Tensor):\n45 |         raise ValueError(f\"{name} must be a torch.Tensor, got {type(tensor)}\")\n46 |     \n   | ^^^^ W293\n47 |     # Check shape\n48 |     if expected_shape is not None:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:59:1: W293 [*] Blank line contains whitespace\n   |\n57 |             else:\n58 |                 shape_matches = False\n59 |             \n   | ^^^^^^^^^^^^ W293\n60 |             if not shape_matches:\n61 |                 raise ValueError(f\"{name} shape mismatch: expected {expected_shape}, got {tensor.shape}\")\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:62:1: W293 [*] Blank line contains whitespace\n   |\n60 |             if not shape_matches:\n61 |                 raise ValueError(f\"{name} shape mismatch: expected {expected_shape}, got {tensor.shape}\")\n62 |     \n   | ^^^^ W293\n63 |     # Check dtype\n64 |     if expected_dtype is not None and tensor.dtype != expected_dtype:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:65:9: B028 No explicit `stacklevel` keyword argument found\n   |\n63 |     # Check dtype\n64 |     if expected_dtype is not None and tensor.dtype != expected_dtype:\n65 |         warnings.warn(f\"{name} dtype mismatch: expected {expected_dtype}, got {tensor.dtype}\")\n   |         ^^^^^^^^^^^^^ B028\n66 |     \n67 |     # Check for NaN values\n   |\n   = help: Set `stacklevel=2`\n\nsrc/dgdn/utils/validation.py:66:1: W293 [*] Blank line contains whitespace\n   |\n64 |     if expected_dtype is not None and tensor.dtype != expected_dtype:\n65 |         warnings.warn(f\"{name} dtype mismatch: expected {expected_dtype}, got {tensor.dtype}\")\n66 |     \n   | ^^^^ W293\n67 |     # Check for NaN values\n68 |     if not allow_nan and torch.isnan(tensor).any():\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:70:1: W293 [*] Blank line contains whitespace\n   |\n68 |     if not allow_nan and torch.isnan(tensor).any():\n69 |         raise ValueError(f\"{name} contains NaN values\")\n70 |     \n   | ^^^^ W293\n71 |     # Check for infinite values\n72 |     if not allow_inf and torch.isinf(tensor).any():\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:74:1: W293 [*] Blank line contains whitespace\n   |\n72 |     if not allow_inf and torch.isinf(tensor).any():\n73 |         raise ValueError(f\"{name} contains infinite values\")\n74 |     \n   | ^^^^ W293\n75 |     # Check value range\n76 |     if min_value is not None or max_value is not None:\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:81:1: W293 [*] Blank line contains whitespace\n   |\n79 |         if max_value is not None and tensor.max() > max_value:\n80 |             raise ValueError(f\"{name} contains values above maximum {max_value}: {tensor.max()}\")\n81 |     \n   | ^^^^ W293\n82 |     logger.debug(f\"Tensor {name} validation passed: shape={tensor.shape}, dtype={tensor.dtype}\")\n83 |     return True\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:88:1: W293 Blank line contains whitespace\n   |\n86 | def validate_temporal_data(data) -> bool:\n87 |     \"\"\"Validate TemporalData object.\n88 |     \n   | ^^^^ W293\n89 |     Args:\n90 |         data: TemporalData object to validate\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:91:1: W293 Blank line contains whitespace\n   |\n89 |     Args:\n90 |         data: TemporalData object to validate\n91 |         \n   | ^^^^^^^^ W293\n92 |     Returns:\n93 |         True if validation passes\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:94:1: W293 Blank line contains whitespace\n   |\n92 |     Returns:\n93 |         True if validation passes\n94 |         \n   | ^^^^^^^^ W293\n95 |     Raises:\n96 |         ValueError: If validation fails\n   |\n   = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:99:1: W293 [*] Blank line contains whitespace\n    |\n 97 |     \"\"\"\n 98 |     logger = get_logger(\"dgdn.validation\")\n 99 |     \n    | ^^^^ W293\n100 |     # Check required attributes\n101 |     required_attrs = ['edge_index', 'timestamps', 'num_nodes']\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:105:1: W293 [*] Blank line contains whitespace\n    |\n103 |         if not hasattr(data, attr):\n104 |             raise ValueError(f\"TemporalData missing required attribute: {attr}\")\n105 |     \n    | ^^^^ W293\n106 |     # Validate edge_index\n107 |     edge_index = data.edge_index\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:109:20: W291 [*] Trailing whitespace\n    |\n107 |     edge_index = data.edge_index\n108 |     validate_tensor_properties(\n109 |         edge_index, \n    |                    ^ W291\n110 |         \"edge_index\",\n111 |         expected_shape=(2, -1),\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/utils/validation.py:115:1: W293 [*] Blank line contains whitespace\n    |\n113 |         min_value=0\n114 |     )\n115 |     \n    | ^^^^ W293\n116 |     # Check edge indices are within node range\n117 |     max_node_idx = edge_index.max().item()\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:120:1: W293 [*] Blank line contains whitespace\n    |\n118 |     if max_node_idx >= data.num_nodes:\n119 |         raise ValueError(f\"Edge index {max_node_idx} exceeds num_nodes {data.num_nodes}\")\n120 |     \n    | ^^^^ W293\n121 |     # Validate timestamps\n122 |     timestamps = data.timestamps\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:125:22: W291 [*] Trailing whitespace\n    |\n123 |     validate_tensor_properties(\n124 |         timestamps,\n125 |         \"timestamps\", \n    |                      ^ W291\n126 |         expected_shape=(edge_index.shape[1],),\n127 |         min_value=0.0\n    |\n    = help: Remove trailing whitespace\n\nsrc/dgdn/utils/validation.py:129:1: W293 [*] Blank line contains whitespace\n    |\n127 |         min_value=0.0\n128 |     )\n129 |     \n    | ^^^^ W293\n130 |     # Check timestamps are sorted (recommended but not required)\n131 |     if not torch.all(timestamps[1:] >= timestamps[:-1]):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:132:9: B028 No explicit `stacklevel` keyword argument found\n    |\n130 |     # Check timestamps are sorted (recommended but not required)\n131 |     if not torch.all(timestamps[1:] >= timestamps[:-1]):\n132 |         warnings.warn(\"Timestamps are not sorted - this may affect model performance\")\n    |         ^^^^^^^^^^^^^ B028\n133 |     \n134 |     # Validate optional attributes\n    |\n    = help: Set `stacklevel=2`\n\nsrc/dgdn/utils/validation.py:133:1: W293 [*] Blank line contains whitespace\n    |\n131 |     if not torch.all(timestamps[1:] >= timestamps[:-1]):\n132 |         warnings.warn(\"Timestamps are not sorted - this may affect model performance\")\n133 |     \n    | ^^^^ W293\n134 |     # Validate optional attributes\n135 |     if hasattr(data, 'node_features') and data.node_features is not None:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:142:1: W293 [*] Blank line contains whitespace\n    |\n140 |             expected_shape=(data.num_nodes, -1)\n141 |         )\n142 |     \n    | ^^^^ W293\n143 |     if hasattr(data, 'edge_attr') and data.edge_attr is not None:\n144 |         edge_attr = data.edge_attr\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:150:1: W293 [*] Blank line contains whitespace\n    |\n148 |             expected_shape=(edge_index.shape[1], -1)\n149 |         )\n150 |     \n    | ^^^^ W293\n151 |     # Check device consistency\n152 |     device = edge_index.device\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:155:1: W293 [*] Blank line contains whitespace\n    |\n153 |     if timestamps.device != device:\n154 |         raise ValueError(f\"Device mismatch: edge_index on {device}, timestamps on {timestamps.device}\")\n155 |     \n    | ^^^^ W293\n156 |     if hasattr(data, 'node_features') and data.node_features is not None:\n157 |         if data.node_features.device != device:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:159:1: W293 [*] Blank line contains whitespace\n    |\n157 |         if data.node_features.device != device:\n158 |             raise ValueError(f\"Device mismatch: edge_index on {device}, node_features on {data.node_features.device}\")\n159 |     \n    | ^^^^ W293\n160 |     if hasattr(data, 'edge_attr') and data.edge_attr is not None:\n161 |         if data.edge_attr.device != device:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:163:1: W293 [*] Blank line contains whitespace\n    |\n161 |         if data.edge_attr.device != device:\n162 |             raise ValueError(f\"Device mismatch: edge_index on {device}, edge_attr on {data.edge_attr.device}\")\n163 |     \n    | ^^^^ W293\n164 |     logger.debug(f\"TemporalData validation passed: {data.num_nodes} nodes, {edge_index.shape[1]} edges\")\n165 |     return True\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:170:1: W293 Blank line contains whitespace\n    |\n168 | def validate_model_config(config: ModelConfig) -> bool:\n169 |     \"\"\"Validate model configuration.\n170 |     \n    | ^^^^ W293\n171 |     Args:\n172 |         config: Model configuration to validate\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:173:1: W293 Blank line contains whitespace\n    |\n171 |     Args:\n172 |         config: Model configuration to validate\n173 |         \n    | ^^^^^^^^ W293\n174 |     Returns:\n175 |         True if validation passes\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:176:1: W293 Blank line contains whitespace\n    |\n174 |     Returns:\n175 |         True if validation passes\n176 |         \n    | ^^^^^^^^ W293\n177 |     Raises:\n178 |         ValueError: If validation fails\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:181:1: W293 [*] Blank line contains whitespace\n    |\n179 |     \"\"\"\n180 |     logger = get_logger(\"dgdn.validation\")\n181 |     \n    | ^^^^ W293\n182 |     # Dimension validations\n183 |     if config.node_dim <= 0:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:191:1: W293 [*] Blank line contains whitespace\n    |\n189 |     if config.hidden_dim <= 0:\n190 |         raise ValueError(f\"hidden_dim must be positive, got {config.hidden_dim}\")\n191 |     \n    | ^^^^ W293\n192 |     # Architecture validations\n193 |     if config.num_layers <= 0:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:199:1: W293 [*] Blank line contains whitespace\n    |\n197 |     if config.hidden_dim % config.num_heads != 0:\n198 |         raise ValueError(f\"hidden_dim ({config.hidden_dim}) must be divisible by num_heads ({config.num_heads})\")\n199 |     \n    | ^^^^ W293\n200 |     # Diffusion validations\n201 |     if config.diffusion_steps <= 0:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:203:1: W293 [*] Blank line contains whitespace\n    |\n201 |     if config.diffusion_steps <= 0:\n202 |         raise ValueError(f\"diffusion_steps must be positive, got {config.diffusion_steps}\")\n203 |     \n    | ^^^^ W293\n204 |     # Hyperparameter validations\n205 |     if not (0.0 <= config.dropout < 1.0):\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:209:1: W293 [*] Blank line contains whitespace\n    |\n207 |     if config.max_time <= 0:\n208 |         raise ValueError(f\"max_time must be positive, got {config.max_time}\")\n209 |     \n    | ^^^^ W293\n210 |     # String parameter validations\n211 |     valid_aggregations = {\"attention\", \"mean\", \"sum\", \"max\"}\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:214:1: W293 [*] Blank line contains whitespace\n    |\n212 |     if config.aggregation not in valid_aggregations:\n213 |         raise ValueError(f\"aggregation must be one of {valid_aggregations}, got {config.aggregation}\")\n214 |     \n    | ^^^^ W293\n215 |     valid_activations = {\"relu\", \"gelu\", \"swish\", \"leaky_relu\", \"elu\", \"selu\"}\n216 |     if config.activation not in valid_activations:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:218:1: W293 [*] Blank line contains whitespace\n    |\n216 |     if config.activation not in valid_activations:\n217 |         raise ValueError(f\"activation must be one of {valid_activations}, got {config.activation}\")\n218 |     \n    | ^^^^ W293\n219 |     valid_time_encodings = {\"fourier\", \"positional\", \"multiscale\", \"learned\"}\n220 |     if config.time_encoding not in valid_time_encodings:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:222:1: W293 [*] Blank line contains whitespace\n    |\n220 |     if config.time_encoding not in valid_time_encodings:\n221 |         raise ValueError(f\"time_encoding must be one of {valid_time_encodings}, got {config.time_encoding}\")\n222 |     \n    | ^^^^ W293\n223 |     logger.debug(\"Model configuration validation passed\")\n224 |     return True\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:229:1: W293 Blank line contains whitespace\n    |\n227 | def validate_data(data, strict: bool = True) -> bool:\n228 |     \"\"\"General data validation function.\n229 |     \n    | ^^^^ W293\n230 |     Args:\n231 |         data: Data to validate (can be various types)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:233:1: W293 Blank line contains whitespace\n    |\n231 |         data: Data to validate (can be various types)\n232 |         strict: Whether to use strict validation\n233 |         \n    | ^^^^^^^^ W293\n234 |     Returns:\n235 |         True if validation passes\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:238:1: W293 [*] Blank line contains whitespace\n    |\n236 |     \"\"\"\n237 |     logger = get_logger(\"dgdn.validation\")\n238 |     \n    | ^^^^ W293\n239 |     if data is None:\n240 |         if strict:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:245:1: W293 [*] Blank line contains whitespace\n    |\n243 |             logger.warning(\"Data is None\")\n244 |             return False\n245 |     \n    | ^^^^ W293\n246 |     # Handle different data types\n247 |     if hasattr(data, 'edge_index'):  # Likely TemporalData\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:253:13: B007 Loop control variable `i` not used within loop body\n    |\n251 |     elif isinstance(data, (list, tuple)):\n252 |         # Validate each item in sequence\n253 |         for i, item in enumerate(data):\n    |             ^ B007\n254 |             validate_data(item, strict=strict)\n255 |         return True\n    |\n    = help: Rename unused `i` to `_i`\n\nsrc/dgdn/utils/validation.py:263:1: W293 Blank line contains whitespace\n    |\n261 | def validate_tensors(tensors: Dict[str, torch.Tensor], specs: Dict[str, Dict[str, Any]]) -> bool:\n262 |     \"\"\"Validate multiple tensors according to specifications.\n263 |     \n    | ^^^^ W293\n264 |     Args:\n265 |         tensors: Dictionary of tensors to validate\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:267:1: W293 Blank line contains whitespace\n    |\n265 |         tensors: Dictionary of tensors to validate\n266 |         specs: Dictionary of validation specifications for each tensor\n267 |         \n    | ^^^^^^^^ W293\n268 |     Returns:\n269 |         True if all validations pass\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:275:1: W293 [*] Blank line contains whitespace\n    |\n273 |             spec = specs[name]\n274 |             validate_tensor_properties(tensor, name, **spec)\n275 |     \n    | ^^^^ W293\n276 |     return True\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:287:1: W293 Blank line contains whitespace\n    |\n285 | ) -> bool:\n286 |     \"\"\"Check if model can fit in available memory.\n287 |     \n    | ^^^^ W293\n288 |     Args:\n289 |         num_nodes: Number of nodes in graph\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:294:1: W293 Blank line contains whitespace\n    |\n292 |         batch_size: Batch size\n293 |         max_memory_gb: Maximum available memory in GB\n294 |         \n    | ^^^^^^^^ W293\n295 |     Returns:\n296 |         True if memory requirements are acceptable\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:297:1: W293 Blank line contains whitespace\n    |\n295 |     Returns:\n296 |         True if memory requirements are acceptable\n297 |         \n    | ^^^^^^^^ W293\n298 |     Raises:\n299 |         ValueError: If memory requirements exceed limit\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:302:1: W293 [*] Blank line contains whitespace\n    |\n300 |     \"\"\"\n301 |     logger = get_logger(\"dgdn.validation\")\n302 |     \n    | ^^^^ W293\n303 |     # Estimate memory requirements (rough calculation)\n304 |     # Node embeddings: num_nodes * hidden_dim * 4 bytes (float32)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:308:1: W293 [*] Blank line contains whitespace\n    |\n306 |     # Attention matrices: num_nodes * num_nodes * 4 bytes (worst case)\n307 |     # Gradients: 2x the model parameters\n308 |     \n    | ^^^^ W293\n309 |     node_memory = num_nodes * hidden_dim * 4 * batch_size\n310 |     edge_memory = num_edges * hidden_dim * 4 * batch_size\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:312:1: W293 [*] Blank line contains whitespace\n    |\n310 |     edge_memory = num_edges * hidden_dim * 4 * batch_size\n311 |     attention_memory = num_nodes * num_nodes * 4 * batch_size  # Conservative estimate\n312 |     \n    | ^^^^ W293\n313 |     total_memory_bytes = node_memory + edge_memory + attention_memory\n314 |     total_memory_gb = total_memory_bytes / (1024 ** 3)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:315:1: W293 [*] Blank line contains whitespace\n    |\n313 |     total_memory_bytes = node_memory + edge_memory + attention_memory\n314 |     total_memory_gb = total_memory_bytes / (1024 ** 3)\n315 |     \n    | ^^^^ W293\n316 |     logger.info(f\"Estimated memory requirements: {total_memory_gb:.2f} GB\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:317:1: W293 [*] Blank line contains whitespace\n    |\n316 |     logger.info(f\"Estimated memory requirements: {total_memory_gb:.2f} GB\")\n317 |     \n    | ^^^^ W293\n318 |     if total_memory_gb > max_memory_gb:\n319 |         raise ValueError(\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:323:1: W293 [*] Blank line contains whitespace\n    |\n321 |             f\"Consider reducing hidden_dim, batch_size, or graph size.\"\n322 |         )\n323 |     \n    | ^^^^ W293\n324 |     return True\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:329:1: W293 Blank line contains whitespace\n    |\n327 | def validate_file_path(file_path: Union[str, Path], must_exist: bool = True) -> Path:\n328 |     \"\"\"Validate file path.\n329 |     \n    | ^^^^ W293\n330 |     Args:\n331 |         file_path: Path to validate\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:333:1: W293 Blank line contains whitespace\n    |\n331 |         file_path: Path to validate\n332 |         must_exist: Whether file must already exist\n333 |         \n    | ^^^^^^^^ W293\n334 |     Returns:\n335 |         Validated Path object\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:336:1: W293 Blank line contains whitespace\n    |\n334 |     Returns:\n335 |         Validated Path object\n336 |         \n    | ^^^^^^^^ W293\n337 |     Raises:\n338 |         ValueError: If validation fails\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:341:1: W293 [*] Blank line contains whitespace\n    |\n339 |     \"\"\"\n340 |     path = Path(file_path)\n341 |     \n    | ^^^^ W293\n342 |     if must_exist and not path.exists():\n343 |         raise ValueError(f\"File does not exist: {path}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:344:1: W293 [*] Blank line contains whitespace\n    |\n342 |     if must_exist and not path.exists():\n343 |         raise ValueError(f\"File does not exist: {path}\")\n344 |     \n    | ^^^^ W293\n345 |     if must_exist and not path.is_file():\n346 |         raise ValueError(f\"Path is not a file: {path}\")\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:347:1: W293 [*] Blank line contains whitespace\n    |\n345 |     if must_exist and not path.is_file():\n346 |         raise ValueError(f\"Path is not a file: {path}\")\n347 |     \n    | ^^^^ W293\n348 |     # Check file extension for known types\n349 |     if path.suffix.lower() not in ['.pt', '.pth', '.pkl', '.json', '.yaml', '.yml', '.csv']:\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:350:9: B028 No explicit `stacklevel` keyword argument found\n    |\n348 |     # Check file extension for known types\n349 |     if path.suffix.lower() not in ['.pt', '.pth', '.pkl', '.json', '.yaml', '.yml', '.csv']:\n350 |         warnings.warn(f\"Unknown file extension: {path.suffix}\")\n    |         ^^^^^^^^^^^^^ B028\n351 |     \n352 |     return path\n    |\n    = help: Set `stacklevel=2`\n\nsrc/dgdn/utils/validation.py:351:1: W293 [*] Blank line contains whitespace\n    |\n349 |     if path.suffix.lower() not in ['.pt', '.pth', '.pkl', '.json', '.yaml', '.yml', '.csv']:\n350 |         warnings.warn(f\"Unknown file extension: {path.suffix}\")\n351 |     \n    | ^^^^ W293\n352 |     return path\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:357:1: W293 [*] Blank line contains whitespace\n    |\n355 | class DataValidator:\n356 |     \"\"\"Stateful data validator that can accumulate validation statistics.\"\"\"\n357 |     \n    | ^^^^ W293\n358 |     def __init__(self, strict: bool = True):\n359 |         self.strict = strict\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:366:1: W293 [*] Blank line contains whitespace\n    |\n364 |         }\n365 |         self.logger = get_logger(\"dgdn.validation\")\n366 |     \n    | ^^^^ W293\n367 |     def validate(self, data, validation_name: str = \"data\") -> bool:\n368 |         \"\"\"Validate data and update statistics.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:370:1: W293 [*] Blank line contains whitespace\n    |\n368 |         \"\"\"Validate data and update statistics.\"\"\"\n369 |         self.validation_stats['total_validations'] += 1\n370 |         \n    | ^^^^^^^^ W293\n371 |         try:\n372 |             result = validate_data(data, strict=self.strict)\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:383:1: W293 [*] Blank line contains whitespace\n    |\n381 |                 self.logger.warning(f\"Validation failed for {validation_name}: {e}\")\n382 |                 return False\n383 |     \n    | ^^^^ W293\n384 |     def get_stats(self) -> Dict[str, Any]:\n385 |         \"\"\"Get validation statistics.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:387:1: W293 [*] Blank line contains whitespace\n    |\n385 |         \"\"\"Get validation statistics.\"\"\"\n386 |         return self.validation_stats.copy()\n387 |     \n    | ^^^^ W293\n388 |     def reset_stats(self) -> None:\n389 |         \"\"\"Reset validation statistics.\"\"\"\n    |\n    = help: Remove whitespace from blank line\n\nsrc/dgdn/utils/validation.py:394:10: W292 [*] No newline at end of file\n    |\n392 |             'failed_validations': 0,\n393 |             'warnings_issued': 0\n394 |         }\n    |          ^ W292\n    |\n    = help: Add trailing newline\n\nFound 1490 errors.\n[*] 1360 fixable with the `--fix` option (123 hidden fixes can be enabled with the `--unsafe-fixes` option).\n",
      "error": "warning: The top-level linter settings are deprecated in favour of their counterparts in the `lint` section. Please update the following options in `pyproject.toml`:\n  - 'ignore' -> 'lint.ignore'\n  - 'select' -> 'lint.select'\n  - 'per-file-ignores' -> 'lint.per-file-ignores'\n"
    },
    "security_scan": {
      "name": "Security Scan",
      "passed": true,
      "duration": 1.5772058963775635,
      "total_issues": 10,
      "high_severity": 0,
      "output": "{\n  \"errors\": [],\n  \"generated_at\": \"2025-08-10T01:06:52Z\",\n  \"metrics\": {\n    \"/root/repo/src/dgdn/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 26,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/compliance/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 21,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/compliance/ccpa.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 336,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/compliance/data_protection.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 361,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/compliance/gdpr.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 306,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/compliance/pdpa.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 380,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/compliance/privacy_manager.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 322,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/data/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 11,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/data/datasets.py\": {\n      \"CONFIDENCE.HIGH\": 3,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 2,\n      \"SEVERITY.MEDIUM\": 1,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 307,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/data/loaders.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 281,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/deployment/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 3,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/deployment/region_manager.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 358,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/i18n/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 5,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/i18n/locales.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 57,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/i18n/messages.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 221,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/i18n/translator.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 149,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/models/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 4,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/models/dgdn.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 398,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/models/layers.py\": {\n      \"CONFIDENCE.HIGH\": 1,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 1,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 237,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/optimization/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 19,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/optimization/caching.py\": {\n      \"CONFIDENCE.HIGH\": 1,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 1,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 265,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/optimization/computation.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 305,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/optimization/memory.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 187,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/temporal/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 4,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/temporal/diffusion.py\": {\n      \"CONFIDENCE.HIGH\": 1,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 1,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 289,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/temporal/encoding.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 169,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/training/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 13,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/training/losses.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 277,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/training/metrics.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 319,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/training/trainer.py\": {\n      \"CONFIDENCE.HIGH\": 1,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 1,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 514,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/utils/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 23,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/utils/config.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 200,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/utils/logging.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 197,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/utils/monitoring.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 372,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/utils/security.py\": {\n      \"CONFIDENCE.HIGH\": 3,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 2,\n      \"SEVERITY.MEDIUM\": 1,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 303,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"/root/repo/src/dgdn/utils/validation.py\": {\n      \"CONFIDENCE.HIGH\": 0,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 0,\n      \"SEVERITY.MEDIUM\": 0,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 285,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    },\n    \"_totals\": {\n      \"CONFIDENCE.HIGH\": 10,\n      \"CONFIDENCE.LOW\": 0,\n      \"CONFIDENCE.MEDIUM\": 0,\n      \"CONFIDENCE.UNDEFINED\": 0,\n      \"SEVERITY.HIGH\": 0,\n      \"SEVERITY.LOW\": 7,\n      \"SEVERITY.MEDIUM\": 3,\n      \"SEVERITY.UNDEFINED\": 0,\n      \"loc\": 7524,\n      \"nosec\": 0,\n      \"skipped_tests\": 0\n    }\n  },\n  \"results\": [\n    {\n      \"code\": \"3 import os\\n4 import pickle\\n5 import numpy as np\\n\",\n      \"col_offset\": 0,\n      \"end_col_offset\": 13,\n      \"filename\": \"/root/repo/src/dgdn/data/datasets.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_cwe\": {\n        \"id\": 502,\n        \"link\": \"https://cwe.mitre.org/data/definitions/502.html\"\n      },\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Consider possible security implications associated with pickle module.\",\n      \"line_number\": 4,\n      \"line_range\": [\n        4\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/1.8.6/blacklists/blacklist_imports.html#b403-import-pickle\",\n      \"test_id\": \"B403\",\n      \"test_name\": \"blacklist\"\n    },\n    {\n      \"code\": \"211         \\\"\\\"\\\"\\n212         assert len(ratios) == 3 and abs(sum(ratios) - 1.0) < 1e-6\\n213         \\n\",\n      \"col_offset\": 8,\n      \"end_col_offset\": 65,\n      \"filename\": \"/root/repo/src/dgdn/data/datasets.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_cwe\": {\n        \"id\": 703,\n        \"link\": \"https://cwe.mitre.org/data/definitions/703.html\"\n      },\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 212,\n      \"line_range\": [\n        212\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"284         with open(path, 'rb') as f:\\n285             return pickle.load(f)\\n286 \\n\",\n      \"col_offset\": 19,\n      \"end_col_offset\": 33,\n      \"filename\": \"/root/repo/src/dgdn/data/datasets.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_cwe\": {\n        \"id\": 502,\n        \"link\": \"https://cwe.mitre.org/data/definitions/502.html\"\n      },\n      \"issue_severity\": \"MEDIUM\",\n      \"issue_text\": \"Pickle and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue.\",\n      \"line_number\": 285,\n      \"line_range\": [\n        285\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/1.8.6/blacklists/blacklist_calls.html#b301-pickle\",\n      \"test_id\": \"B301\",\n      \"test_name\": \"blacklist\"\n    },\n    {\n      \"code\": \"34         \\n35         assert hidden_dim % num_heads == 0, \\\"hidden_dim must be divisible by num_heads\\\"\\n36         \\n\",\n      \"col_offset\": 8,\n      \"end_col_offset\": 87,\n      \"filename\": \"/root/repo/src/dgdn/models/layers.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_cwe\": {\n        \"id\": 703,\n        \"link\": \"https://cwe.mitre.org/data/definitions/703.html\"\n      },\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 35,\n      \"line_range\": [\n        35\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"8 import hashlib\\n9 import pickle\\n10 import time\\n\",\n      \"col_offset\": 0,\n      \"end_col_offset\": 13,\n      \"filename\": \"/root/repo/src/dgdn/optimization/caching.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_cwe\": {\n        \"id\": 502,\n        \"link\": \"https://cwe.mitre.org/data/definitions/502.html\"\n      },\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Consider possible security implications associated with pickle module.\",\n      \"line_number\": 9,\n      \"line_range\": [\n        9\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/1.8.6/blacklists/blacklist_imports.html#b403-import-pickle\",\n      \"test_id\": \"B403\",\n      \"test_name\": \"blacklist\"\n    },\n    {\n      \"code\": \"231         \\n232         assert hidden_dim % num_heads == 0, \\\"hidden_dim must be divisible by num_heads\\\"\\n233         \\n\",\n      \"col_offset\": 8,\n      \"end_col_offset\": 87,\n      \"filename\": \"/root/repo/src/dgdn/temporal/diffusion.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_cwe\": {\n        \"id\": 703,\n        \"link\": \"https://cwe.mitre.org/data/definitions/703.html\"\n      },\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 232,\n      \"line_range\": [\n        232\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/1.8.6/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"552         checkpoint_path = os.path.join(self.checkpoint_dir, filename)\\n553         checkpoint = torch.load(checkpoint_path, map_location=self.device)\\n554         \\n\",\n      \"col_offset\": 21,\n      \"end_col_offset\": 74,\n      \"filename\": \"/root/repo/src/dgdn/training/trainer.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_cwe\": {\n        \"id\": 502,\n        \"link\": \"https://cwe.mitre.org/data/definitions/502.html\"\n      },\n      \"issue_severity\": \"MEDIUM\",\n      \"issue_text\": \"Use of unsafe PyTorch load\",\n      \"line_number\": 553,\n      \"line_range\": [\n        553\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/1.8.6/plugins/b614_pytorch_load.html\",\n      \"test_id\": \"B614\",\n      \"test_name\": \"pytorch_load\"\n    },\n    {\n      \"code\": \"4 import hashlib\\n5 import pickle\\n6 import tempfile\\n\",\n      \"col_offset\": 0,\n      \"end_col_offset\": 13,\n      \"filename\": \"/root/repo/src/dgdn/utils/security.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_cwe\": {\n        \"id\": 502,\n        \"link\": \"https://cwe.mitre.org/data/definitions/502.html\"\n      },\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Consider possible security implications associated with pickle module.\",\n      \"line_number\": 5,\n      \"line_range\": [\n        5\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/1.8.6/blacklists/blacklist_imports.html#b403-import-pickle\",\n      \"test_id\": \"B403\",\n      \"test_name\": \"blacklist\"\n    },\n    {\n      \"code\": \"304     try:\\n305         state_dict = torch.load(path, map_location='cpu')\\n306     except Exception as e:\\n\",\n      \"col_offset\": 21,\n      \"end_col_offset\": 57,\n      \"filename\": \"/root/repo/src/dgdn/utils/security.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_cwe\": {\n        \"id\": 502,\n        \"link\": \"https://cwe.mitre.org/data/definitions/502.html\"\n      },\n      \"issue_severity\": \"MEDIUM\",\n      \"issue_text\": \"Use of unsafe PyTorch load\",\n      \"line_number\": 305,\n      \"line_range\": [\n        305\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/1.8.6/plugins/b614_pytorch_load.html\",\n      \"test_id\": \"B614\",\n      \"test_name\": \"pytorch_load\"\n    },\n    {\n      \"code\": \"448             path.unlink()\\n449         except Exception:\\n450             pass\\n\",\n      \"col_offset\": 8,\n      \"end_col_offset\": 16,\n      \"filename\": \"/root/repo/src/dgdn/utils/security.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_cwe\": {\n        \"id\": 703,\n        \"link\": \"https://cwe.mitre.org/data/definitions/703.html\"\n      },\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Try, Except, Pass detected.\",\n      \"line_number\": 449,\n      \"line_range\": [\n        449,\n        450\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/1.8.6/plugins/b110_try_except_pass.html\",\n      \"test_id\": \"B110\",\n      \"test_name\": \"try_except_pass\"\n    }\n  ]\n}",
      "error": "[main]\tINFO\tprofile include tests: None\n[main]\tINFO\tprofile exclude tests: None\n[main]\tINFO\tcli include tests: None\n[main]\tINFO\tcli exclude tests: None\n"
    },
    "dependency_scan": {
      "name": "Dependency Scan",
      "passed": true,
      "duration": 0.0009653568267822266,
      "vulnerabilities": 0,
      "output": "",
      "error": "[Errno 2] No such file or directory: 'safety'"
    },
    "performance_tests": {
      "name": "Performance Tests",
      "passed": false,
      "duration": 0.08192229270935059,
      "output": "Generation 1 failed: Traceback (most recent call last):\n  File \"/root/repo/gen1_demo.py\", line 10, in <module>\n    import torch\nModuleNotFoundError: No module named 'torch'\n\nGeneration 2 failed: Traceback (most recent call last):\n  File \"/root/repo/gen2_simple_demo.py\", line 10, in <module>\n    import torch\nModuleNotFoundError: No module named 'torch'\n\nGeneration 3 failed: Traceback (most recent call last):\n  File \"/root/repo/gen3_demo.py\", line 10, in <module>\n    import torch\nModuleNotFoundError: No module named 'torch'\n",
      "error": "Some performance tests failed"
    }
  },
  "critical_failures": [
    "import_tests",
    "unit_tests"
  ],
  "summary": {
    "total": 10,
    "passed": 2,
    "failed": 8
  }
}